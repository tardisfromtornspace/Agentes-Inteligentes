{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca9707c3",
   "metadata": {},
   "source": [
    "<div><img style=\"float: right; width: 120px; vertical-align:middle\" src=\"https://www.upm.es/sfs/Rectorado/Gabinete%20del%20Rector/Logos/EU_Informatica/ETSI%20SIST_INFORM_COLOR.png\" alt=\"ETSISI logo\" />\n",
    "\n",
    "\n",
    "# _Transfer learning_<a id=\"top\"></a>\n",
    "\n",
    "<i><small>Autor: Alberto Díaz Álvarez<br>Última actualización: 2023-03-28</small></i></div>\n",
    "                                                  \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ad5ac6",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En este notebook vamos a trabajar con el concepto de _Transfer Learning_. La idea tras este es \"vamos a aprovechar los conocimientos aprendidos en un modelo para el entrenamiento de otro modelo\".\n",
    "\n",
    "Siendo un poco más específicos, el proceso consiste en hacer uso de una red neuronal previamente entrenada con un buen rendimiento en un conjunto de datos más amplio, usándola como base sobre la que crear un nuevo modelo que aproveche la exactitud de esa red anterior para una nueva tarea. La \"intuición\" detrás de esto es que, como las primeras capas se encargan de características determinadas (en nuestro ejemplo, de características propias de imágenes), un problema que también trate con este tipo de características usará las mismas o muy parecidas (en nuestro ejemplo bordes, manchas, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a448bd3c",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "\n",
    "Aprenderemos a salvar y cargar modelos, y a usarlos parcialmente para crear modelos basados en otros ya entrenados usando la técnicas del _transfer learning_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fed507",
   "metadata": {},
   "source": [
    "## Imports y configuración\n",
    "\n",
    "A continuación importaremos las librerías que se usarán a lo largo del notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b77bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emnist\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce86e18",
   "metadata": {},
   "source": [
    "Asímismo, configuramos algunos parámetros para adecuar la presentación gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bbabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'figure.figsize': (20, 6),'figure.dpi': 64})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a0af3a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8ba69d",
   "metadata": {},
   "source": [
    "## Extracción de características vs. ajuste fino (fine-tuning)\n",
    "\n",
    "Existen dos extremos a la hora de usar el _Transfer Learning_; en uno de ellos, partimos de una red preentrenada, pero permitimos que se modifiquen algunos de los pesos (normalmente la última capa o las últimas capas). Se denomina \"ajuste fino\" o _fine-tuning_ porque estamos ajustando ligeramente los pesos de la red preentrenada a la nueva tarea. Normalmente entrenamos una red de este tipo con una tasa de aprendizaje más baja de lo normal, ya que esperamos que las características ya sean relativamente buenas y no sea necesario cambiarlas demasiado.\n",
    "\n",
    "En el otro extremo, consiste en tomar la red preentrenada y congelar totalmente los pesos, utilizando una de sus capas ocultas (normalmente la última) como extractor de características y, por tanto, como entrada a una red neuronal más pequeña.\n",
    "\n",
    "## Salvando y cargando nuestro modelo\n",
    "\n",
    "En este ejemplo vamos a usar primero la red neuronal que usamos en el primer ejercicio para resolver el problema MNIST. La vamos a salvar y a cargar para volver a entrenarla, pero esta vez con los pesos ya cargados. Esto es únicamente una muestra, para más información por favor visitar [Save and load Keras models](https://www.tensorflow.org/guide/keras/save\\_and\\_serialize?hl=sl), donde se muestran distintas alternativas de salvado y cargado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77db2c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(f'Training shape: {x_train.shape} input, {y_train.shape} output')\n",
    "print(f'Test shape:     {x_test.shape} input, {y_test.shape} output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90f98e1",
   "metadata": {},
   "source": [
    "En esta ocasión no vamos a hacer una codificación _one-hot_ en la salida. Existe un método para calcular el _loss_ análogo a `categorical_crossentropy` denominado `sparse_categorical_crossentropy` que esencialmente hace lo mismo. La única diferencia es el formato en el que se representa la salida.\n",
    "\n",
    "Si esta es en formato _one-hot_, es necesario categorical_crossentropy, y si es un valor entero, `sparse_categorical_crossentropy`. No tiene más. El uso depende totalmente de cómo cargue el conjunto de datos. Una ventaja de utilizar la `sparse_categorical_crossentropy` es que ahorra memoria al utilizar un único número entero para una clase, en lugar de un vector completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1525afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics = ['sparse_categorical_accuracy'])\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train, epochs=100, batch_size=len(x_train), validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d1a1c7",
   "metadata": {},
   "source": [
    "Veamos la evolución del entrenamiento gráficamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde03ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6886a634",
   "metadata": {},
   "source": [
    "Ahora vamos a salvar el modelo. Evaluaremos contra el conjunto de test antes de salvarlo y después de cargarlo para asegurarnos de que es el mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bbebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sacamos medidas\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'Original model: {loss} loss, {accuracy} accuracy')\n",
    "# Salvamos el modelo\n",
    "model.save('tmp/supermodel.h5')\n",
    "# Cargamos el modelo\n",
    "model2 = tf.keras.models.load_model('tmp/supermodel.h5')\n",
    "# Sacamos las medidas del modelo cargado\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'Lodaded model:  {loss} loss, {accuracy} accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f4d422",
   "metadata": {},
   "source": [
    "Lo bueno es que ahora podemos seguir entrenando el modelo en el punto que lo dejamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e026b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model2.fit(x_train, y_train, epochs=100, batch_size=len(x_train), validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1106c0",
   "metadata": {},
   "source": [
    "Podemos examinar la tendencia de esta fase de entrenamiento para comprobar que, efectivamente, comienza en el punto que se quedó en el anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66edd5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee8fbe9",
   "metadata": {},
   "source": [
    "Ahora, vamos a usar nuestro modelo para intentar reconocer no sólo números, sino también letras (un poco pretencioso, sí, pero es para aprender a usar nuestros modelos con _transfer learning_). Para ello nos apoyaremos en el conjunto [https://www.nist.gov/itl/products-and-services/emnist-dataset](EMNIST (Extended MNIST)) y de un _wrapper_ llamado `emnist` (`pip install emnist`) para no tener que descargar el dataset a mano.\n",
    "\n",
    "Una vez lo tenemos instalado, haremos uso del _dataset_ con las clases balanceadas: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1284a785",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_emnist, y_train_emnist = emnist.extract_training_samples('balanced')\n",
    "x_test_emnist, y_test_emnist = emnist.extract_test_samples('balanced')\n",
    "\n",
    "x_train_emnist = x_train_emnist / 255\n",
    "x_test_emnist = x_test_emnist / 255\n",
    "\n",
    "print(f'Training shape: {x_train_emnist.shape} input, {y_train_emnist.shape} output')\n",
    "print(f'Test shape:     {x_test_emnist.shape}  input, {y_test_emnist.shape} output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feed30a",
   "metadata": {},
   "source": [
    "Los ejemplos tienen la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa07a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train_emnist[0], cmap='hot');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b64b0d",
   "metadata": {},
   "source": [
    "Y sus etiquetas correspondientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ecbea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train_emnist[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc68c1b",
   "metadata": {},
   "source": [
    "Lo que haremos será cargar nuestro modelo previamente salvado y usaremos sus primeras capas sin modificar. Únicamente cambiaremos la última capa para que clasifique nuestros ejemplos, que son bastantes más.\n",
    "\n",
    "Ésta será la única capa que entrenaremos. Esto se hace con la suposición de que las primeras capas de un modelo extraen o aprenden las características relevantes que hacen a los ejemplos únicos, y que las últimas aprenden a inferir a partir de estas características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a952f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('tmp/supermodel.h5')\n",
    "\n",
    "model_emnist = tf.keras.Sequential()\n",
    "for i, layer in enumerate(model.layers[:-1]):  # ¡¡No incluimos la última!!\n",
    "    model_emnist.add(layer)\n",
    "    model_emnist.layers[-1].trainable = False  # Si no, entrenará los parámetros de estas capas\n",
    "model_emnist.add(tf.keras.layers.Dense(47, activation='softmax'))\n",
    "\n",
    "model_emnist.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics = ['sparse_categorical_accuracy'])\n",
    "model_emnist.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a800ab7",
   "metadata": {},
   "source": [
    "Viendo el resumen de la arquitectura de la red podemos observar que de todos los parámetros que existen, sólo se entrenarán 235, los correspondientes a las conexiones entre la penúltima y última capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0773efd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_emnist.fit(x_train_emnist, y_train_emnist, epochs=100, batch_size=len(x_train_emnist), validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2972e90",
   "metadata": {},
   "source": [
    "Ahora veamos cómo ha progresado la evolución del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c26a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c56084",
   "metadata": {},
   "source": [
    "Bueno, quizá no ha sido el mejor ejemplo, ya que es modelo de partida es pequeño y poco generalista. Pero al menos ya sabemos como manipular un modelo para crear uno nuevo a partir de otro previamente entrenado. Ahora usaremos otro modelo más grande para ver cómo se comporta con el _dataset_ EMNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b297af",
   "metadata": {},
   "source": [
    "### Usando un modelo preentrenado\n",
    "\n",
    "Podemos hacer uso de los modelos salvados como parte de nuevos modelos. No suele ser trivial, pero no demasiado complicado ya que los propios modelos suelen proporcionar ayuda o, al menos, la descripción de la arquitectura para entender cómo realizarlos.\n",
    "\n",
    "Disponemos de múltiples modelos con los que trabajar. Sólo en Keras existen decenas de modelos preentrenados listos para descargar desde la API `applications`. Veamos un ejemplo con el modelo _ResNet50_.\n",
    "\n",
    "Para ello, necesitaremos transformar nuestras imágenes del EMNIST (en realidad arrays bidimensionales) en imágenes de 3 canales de color. Además el tamaño mínimo de imagen esperado es de $75 \\times 75$, por lo que tendremos que ajustarlas también."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d58231",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_emnist.reshape((-1, 28, 28, 1))\n",
    "x_test = x_test_emnist.reshape((-1, 28, 28, 1))\n",
    "x_train, x_test = tf.image.resize(x_train, (32, 32)), tf.image.resize(x_test, (32, 32))\n",
    "x_train, x_test = tf.image.grayscale_to_rgb(x_train), tf.image.grayscale_to_rgb(x_test)\n",
    "y_train, y_test = y_train_emnist, y_test_emnist\n",
    "\n",
    "print(f'Training shape: {x_train.shape} input, {y_train.shape} output')\n",
    "print(f'Test shape:     {x_test.shape}  input, {y_test.shape} output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e2fd8a",
   "metadata": {},
   "source": [
    "Ahora, al igual que hemos hecho antes, cargaremos el modelo ResNet50 sin incluir la última capa (argumento `include_top` a `False`). Además especificaremos que **no** queremos entrenar el modelo precargado. Los ingenieros de Microsoft han empleado tiempo y máquinas como para que estos modelos estén bastante bien entrenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67af95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = tf.keras.applications.ResNet50(input_shape=[32, 32, 3], include_top=False)\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    pretrained_model,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(47, activation='softmax')\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics = ['sparse_categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592f0423",
   "metadata": {},
   "source": [
    "Ahora sólo nos quedaría entrenar. Afortunadamente, de los más de 23 millones de parámetros, sólo ajustaremos algo más de 96000, así que genial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d5ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, batch_size=1024, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc08b54",
   "metadata": {},
   "source": [
    "Lento, ¿eh? Bueno, aunque nos hemos evitado entrenar millones de parámetros, lo que no hemos podido evitar es la inferencia, y esta suele costar.\n",
    "\n",
    "Veamos cómo ha evolucionado el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53cff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05239ef4",
   "metadata": {},
   "source": [
    "## ¿De dónde obtener modelos preentrenados?\n",
    "\n",
    "A fecha de hoy (28 de marzo de 2023) existen más $38$ modelos preentrenados disponibles en Keras a través de la API `applications`. Al descargarlo, los pesos se descargarán automáticamente en el directorio `~/.keras/models/`. Desafortunadamente, todos los modelos de la API hasta la fecha se usan para imágenes.\n",
    "\n",
    "Tenemos disponibles no obstante más fuentes de modelos preentrenados.\n",
    "\n",
    "### [TensorFlow Hub](https://tfhub.dev/)\n",
    "\n",
    "Como no  podía ser de otro modo, existe un \"Hub\" para modelos de TensorFlow. Un ejemplo de instanciación puede ser el siguiente:\n",
    "\n",
    "```python\n",
    "import tensorflow_hub as hub\n",
    "  \n",
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\n",
    "        'https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1',\n",
    "        trainable=False\n",
    "    ),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "```\n",
    "\n",
    "El API de TensorFlow Hub está disponible a traves de pip: `pip install --upgrade tensorflow_hub`\n",
    "\n",
    "### Embeddings\n",
    "\n",
    "Los veremos más adelante en Procesamiento de Lenguaje Natural (NLP), pero para que quede dicho, existen alguos proyectos independientes lo suficientemente famosos para disponer de su propio sitio de descarga. Este es el caso de los _embeddings_, como por ejemplo:\n",
    "\n",
    "* [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/)\n",
    "* [Word2vec](https://code.google.com/archive/p/word2vec/)\n",
    "* [fastText](https://fasttext.cc/docs/en/english-vectors.html)\n",
    "\n",
    "En el tema de NLP veremos cómo usar algunos de estos _embeddings_.\n",
    "\n",
    "### [Hugging face](https://huggingface.co/)\n",
    "\n",
    "Hugging Face es una empresa con sede en los Estados Unidos que desarrolla herramientas para la creación de aplicaciones basadas en aprendizaje automático. Son los desarrolladores de la biblioteca `transformers`, la cual se usa extensamente para aplicaciones de NLP.\n",
    "\n",
    "Su plataforma permite a los usuarios compartir modelos y conjuntos de datos de aprendizaje automático. En la actualidad disponen de miles de modelo preentrenados para realizar tareas de todo tipo:\n",
    "\n",
    "- **Visión artificial**, como clasificación de imágenes o de vídeo, segmentación o detección de objetos.\n",
    "- **NLP**, como análisis de sentimiento, generación de texto o traducción.\n",
    "- **Audio**, como reconocimiento del habla, clasificación o generación de audio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9ad2d7",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div><img style=\"float: right; width: 120px; vertical-align:top\" src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" alt=\"Creative Commons by-nc-sa logo\" />\n",
    "\n",
    "[Volver al inicio](#top)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
