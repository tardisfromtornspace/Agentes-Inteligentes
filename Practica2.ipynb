{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4e324d9",
   "metadata": {},
   "source": [
    "FASE 0: PREPARACIÓN\n",
    "\n",
    "El sistema requiere de array, ast, numpy, pandas, re, scikit-learn (sklearn) y keras (tensorflow)\n",
    "\n",
    "Comentado se encuentra una posible opción para tratar que tensorflow no utilize la GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5e7203e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "# Sin GPU\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "from array import array\n",
    "import ast\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import sklearn.model_selection\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f92c83b",
   "metadata": {},
   "source": [
    "Primero cargamos el conjunto de entrenamiento y test, en este caso de un .csv mediante pandas. Utilizamos una función de pandas para que se muestre todo.\n",
    "\n",
    "Más tarde los dividimos en esos subconjuntos y lo comprobamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6097f86b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None) # Se muestra todo\n",
    "pd.set_option('display.max_columns', None) # Se muestra todo\n",
    "x_dataframe = pd.read_csv('papers.csv') #tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c1cd4b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total shape: (448, 8) input (448,) output\n",
      "Training shape: (404, 8) input (404,) output\n",
      "Test shape: (44, 8) input (44,) output\n"
     ]
    }
   ],
   "source": [
    "x_test, x_train = sklearn.model_selection.train_test_split(x_dataframe, test_size=0.9, train_size=0.1, random_state=None, shuffle=True, stratify=None)\n",
    "# validación en el propio fit, validation_split = 0.1\n",
    "\n",
    "print(f'Total shape: {str(x_dataframe.shape)} input {x_dataframe.keywords.shape} output') \n",
    "print(f'Training shape: {str(x_train.shape)} input {x_train.keywords.shape} output') # Estructura: 60k números de 28x28 \n",
    "#print(x_train)\n",
    "print(f'Test shape: {str(x_test.shape)} input {x_test.keywords.shape} output')\n",
    "#print(x_test)\n",
    "# TO-DO si son números divide para normalizar (divide por valor máximo)\n",
    "\n",
    "# En keras pon capa de salida para problemas de multiclasifiación, los paso a cetegorical\n",
    "# y_train = to_categorical(x_train, num_classes=600) #nos vuelve valor numérico en array ordenado donde se activa la neurona que corresponde con respuesta\n",
    "# y_test = to_categorical(y_test, num_classes=600)\n",
    "# to_one_hot # de pandas\n",
    "# TO-DO dividir a parte de test y entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1611eb7b",
   "metadata": {},
   "source": [
    "Aquí es conveniente definir una función que a partir de un conjunto, pueda devolvernos las cadenas de título, abstract y palabras clave debidamente separadas en sus palabras. De esta forma se pueden sacar las palabras del conjunto de entrenamiento, test y cualquier conjunto futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c7d46cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extraerPalabrasDelConjunto (x_train, listaPalabras):\n",
    "    listaTitlesTemp = x_train.title.tolist() # Listarlos\n",
    "    listaTitlesPorArticulo = [] # Con esto sabemos cuales son de cada artículo\n",
    "    listaTitles = [] # Con esto los pasamos a una lista de 1 nivel\n",
    "  \n",
    "    listaAbstractsTemp = x_train.abstract.tolist() # Listarlos\n",
    "    listaAbstractsPorArticulo = [] # Con esto sabemos cuales son de cada artículo\n",
    "    listaAbstracts = [] # Con esto los pasamos a una lista de 1 nivel\n",
    "\n",
    "    listaKeywordsTemp = x_train.keywords.tolist() # Listarlos\n",
    "    listaKeywordsPorArticulo = [] # Con esto sabemos cuales son de cada artículo\n",
    "    listaKeywords = [] # Con esto los pasamos a una lista de 1 nivel    \n",
    "\n",
    "    for valor in listaKeywordsTemp:\n",
    "        #chunks = valor.split(',')\n",
    "        chunks = re.split(',[ ]*',valor) # Son separados por comas, pero ignoramos los espacios antes de dichos tags\n",
    "        listaKeywordsPorArticulo.append(chunks)\n",
    "        for chunk in chunks:\n",
    "            listaKeywords.append(chunk)\n",
    "            listaPalabras.append(chunk)\n",
    "        \n",
    "    for valor in listaAbstractsTemp:\n",
    "        chunks = re.split('[^a-zA-Z0-9]+',valor) # separo dejando solo caracteres normales\n",
    "        listaAbstractsPorArticulo.append(chunks)\n",
    "        for chunk in chunks:\n",
    "            listaAbstracts.append(chunk)\n",
    "            listaPalabras.append(chunk)\n",
    "        \n",
    "    for valor in listaTitlesTemp:\n",
    "        chunks = re.split('[^a-zA-Z0-9]+',valor)\n",
    "        listaTitlesPorArticulo.append(chunks)\n",
    "        for chunk in chunks:\n",
    "            listaTitles.append(chunk)\n",
    "            listaPalabras.append(chunk)\n",
    "            \n",
    "    return listaTitlesPorArticulo, listaTitles, listaAbstractsPorArticulo, listaAbstracts, listaKeywordsPorArticulo, listaKeywords, listaPalabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf679b04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77870\n",
      "69991\n",
      "7879\n"
     ]
    }
   ],
   "source": [
    "# Verifico que me sale lo mismo\n",
    "listaPalabrasTotal = []\n",
    "listaTitlesTotalPorArticulo, listaTotalTitles, listaTotalAbstractsPorArticulo, listaTotalAbstracts, listaTotalKeywordsPorArticulo, listaTotalKeywords, listaPalabrasTotal = extraerPalabrasDelConjunto (x_dataframe, listaPalabrasTotal)\n",
    "print(len(listaPalabrasTotal))\n",
    "\n",
    "listaPalabrasTrain = []\n",
    "listaTitlesPorArticulo, listaTitles, listaAbstractsPorArticulo, listaAbstracts, listaKeywordsPorArticulo, listaKeywords, listaPalabrasEntrena = extraerPalabrasDelConjunto (x_train, listaPalabrasTrain)\n",
    "print(len(listaPalabrasEntrena))\n",
    "listaPalabrasTest = []\n",
    "listaTestTitlesPorArticulo, listaTestTitles, listaTestAbstractsPorArticulo, listaTestAbstracts, listaTestKeywordsPorArticulo, listaTestKeywords, listaPalabrasTest = extraerPalabrasDelConjunto (x_test, listaPalabrasTest)\n",
    "print(len(listaPalabrasTest))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b94cc0",
   "metadata": {},
   "source": [
    "Es ahora cuando generamos una traducción de palabras obtenidas a valores que una red neuronal pueda entender, es decir, números.\n",
    "\n",
    "El primer paso consiste en ordenar y quitarnos de en medio términos repetidos. Es posible que el utilizar mayúsculas en vez de minúsculas sea un diferenciador importante, por lo que términos con mismas letras pero capitalizados de forma diferente tengan un matiz de significado interesante.\n",
    "\n",
    "También resulta interesante hacer lo mismo para las keywords obtenidas, así sabemos las dimensiones de salida más tarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c81a68a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9727\n",
      "['', '0', '000', '0003', '01', '04', '05', '06', '09', '1', '10', '100', '1000', '100s', '101', '104', '106', '108', '109', '11', '116', '12', '120', '123', '13', '130', '14', '15', '153600', '16', '160', '1635', '17', '178', '18', '1833', '1874', '19', '1915', '1H', '2', '2-dim distance measure', '20', '2004', '2006', '2007', '2009', '2010', '2011', '2012', '2013', '2015', '2016', '2017', '2099', '21', '211', '216', '22', '23', '24', '243', '25', '250', '2586', '26', '27', '28', '29', '2D', '2d:4d', '2v1', '2v2', '3', '30', '31', '31m', '33', '34', '35', '3521', '36', '37', '39', '3960', '3d', '3D', '3d shapes', '3d-convnets', '3MW', '4', '40', '41', '410', '412', '42', '43', '44160', '47', '49', '4D', '4th', '5', '50', '500', '5000', '53', '54', '55', '56', '563', '59', '6', '60', '61', '63', '65', '67', '68', '7', '70', '72', '74', '75', '76', '77', '78', '79', '8', '80', '800', '81', '82', '83', '85', '86', '87', '88', '89', '9', '90', '901', '91', '92', '93', '94', '95', '97', '98', '99', 'A', 'a', 'A2', 'AAL', 'AAPL', 'abbreviations', 'ABC', 'abdominal', 'Abdominal', 'Abductive', 'abilities', 'ability', 'Ability', 'able', 'Abnormal', 'abnormal', 'abnormal event detection', 'abound', 'about', 'above', 'ABP', 'absence', 'absent', 'Absolute', 'absolute', 'abstraction', 'Abstraction', 'abstractions', 'abundance', 'abundant', 'ACA', 'academia', 'academic', 'Academic', 'academic success', 'acapella', 'accelerate', 'Accelerated', 'accelerates', 'accelerating', 'acceleration', 'accelerometer', 'Accelerometer', 'accelerometer data', 'accelerometers', 'acceptable', 'acceptance', 'Acceptance', 'accepting', 'access', 'Access', 'accessible', 'accessing', 'accession', 'Accident', 'accident', 'accidents', 'accommodate', 'accompanying', 'accomplish', 'accomplished', 'accorded', 'according', 'According', 'accordingly', 'Account', 'account', 'accounting', 'Accounting', 'accounts', 'Accounts', 'accreditation', 'accreditation and assesments', 'accumulate', 'accumulator', 'accuracies', 'accuractely', 'Accuracy', 'accuracy', 'accurate', 'Accurate', 'accurately', 'ACF', 'achievable', 'achieve', 'achieved', 'achievement', 'Achievement', 'achievements', 'Achievements', 'achievements information', 'achieves', 'achieving', 'acid', 'acids', 'acoustic', 'Acoustic', 'acoustic feature learning', 'acquire', 'acquired', 'Acquiring', 'acquiring', 'Acquisition', 'acquisition', 'across', 'action', 'Action', 'action bank features', 'actionable', 'Actions', 'actions', 'activation', 'activation function', 'activations', 'active', 'Active', 'active contour method', 'active learning', 'active set shrinking', 'actively', 'Activities', 'activities', 'activity', 'Activity', 'activity detection', 'activity forecasting', 'activity recognition', 'actual', 'actually', 'actuation', 'acute', 'Acute', 'acyclic', 'Acyclic', 'Adaboost', 'ADAGRAD', 'adapt', 'adaptable', 'adaptation', 'Adaptation', 'adaptation method', 'adaptation models', 'adaptations', 'adapted', 'adapting', 'Adaptive', 'adaptive', 'adaptive approaches', 'adaptive learning', 'adaptive scheduling', 'adaptive threshold', 'adaptively', 'Adaptively', 'adapts', 'Adatron', 'add', 'Added', 'added', 'Adding', 'adding', 'addition', 'Addition', 'additional', 'Additionally', 'additionally', 'address', 'Address', 'addressed', 'addresses', 'addressing', 'adds', 'Adenoviral', 'adenoviral conjunctivitis (pink eye)', 'adequate', 'adequately', 'adjacent', 'adjust', 'adjusted', 'adjustment', 'Adjustment', 'adjustments', 'Administration', 'administrators', 'Administrators', 'admission', 'Admission', 'admitted', 'ADMM', 'adolescent', 'adolescents', 'adopt', 'adopted', 'Adopted', 'adopting', 'adopts', 'adult', 'advance', 'Advanced', 'advanced', 'advancement', 'advancements', 'advances', 'Advances', 'advantage', 'advantages', 'Adventure', 'adversarial', 'Adversarial', 'adversarial machine learning', 'adversaries', 'adversary', 'adverse', 'advertising', 'advice', 'advise', 'AF', 'affect', 'affected', 'affecting', 'affective', 'affects', 'Affinity', 'affordability', 'affordable', 'afforded', 'affords', 'afingerprint', 'afis', 'aforementioned', 'after', 'After', 'afterstate', 'Afterward', 'Afterwards', 'again', 'against', 'age', 'Age', 'aged', 'agencies', 'agent', 'Agent', 'agents', 'ages', 'agglomerations', 'agglomerative', 'aggregate', 'Aggregate', 'aggregated', 'Aggregated', 'aggregated netflows', 'aggregates', 'aggregating', 'aggregation', 'Aggregation', 'aggregator', 'aggression', 'Aggressive', 'agricultural', 'agriculture', 'Ahead', 'ahead', 'AHTD', 'AI', 'AIC', 'aid', 'aided', 'aiding', 'aids', 'ailments', 'aim', 'Aim', 'aimed', 'aiming', 'aims', 'air', 'Air', 'air combat', 'aircraft', 'Akaike', 'al', 'Alamos', 'alarm', 'Alarm', 'alarmingly', 'alarms', 'Alarms', 'alerts', 'Alfortville', 'algebraic', 'Algorithm', 'algorithm', 'algorithm design and analysis', 'algorithm recognition', 'algorithm selection', 'algorithmic', 'Algorithms', 'algorithms', 'alicious', 'align', 'Aligned', 'aligned', 'Aligning', 'alignment', 'Alignment', 'alignments', 'All', 'all', 'alleviating', 'AllMusic', 'Allocation', 'allocation', 'allocations', 'allow', 'allowed', 'allowing', 'allows', 'almost', 'alone', 'along', 'already', 'also', 'Also', 'alter', 'altering', 'alternate', 'Alternating', 'alternative', 'alternatives', 'Although', 'although', 'always', 'Always', 'Alzheimer', \"alzheimer's disease\", \"alzheimer's disease stage detection\", 'Amazon', 'ambient', 'Ambient', 'ambulatory', 'America', 'American', 'american sign language', 'amino', 'Among', 'among', 'amount', 'amounts', 'Amphiphilic', 'amplification', 'amplitude', 'an', 'An', 'anaemia', 'analogue', 'analyse', 'analysed', 'Analyses', 'analyses', 'analysis', 'Analysis', 'analytic', 'analytical', 'analytics', 'Analytics', 'analyze', 'analyzed', 'Analyzer', 'analyzer', 'analyzes', 'Analyzing', 'analyzing', 'anatomical', 'anatomy', 'anchored', 'anchored synchronization', 'AND', 'and', 'And', 'android', 'Android', 'Anemia', 'anemia', 'angels', 'angle', 'angles', 'animal', 'ANN', 'annotated', 'annotations', 'Annotations', 'annoyance', 'anns', 'ANNs', 'annual', 'anomalies', 'anomalous', 'Anomaly', 'anomaly', 'anomaly detection', 'anomaly prediction', 'anonymity', 'anonymization', 'anonymized', 'anonymizing', 'anonymous', 'another', 'Another', 'ANOVA', 'answer', 'answered', 'ANT', 'ant colony optimization', 'antecedent', 'Antecedent', 'anti', 'anticipated', 'antivirus', 'anxiety', 'Anxiety', 'Any', 'any', 'anytime', 'Anytime', 'anytime algorithm', 'ap imashups', 'APACHE', 'APARF', 'aparments', 'apart', 'API', 'APIs', 'Apnea', 'apnea', 'App', 'appear', 'Appearance', 'appearance', 'appearance-based learning', 'appears', 'Appliance', 'appliance', 'appliances', 'applicability', 'applicable', 'applicants', 'Applicants', 'application', 'Application', 'application essay', 'application layer ddos', 'Applications', 'applications', 'applied', 'Applied', 'applies', 'apply', 'applying', 'Applying', 'appraised', 'appraisers', 'approach', 'Approach', 'approached', 'approaches', 'Approaches', 'appropriate', 'approximate', 'approximate computing', 'approximate inference', 'approximated', 'approximately', 'Approximately', 'approximates', 'approximating', 'Approximation', 'approXimation', 'approximation', 'approximation algorithms', 'approximation methods', 'approximations', 'approximator', 'Approximators', 'approximators', 'apps', 'Apps', 'Appstore', 'arbitrary', 'Archi', 'Architecture', 'architecture', 'architectures', 'archives', 'Arctic', 'arctic sea ice', 'Are', 'are', 'Area', 'area', 'areas', 'arenas', 'arguably', 'argue', 'argued', 'Argument', 'arguments', 'arid', 'Arid', 'arima', 'ARIMA', 'arise', 'arises', 'arising', 'Arising', 'arm', 'arma', 'ARMA', 'armed', 'arms', 'arose', 'around', 'Array', 'Arrhythmia', 'arrhythmias', 'arrival', 'arrivals', 'arrive', 'arriving', 'ARSpread', 'art', 'arterial', 'article', 'articles', 'artifact', 'Artifact', 'artifacts', 'artifial neural network model', 'artificial', 'Artificial', 'artificial defects', 'artificial intelligence', 'artificial neural network', 'artificial neural network (ann)', 'artificial neural networks', 'artificial-neural-network', 'artificially', 'artist', 'Artist', 'ARTL', 'as', 'As', 'Ascending', 'ascertain', 'ASD', 'ask', 'aspect', 'aspects', 'ASR', 'assembling', 'asses', 'assess', 'assessed', 'assesses', 'Assessing', 'assessment', 'Assessment', 'asset', 'assets', 'assign', 'assigned', 'assigning', 'assignment', 'assigns', 'assist', 'assisted', 'Assisted', 'assisting', 'associated', 'Association', 'association', 'association map', 'association rules', 'associative', 'associative classification', 'associative memory', 'associatively', 'assume', 'assumed', 'assumes', 'assuming', 'assumption', 'assumptions', 'Assurance', 'assuring', 'Asthma', 'Astroturf', 'At', 'at', 'Atlas', 'atlas', 'Atlases', 'atlases', 'atmospheric', 'Atmospheric', 'ATMS', 'attach', 'Attack', 'attack', 'Attackers', 'attackers', 'attacking', 'Attacks', 'attacks', 'attain', 'attained', 'attaining', 'attainment', 'attains', 'attempt', 'attempts', 'attention', 'attentions', 'attracted', 'attractive', 'Attribute', 'attribute', 'Attributes', 'attributes', 'ATTs', 'AUC', 'Auction', 'auction', 'auctions', 'audio', 'Audio', 'audio captcha', 'audio equalizer', 'audio signal', 'audiogram', 'auditory', 'augment', 'augmentation', 'Augmented', 'augmented', 'augmenting', 'Augmenting', 'August', 'aurally', 'Australia', 'Authentication', 'authentication', 'authentication graphs', 'Authentications', 'author', 'author classification', 'authoring', 'authoritative', 'authority', 'authors', 'authorship', 'autism', 'Autism', 'autism spectrum disorder', 'Auto', 'auto', 'Autocorrelation', 'autocorrelation-function-(acf)', 'autoencod', 'autoencoder', 'Autoencoder', 'Autoencoders', 'autoencoders', 'automate', 'Automated', 'automated', 'automated classification', 'automates', 'Automatic', 'automatic', 'automatic diagnosis', 'automatic gender estimation', 'automatic scoring', 'automatic speech recognition', 'automatically', 'Automatically', 'Automating', 'automating', 'automation', 'automobiles', 'Automotive', 'automotive security', 'autonomous', 'autonomously', 'Autoregressive', 'autoregressive', 'autoregressive processes', 'Auxiliary', 'auxiliary', 'auxiliary objectives', 'AV', 'availabilities', 'availability', 'available', 'avenue', 'Average', 'average', 'averaged', 'averages', 'averaging', 'avoid', 'avoided', 'aware', 'Aware', 'awareness', 'Awareness', 'away', 'axis', 'B', 'b', 'back', 'Back', 'back-propagation-algorithm', 'Backblaze', 'background', 'Background', 'backpropagation', 'bacteria', 'bacterial', 'bad', 'badminton', 'Badminton', 'Bag', 'bag', 'bag-of-concepts', 'bag-of-pattern', 'Bagged', 'bagging', 'Bagging', 'Bags', 'bags', 'balance', 'balanced', 'Balanced', 'balanced k-means', 'balances', 'balancing', 'ball', 'Ballistocardiogram', 'ballistocardiogram artifact', 'Baltimore', 'Band', 'Bandit', 'bandit', 'bands', 'bandwidth', 'bank', 'banks', 'bare', 'barrier', 'Bartlett', 'bartlett tests', 'BAS', 'base', 'Base', 'base station (bs)', 'Based', 'based', 'baseline', 'baselines', 'bases', 'basic', 'Basis', 'basis', 'basis selection', 'batch', 'batches', 'batteries', 'battery', 'Baum', 'Bayes', 'bayes classifier', 'bayes methods', 'bayesian', 'Bayesian', 'bayesian analysis', 'bayesian classification', 'bayesian inference', 'bayesian network', 'bayesian networks', 'bayesian nonparametrics', 'bayesian-networks', 'BBC', 'BCI', 'be', 'Bearing', 'bearing defects', 'bearings', 'became', 'because', 'Because', 'become', 'becomes', 'becoming', 'bedrooms', 'bedside', 'been', 'before', 'befriend', 'began', 'beginning', 'begins', 'behave', 'Behavior', 'behavior', 'Behavioral', 'behavioral', 'Behaviors', 'behaviors', 'behaviour', 'Behaviours', 'behind', 'being', 'Being', 'belief', 'beliefs', 'believe', 'Bellman', 'Bellmans', 'belong', 'belonging', 'belongs', 'benchmark', 'Benchmark', 'Benchmarking', 'benchmarks', 'beneficial', 'benefit', 'benefits', 'benign', 'Berkeley', 'Bernoulli', 'Besides', 'best', 'Best', 'best subset linear regression', 'Better', 'better', 'Between', 'between', 'betweens', 'beyond', 'BF', 'BG', 'BHPMF', 'bias', 'biased', 'biases', 'BIC', 'bidder', 'bidders', 'bidding', 'bidiagonalization', 'bids', 'bifurcation', 'Big', 'big', 'big data', 'big data analytics', 'big data clustering', 'big healthcare data', 'big mobile social data', 'big-data', 'biggest', 'BIH', 'bike', 'bilateral filter', 'bilevel', 'Bilevel', 'bilinear', 'billions', 'bimodal', 'bin', 'binarization', 'binary', 'Binary', 'binary classification', 'binary codes', 'Binding', 'binding', 'bins', 'bio', 'bio-acoustics', 'bio-detection', 'bioinformatics', 'Bioinformatics', 'biological', 'Biological', 'biological neural networks', 'biological system modeling', 'biology', 'biomarker', 'biomarkers', 'biomedical informatics', 'biometric', 'Biometric', 'biometric recognition', 'biometrics', 'Biometry', 'biopsy', 'Bipartite', 'bipartite', 'bipartite graphs', 'bipartite ranking problem', 'bird', 'Bird', 'bird call identification', 'birds', 'Birdsong', 'birdsong', 'birth', 'Bit', 'bitcoin', 'Bitcoin', 'Bitcoins', 'bits', 'black', 'black-box testing', 'blackout', 'blade', 'bleeding', 'blends', 'blind', 'blind source seperation', 'blindness', 'blobs', 'Block', 'block', 'Blockchain', 'blockchain', 'blocks', 'blog spam', 'blogs', 'blood', 'Blood', 'BLPCA', 'BLSTM', 'blunder', 'BN', 'BNP', 'board', 'BoB', 'BOC', 'Body', 'body', 'Boltzmann', 'bone', 'bookings', 'Boolean', 'boolean networks', 'boost', 'Boosted', 'boosted', 'boosting', 'Boosting', 'bootstrap', 'bootstrap approaches', 'Bootstrapping', 'bootstrapping', 'BoP', 'border', 'borders', 'borrowing', 'bot', 'both', 'Both', 'botnets', 'bots', 'bottlenecks', 'bottom', 'bound', 'boundaries', 'boundary', 'boundary value problems', 'bounded', 'Bounded', 'bounding', 'bounds', 'BOW', 'box', 'Box', 'box office', 'boxes', 'BP', 'Brace', 'brace', 'brace treatment', 'Brain', 'brain', 'brain computer interface', 'Brains', 'brains', 'braking', 'branch', 'branches', 'branching', 'Brand', 'brand', 'brand perception', 'brands', 'breach', 'break', 'BreakFast', 'Breaking', 'breaking', 'breaking news', 'breast', 'Breast', 'breast cancer', 'breathing', 'breeding', 'Bregman', 'bridges', 'brief', 'brightness', 'bring', 'brings', 'broad', 'broadcast', 'broadcasting', 'broken', 'brought', 'Brown', 'browser', 'browsing', 'Brute', 'brute', 'brute force', 'BSO', 'bubbled', 'bucket', 'budget', 'budgeted', 'Budgeted', 'budgeted learning', 'budgets', 'build', 'building', 'Building', 'Buildings', 'buildings', 'Builds', 'builds', 'built', 'Built', 'burden', 'burdensome', 'Bus', 'bus', 'bus transportation', 'business', 'businesses', 'busted', 'But', 'but', 'buyers', 'buying', 'BW', 'by', 'By', 'bypass', 'byte', 'c', 'C', 'c++ languages', 'C4', 'cache', 'Caches', 'caching', 'Caching', 'CAD', 'Cagman', 'calculate', 'calculated', 'calculates', 'calculating', 'Calculation', 'calculation', 'calculations', 'calculus', 'calibrate', 'calibrated', 'Calibration', 'calibration', 'California', 'call', 'Call', 'called', 'calls', 'Caltech', 'camera', 'cameras', 'campaigns', 'campus', 'CAN', 'Can', 'can', 'can bus', 'Canada', 'canal', 'Canal', 'canal command', 'Cancer', 'cancer', 'cancer detection', 'cancerous', 'candidate', 'candidates', 'cannot', 'canonical', 'Canonical', 'canonical correlation analysis', 'Canopy', 'canopy algorithm', 'capabilities', 'capability', 'capable', 'capacity', 'capella', 'CAPTCHA', 'CAPTCHAs', 'capture', 'captured', 'captures', 'capturing', 'car', 'Car', 'car following model', 'carbon', 'Carbon', 'card', 'Card', 'cardiac', 'cardinality', 'Care', 'care', 'career', 'careerbuilder', 'CareerBuilder', 'careers', 'carefully', 'caregivers', 'Carlo', 'Carnegie', 'carried', 'carry', 'carrying', 'cars', 'Cartesian', 'cartesian', 'Carthagene', 'carving', 'cascaded', 'Cascaded', 'cascaded sparse autoencoders', 'cascading style sheets', 'case', 'Case', 'case management', 'case-based reasoning', 'caseload', 'cases', 'Cases', 'caseworkers', 'CAST', 'catalyst', 'catastrophe', 'catastrophic', 'categorical', 'categories', 'categorise', 'categorization', 'categorized', 'category', 'Causal', 'causal', 'causal discovery', 'Causality', 'causality', 'Causation', 'cause', 'caused', 'causes', 'causing', 'CBR', 'CCA', 'CCD', 'CCQ', 'CD', 'CDFTSVM', 'CDK', 'celebrated', 'Celerity', 'cell', 'Cell', 'cell images', 'cells', 'cellular', 'cember', 'center', 'Center', 'centerbased', 'Centered', 'centers', 'central', 'Central', 'centric', 'Centric', 'Centroid', 'centroids', 'CEP', 'Cepstral', 'cepstral', 'cepstral coefficients', 'certain', 'Certainly', 'CF', 'CFRP', 'cfrp', 'CGP', 'cgp', 'CGPANN', 'cgpann', 'chain', 'Chain', 'Challenge', 'challenge', 'challenges', 'challenging', 'Challenging', 'challenging behaviors', 'chance', 'Change', 'change', 'changed', 'changes', 'Changes', 'changing', 'channel', 'Channel', 'channels', 'chaotic', 'character', 'Character', 'characterisation', 'characteristic', 'characteristics', 'Characteristics', 'characterization', 'characterize', 'characterized', 'characterizing', 'charge', 'chart', 'chatting', 'cheaper', 'check', 'checked', 'checking', 'Chelsea', 'Chemical', 'chemical', 'Chennai', 'chess', 'Chess', 'Chi', 'Chicago', 'child', 'Child', 'child support', 'children', 'Chinese', 'chips', 'Chisini', 'choice', 'choices', 'choose', 'choosing', 'Chord', 'chord', 'chosen', 'Chronic', 'chronic', 'chronically', 'chronological', 'churn', 'Churn', 'churn prediction', 'CIFAR', 'circuit', 'circular', 'circulation', 'circumstances', 'circumvent', 'cite', 'cities', 'Cities', 'citizens', 'City', 'city', 'CL', 'claim', 'claimant', 'claims', 'Claims', 'clamp', 'clamped', 'class', 'Class', 'class decomposition', 'class imbalance', 'classes', 'classic', 'Classical', 'classical', 'Classification', 'classification', 'classification algorithms', 'classification techniques', 'classifications', 'classified', 'Classifier', 'classifier', 'classifier ensemble', 'Classifiers', 'classifiers', 'classifies', 'Classify', 'classify', 'Classifying', 'classifying', 'clauses', 'CLE', 'clean', 'cleaned', 'cleaning', 'clear', 'clearances', 'clearer', 'clearly', 'clicking', 'clients', 'climate', 'Climate', 'climate science', 'climatic', 'climbing', 'clinical', 'Clinical', 'clinicians', 'clips', 'clnn', 'CLNN', 'CLO', 'clo', 'clone', 'Clone', 'clone refactoring', 'CLOs', 'close', 'Close', 'closed', 'closely', 'closer', 'closures', 'cloud', 'Cloud', 'cloud computing', 'cloud data security', 'cloud-oriented architecture', 'clouds', 'CLP', 'CLUE', 'cluster', 'Cluster', 'cluster analysis', 'cluster data', 'cluster forest', 'cluster head (ch)', 'cluster size distribution', 'cluster validation', 'cluster validity', 'clustered', 'clustering', 'Clustering', 'clustering algorithms', 'Clusters', 'clusters', 'Clutter', 'clutter', 'cm', 'CM', 'cm-knn', 'CMA', 'cma-es', 'CMU', 'cnn', 'CNN', 'CNNs', 'co', 'coarse', 'coauthorship', 'Code', 'code', 'codebases', 'coded', 'Codes', 'codes', 'CoDis', 'coefficient', 'Coefficient', 'coefficients', 'Coefficients', 'cognitive', 'coherency', 'Coherent', 'coherent', 'coherently', 'cohesive', 'Cohorts', 'cohorts', 'coil', 'cold', 'cold-start problem', 'collaborate', 'collaboration', 'Collaboration', 'collaboration network', 'collaborative', 'Collaborative', 'collaborative filtering', 'collaborative learning', 'collaborative recommendation', 'collect', 'collected', 'collecting', 'Collection', 'collection', 'collections', 'collective', 'Collective', 'collector apis', 'collects', 'Colleges', 'collision', 'Colombia', 'color', 'Colorization', 'colorization', 'Coloured', 'coloured petri nets', 'com', 'Combat', 'combat', 'Combating', 'combination', 'Combination', 'combination forgery', 'combinations', 'combinatorial', 'combinatorial optimization', 'combinatorial reverse auctions', 'combine', 'combined', 'Combined', 'combiner', 'Combiner', 'combines', 'combining', 'Combining', 'come', 'comes', 'comfirms', 'comfort', 'Comfort', 'coming', 'command', 'Command', 'commands', 'Commands', 'Comment', 'comment', 'comment features', 'comment spam detection', 'Commentary', 'comments', 'commerce', 'Commerce', 'commercial', 'commercialized', 'commercially', 'commodity', 'Common', 'common', 'common metric learning', 'commonly', 'commonplace', 'communicate', 'Communication', 'communication', 'communications', 'communities', 'community', 'Community', 'commutating', 'compactness', 'compactness measure of clusters', 'companies', 'Company', 'company', 'comparable', 'Comparative', 'comparative', 'comparative market analysis', 'comparative study', 'comparatively', 'compare', 'Compared', 'compared', 'compares', 'comparing', 'Comparing', 'comparison', 'Comparison', 'comparisons', 'Compatibility', 'compatibility', 'compatible', 'competent', 'competing', 'competition', 'competitions', 'competitive', 'competitiveness', 'compiler', 'compilers', 'complete', 'completed', 'completely', 'completeness', 'Completeness', 'completion', 'Completion', 'complex', 'Complex', 'complex event programming', 'complexities', 'complexity', 'Complexity', 'complexity reduction', 'compliance', 'compliant', 'complicated', 'complication', 'complications', 'component', 'Component', 'component based design petri nets', 'Components', 'components', 'composed', 'composers', 'composing', 'composition', 'compound', 'compounded', 'compounds', 'comprehend', 'comprehension', 'comprehensive', 'comprehensively', 'compressed', 'compression', 'compression algorithms', 'comprised', 'comprises', 'comprising', 'compromise', 'compromised', 'compromising', 'Computation', 'computation', 'Computational', 'computational', 'computational modeling', 'computationally', 'computations', 'compute', 'computed', 'Computed', 'computer', 'Computer', 'computer crime', 'computer generated forces', 'computer science', 'computer vision', 'computer-aided detection (cad)', 'computer-aided diagnosis', 'computers', 'computes', 'Computing', 'computing', 'concatenating', 'concentrate', 'concentrates', 'concentration', 'concept', 'Concept', 'conception', 'Concepts', 'concepts', 'Conceptual', 'conceptualization', 'conceptually', 'concern', 'concerned', 'concerning', 'conclude', 'concluded', 'Conclusion', 'conclusion', 'conclusions', 'concurrent', 'condition', 'Condition', 'Conditional', 'conditional', 'ConditionaL', 'conditional neural networks', 'conditional restricted boltzmann machine', 'Conditioning', 'conditioning', 'conditions', 'Conditions', 'conduct', 'conducted', 'conducting', 'cone', 'conferences', 'Confidence', 'confidence', 'confidence region', 'confident', 'Configuration', 'configuration', 'configurations', 'configure', 'configuring', 'Configuring', 'confirm', 'confirmed', 'conflating', 'conflicting', 'conformal', 'Conformal', 'conformal prediction', 'conformalized', 'Conformalized', 'Conformation', 'conformation', 'conformation motion', 'conformations', 'confronting', 'confusion matrix', 'congested', 'congestion', 'conjecture', 'conjugate', 'conjunction', 'conjunctivitis', 'Conjunctivitis', 'connect', 'connected', 'Connected', 'connected vehicles', 'connection', 'connections', 'connectivities', 'connectivity', 'Connects', 'conquer', 'consciousness', 'consecutive', 'Consensus', 'consensus', 'consequence', 'consequences', 'consequent', 'consequently', 'Consequently', 'conservation', 'consider', 'Consider', 'considerable', 'considerably', 'consideration', 'considered', 'Considering', 'considering', 'considers', 'consist', 'consisted', 'consistency', 'consistent', 'consistently', 'Consistently', 'consisting', 'consists', 'consolidate', 'consolidation', 'Consortium', 'Constant', 'constant', 'constituent', 'constitutes', 'Constrained', 'constrained', 'Constraint', 'constraint', 'constraint programming', 'constraint satisfaction problem', 'constraints', 'Constraints', 'construct', 'constructed', 'Constructed', 'constructing', 'Constructing', 'construction', 'constructive', 'constructs', 'consume', 'consumed', 'Consumer', 'consumer', 'consumers', 'consumes', 'consuming', 'Consumption', 'consumption', 'contacted', 'contagious', 'contain', 'contained', 'containing', 'contains', 'contaminant', 'contemporary', 'content', 'Content', 'content caching', 'content spam', 'contents', 'context', 'Context', 'context aware', 'contexts', 'Contextual', 'contextual similarity', 'Continental', 'continental', 'continue', 'continues', 'continuing', 'continuous', 'Continuous', 'continuously', 'Contour', 'contour', 'contour recognition', 'contour representations', 'contours', 'Contours', 'contracted', 'contracts', 'contrary', 'contrast', 'contrasting', 'Contrastive', 'contrasts', 'contribute', 'contributes', 'contributing', 'Contribution', 'contribution', 'contributions', 'contributor', 'control', 'Control', 'control period computational burden', 'control system', 'control systems', 'Controlled', 'controlled', 'Controller', 'controller', 'controllers', 'controlling', 'controls', 'controversial', 'convenience', 'convenient', 'conventional', 'convergence', 'convergent', 'converges', 'converging', 'conversions', 'convert', 'converted', 'Converter', 'converter', 'converters', 'Converters', 'Convex', 'convex', 'convexity', 'ConvNet', 'convoluted', 'convolution', 'convolution filtering', 'Convolutional', 'convolutional', 'convolutional neural nets', 'convolutional neural network', 'convolutional neural networks', 'convolutional neural networks (cnn)', 'convolutional neural networks (cnns)', 'coooperative', 'cooperated', 'Cooperation', 'cooperation', 'cooperative', 'Cooperative', 'cooperative adaptive cruise control', 'cooperative systems', 'Coordinate', 'coordinate', 'coordinate descent', 'coordinated', 'coordinates', 'cope', 'copies', 'copious', 'copy', 'core', 'Core', 'coreference', 'Coreference', 'coreferent', 'Corneal', 'corneal', 'corner', 'corpora', 'Corpora', 'corporate', 'corpses', 'corpus', 'correct', 'correction', 'corrections', 'correctly', 'correctness', 'correlate', 'correlated', 'Correlated', 'Correlating', 'correlating', 'Correlation', 'correlation', 'correlations', 'correspond', 'corresponding', 'corresponds', 'cortex', 'Cosine', 'cost', 'Cost', 'cost sensitive classification', 'cost-sensitive learning', 'costly', 'costs', 'could', 'couldn', 'Count', 'Counter', 'countermeasure', 'countermeasures', 'counterpart', 'counterparts', 'counters', 'counties', 'countries', 'country', 'counts', 'coupled', 'Coupled', 'coupling', 'couplings', 'course', 'Course', 'Covariance', 'covariance', 'covariance matrix', 'covariates', 'cover', 'coverability', 'coverage', 'covered', 'covers', 'cpd', 'CPD', 'CPLM', 'CPU', 'crafted', 'crafting', 'crawlers', 'crbm', 'create', 'created', 'creates', 'creating', 'creation', 'credible', 'Credible', 'Credit', 'credit', 'credit default swap', 'credit scoring', 'Crescendo', 'CRF', 'CRFs', 'crime', 'crime prediction', 'criminal', 'crises', 'crisis', 'criteria', 'Criterion', 'criterion', 'critical', 'Critical', 'criticality', 'critically', 'criticized', 'crop', 'crops', 'Cross', 'cross', 'cross lingual', 'cross-validation', 'crosses', 'crossing', 'Crossing', 'crosslingual', 'crowd', 'crowd-sourcing', 'crowdsourcing', 'Crowdsourcing', 'crucial', 'Crude', 'crude', 'crude oil price forecasting', 'cruise', 'cruise control', 'cryptocurrency', 'CS1', 'CSI', 'CSP', 'CT', 'ct images', 'ct prediction', 'cube', 'Cuckoo', 'cue', 'cues', 'culture', 'cumbersome', 'cumulative', 'Cup', 'cure', 'curiosity', 'currency', 'Current', 'current', 'currently', 'Currently', 'Curriculum', 'curse', 'curvature', 'Curvature', 'Curve', 'curve', 'curve simplification', 'curves', 'custodial', 'custom', 'customer', 'customers', 'customize', 'customized', 'cuts', 'CWT', 'cwt', 'cyber', 'Cyber', 'cyber forensic', 'cyber security', 'cyber-security vulnerabilities', 'cyberattack', 'Cyberattack', 'cyberattacks', 'Cyberattacks', 'Cybersecurity', 'cybersecurity', 'cybersecurity applications', 'Cycle', 'Cyclic', 'cyclic contrastive divergence learning', 'cycling', 'cylinder', 'cytoskeleton', 'Czech', 'czech ner', 'd', 'D', 'DAG', 'daily', 'Daily', 'Dalvik', 'dam', 'Dam', 'Damage', 'damage', 'damaged', 'damages', 'damp', 'Dams', 'danger', 'dangerous', 'darker', 'DARPA', 'dasgupta13', 'dashboards', 'data', 'Data', 'data analysis', 'data analytics', 'data augmentation', 'data clustering', 'data contamination', 'data diversity', 'data integration', 'data mining', 'data models', 'data modification intrusion detection', 'data privacy', 'data stream', 'data stream with concept drift', 'data warehouse', 'data-acquisition', 'data-driven', 'Database', 'database', 'databaselike', 'Databases', 'databases', 'datagrapple', 'Dataset', 'dataset', 'datasets', 'Datasets', 'DataStreams', 'date', 'dating', 'Day', 'day', 'days', 'dB', 'DB', 'DB1', 'DBLP', 'DBMS', 'DBMSs', 'dbn', 'dbpedia ontology', 'dc', 'DC', 'dc-dc converter', 'dc/dc-boost-converter', 'DCT', 'dct', 'DDC', 'DDoS', 'DDPG', 'de', 'De', 'deal', 'dealing', 'Dealing', 'deals', 'dealt', 'deaths', 'debates', 'Debates', 'decade', 'decades', 'Decaying', 'decaying', 'deceive', 'decent', 'Decentralized', 'decentralized', 'deception', 'Deceptive', 'deceptive', 'decide', 'decided', 'decidedly', 'decides', 'decision', 'Decision', 'decision making', 'decision support', 'decision support system', 'decision tree', 'decision trees', 'Decisions', 'decisions', 'declarative learning', 'decode', 'decoder', 'decoding', 'Decoding', 'decompose', 'decomposing', 'Decomposition', 'decomposition', 'decomposition-based reinforcement learning', 'decompositions', 'deconvolutional', 'deconvolutional networks (deconvnet)', 'Decorrelated', 'decorrelating', 'decorrelation', 'decrease', 'decreases', 'decreasing', 'dedicated', 'deemed', 'deep', 'Deep', 'deep convolutional network', 'deep learning', 'deep neural network', 'deep neural networks', 'deep regression model', 'deep reinforcement learning', 'deepening', 'Deepness', 'DeepPositioning', 'default', 'Defect', 'defect', 'Defects', 'defects', 'Defences', 'defend', 'defense', 'deficiencies', 'deficiency', 'deficient', 'define', 'defined', 'Defined', 'defines', 'defining', 'definitely', 'definition', 'deformations', 'degradation', 'degrade', 'degraded', 'degrades', 'Degree', 'degree', 'degrees', 'dehazing', 'delay', 'Delayed', 'delayed', 'delayed labels', 'delaying', 'delays', 'Delays', 'delimited', 'delineated', 'delivered', 'delivering', 'delivers', 'Delivery', 'delivery', 'Demand', 'demand', 'demand forecast', 'demands', 'Demographic', 'demographic', 'demographic group prediction', 'demographics', 'demonstrate', 'demonstrated', 'demonstrates', 'demonstrating', 'Demonstration', 'demonstration', 'dendrograms', 'Denial', 'denial-of-service (dos)', 'Denoising', 'denoising', 'dense', 'Dense', 'Densities', 'densities', 'density', 'Density', 'depend', 'dependable', 'dependence', 'dependencies', 'dependency', 'Dependency', 'Dependent', 'dependent', 'depending', 'depends', 'depicting', 'deploy', 'deployed', 'deploying', 'deployment', 'deploys', 'depot', 'depressed', 'depression', 'Depression', 'Depressive', 'depressive disorders', 'depth', 'deregulation', 'DERIV', 'derivation', 'derive', 'derived', 'deriving', 'Descending', 'Descent', 'descent', 'describe', 'described', 'describes', 'describing', 'description', 'Description', 'descriptions', 'descriptors', 'desensitization', 'desensitized', 'deserving', 'Design', 'design', 'designed', 'designer', 'designing', 'desirable', 'desired', 'despite', 'Despite', 'destabilize', 'destinations', 'DET', 'detail', 'detailed', 'Detailed', 'details', 'Detect', 'detect', 'detected', 'detecting', 'Detecting', 'Detection', 'detection', 'Detector', 'detector', 'detectors', 'detects', 'deteriorated', 'deterioration', 'determination', 'Determination', 'determine', 'determined', 'determines', 'determining', 'Determining', 'Deterministic', 'deterministic', 'detrimental', 'Detrimental', 'develop', 'developed', 'Developed', 'developers', 'Developers', 'Developing', 'developing', 'development', 'Development', 'developments', 'developping', 'develops', 'Deviance', 'deviates', 'deviation', 'deviations', 'device', 'Device', 'Devices', 'devices', 'devise', 'devised', 'devoted', 'Dewey', 'DEX', 'dh-hemts', 'Diabetes', 'diabetes', 'diabetic', 'Diabetic', 'diagnosability', 'diagnosabiliy', 'diagnose', 'diagnosed', 'diagnoser', 'diagnosing', 'diagnosis', 'Diagnosis', 'diagnostic', 'Diagnostics', 'diagnostics', 'diagram', 'diary', 'Dice', 'Dickey', 'dictated', 'dictionary', 'did', 'diet', 'Diet', 'differ', 'difference', 'Difference', 'differences', 'Different', 'different', 'Differential', 'differential', 'differentiated', 'Differentiation', 'differentiation', 'differently', 'differs', 'difficult', 'difficulties', 'difficulty', 'digit', 'Digit', 'digital', 'digitalize', 'digitalSTROM', 'digitized', 'digits', 'DIL', 'dilemma', 'dim', 'dimension', 'Dimension', 'Dimensional', 'dimensional', 'dimensional reduction', 'dimensionality', 'Dimensionality', 'dimensionality reduction', 'dimensioning', 'dimensions', 'Dimensions', 'Diminuendo', 'diodes', 'DIP', 'dips', 'direct', 'Direct', 'directed', 'Directed', 'Direction', 'direction', 'directions', 'directly', 'directs', 'Dirichlet', 'dirichlet process', 'disable', 'disabled', 'disadvantages', 'disaggregate', 'Disaggregation', 'disaggregation', 'disappear', 'disasters', 'discard', 'discarded', 'discarding', 'discern', 'disciplinary', 'discipline', 'disciplined', 'disclosure', 'discontinuous', 'discourse', 'discover', 'discovered', 'discovering', 'Discovering', 'discovery', 'Discovery', 'discrete', 'Discrete', 'discrete cosine transforms', 'discrete event systems', 'discrete fourier', 'discrete-event systems', 'discretization', 'discretize', 'discretizing', 'discriminant', 'Discriminant', 'discriminate', 'discriminates', 'discriminating', 'discrimination', 'Discrimination', 'discriminative', 'Discriminative', 'discriminatory', 'discs', 'discuss', 'discussed', 'discusses', 'discussion', 'Disease', 'disease', 'diseased', 'diseases', 'disjoint', 'disjunctive', 'Disorder', 'disorder', 'disorders', 'Disorders', 'disparate', 'disparity', 'dispatch', 'dispersed', 'Dispersion', 'dispersion', 'display', 'displays', 'disputed', 'disregarded', 'disruption', 'dissatisfaction', 'disseminate', 'dissemination', 'dissimilarity', 'Distance', 'distance', 'distances', 'distinct', 'distinctions', 'distinctive', 'distinctness', 'distinctness measure of clusters', 'distinguish', 'distinguished', 'distinguishing', 'distorted', 'distortion', 'distress', 'Distributable', 'distribute', 'Distributed', 'distributed', 'DistributEd', 'distributed computing', 'distributed data clustering', 'distributed sgd', 'distributed simulation', 'distribution', 'Distribution', 'distributions', 'Distributions', 'divergence', 'Divergence', 'diverse', 'diversification', 'diversifying', 'diversity', 'Diversity', 'divide', 'divided', 'dividing', 'division', 'Divisive', 'divisive', 'divisive analysis', 'DK', 'DL', 'DNK', 'DNN', 'dnn', 'DNNs', 'do', 'docetaxel', 'doctor', 'Document', 'document', 'document classification', 'documentation', 'documented', 'documents', 'Does', 'does', 'Doing', 'doing', 'dollars', 'DOM', 'Domain', 'domain', 'domain class imbalance', 'domain knowledge', 'domains', 'domestic', 'Domestic', 'domestic hot water', 'dominant', 'dominate', 'dominated', 'don', 'done', 'Donor', 'donor', 'donor selection', 'donors', 'dont', 'doors', 'DoS', 'dos attack', 'dot', 'Dot', 'doubles', 'Doubles', 'down', 'downscale', 'Downscaling', 'downscaling', 'downstairs', 'downstream', 'downtime', 'DP', 'DPFNN', 'DQN', 'drastically', 'draw', 'drawback', 'Drawbacks', 'drawing', 'Drawn', 'drawn', 'draws', 'DREAM4', 'drift', 'Drift', 'drifted', 'Drifting', 'drifting', 'drifts', 'drive', 'Drive', 'Driven', 'driven', 'driver', 'driver behavior', 'drivers', 'drives', 'driving', 'DRL', 'drop', 'drop out technique', 'dropout', 'Dropout', 'dropping', 'drought', 'drought modelling', 'drug', 'Drug', 'drug-design', 'drugs', 'DTNMF', 'DTSCluster', 'DTW', 'Dual', 'dual', 'DUC2002', 'Due', 'due', 'Duration', 'duration', 'durations', 'Durbin', 'During', 'during', 'DWT', 'dwt', 'Dynamic', 'dynamic', 'dynamic clustering', 'dynamic factor analysis', 'dynamic kernels', 'dynamic programming', 'dynamic system', 'dynamic web domain', 'dynamical', 'dynamical systems', 'dynamically', 'dynamicity', 'Dynamics', 'dynamics', 'e', 'e-commerce', 'EA', 'ea+rl', 'Each', 'each', 'Eager', 'earlier', 'Earlier', 'Early', 'early', 'earned', 'eart', 'Earth', 'earth', 'earth levee', 'ease', 'eases', 'easier', 'easily', 'easing', 'Eastern', 'easy', 'eating', 'Eating', 'Eazy', 'ECD', 'ecg', 'ECG', 'ECHMM', 'ECHMMs', 'Eclipse', 'ecognition', 'ecology', 'econometric', 'economic', 'economically', 'economy', 'ECU', 'Ecuador', 'ECUs', 'Edge', 'edge', 'edges', 'Edison', 'editors', 'EDL', 'EDLs', 'education', 'Education', 'educational', 'Educational', 'educational analytics', 'educational data mining', 'educational data mining (edm)', 'educational institutions', 'EEG', 'eeg signals', 'eembedding payload', 'EFC', 'Effect', 'effect', 'Effective', 'effective', 'effective sample size', 'Effectively', 'effectively', 'effectiveness', 'effects', 'Effects', 'efficacy', 'Efficiency', 'efficiency', 'Efficient', 'efficient', 'efficiently', 'Effort', 'effort', 'effort prediction', 'efforts', 'EFIS', 'EFSM', 'EGO', 'eigenfaces', 'eigenvalue', 'eigenvalues', 'eigenvector', 'eigenvectors', 'eight', 'eikonal', 'either', 'elaborates', 'elagant', 'elapsed', 'elderly', 'electric', 'Electric', 'electrical', 'electrical engineering', 'electricity', 'Electricity', 'electricity market', 'electricity retail markets', 'electrocardiogram', 'electrocardiograms', 'electrocardiography', 'Electroencephalogram', 'electroencephalogram', 'electroencephalography', 'Electronic', 'electronic mail', 'element', 'Elements', 'elements', 'elevated', 'elicited', 'eliminates', 'Eliminating', 'eliminating', 'elimination', 'ellipse', 'elliptic', 'Elman', 'else', 'ELU', 'EM', 'email', 'emails', 'embankment', 'embed', 'Embedded', 'embedded', 'embedded methods', 'embedding', 'Embedding', 'embedding efficiency', 'embeddings', 'Embeddings', 'embodies', 'embody', 'embraced', 'EMD', 'emerge', 'emerged', 'emergence', 'emerges', 'emerging', 'emitting', 'emotion', 'emotions', 'emphasis', 'Empirical', 'empirical', 'empirical mode decomposition', 'empirically', 'employ', 'employed', 'Employing', 'employing', 'employment', 'employs', 'empowered', 'empowers', 'empty', 'emulates', 'enable', 'enabled', 'enables', 'encapsulate', 'encode', 'encoded', 'Encoders', 'encoders', 'Encoding', 'encoding', 'encompassing', 'encountered', 'encourage', 'encouraging', 'encrypted', 'encryption', 'end', 'endanger', 'endeavor', 'energy', 'Energy', 'energy end-use model', 'energy management', 'energy saving', 'enforce', 'enforced', 'enforcement', 'enforcing', 'engage', 'Engagement', 'engagement', 'engagement detection', 'engine', 'engineer', 'engineering', 'engineers', 'engines', 'english', 'English', 'enhance', 'Enhanced', 'enhanced', 'Enhanceing', 'enhancement', 'Enhancement', 'enhancements', 'enhances', 'enhancing', 'enjoys', 'enormous', 'enough', 'enriches', 'enriching', 'enrolled', 'ensemble', 'Ensemble', 'ensemble clustering', 'ensemble learning', 'ensemble method', 'ensemble methods', 'ensembles', 'ensue', 'ensues', 'ensure', 'ensures', 'ensuring', 'entails', 'enterprise', 'enterprises', 'enthusiastic', 'entiated', 'entire', 'entirely', 'entities', 'entitled', 'Entity', 'entity', 'entity extraction', 'entrance', 'entries', 'Entropy', 'entropy', 'entropy0', 'entry', 'envelope', 'environment', 'Environment', 'environmental', 'Environmental', 'environmental sound recognition', 'environments', 'Environments', 'Epilepsy', 'epilepsy', 'epileptic', 'Epileptic', 'Epileptogenesis', 'epileptogenesis', 'episode', 'episodes', 'epoch', 'epochs', 'EPP', 'EQ', 'EQs', 'equal', 'equal loudness contour', 'equality', 'equalization', 'Equalization', 'equalizer', 'equalizers', 'equally', 'equation', 'Equation', 'Equations', 'equations', 'Equi', 'Equipment', 'equipment', 'equipment condition diagnosis (ecd)', 'equipped', 'equivalent', 'era', 'Erdos', 'Ergodic', 'Erosion', 'erosion', 'erred', 'erroneous', 'Error', 'error', 'error analysis', 'error entropy', 'errors', 'ers', 'erupted', 'es', 'ES', 'ESC', 'ESDMK', 'ESDMKs', 'ESM', 'esm', 'especially', 'esr', 'essays', 'Essays', 'essence', 'essential', 'establish', 'established', 'establishes', 'establishing', 'estate', 'estimate', 'estimated', 'estimates', 'Estimates', 'estimating', 'estimation', 'Estimation', 'estimation of students successes', 'estimator', 'estimators', 'et', 'etalon', 'etc', 'etiologies', 'EUC', 'Euclidean', 'EURECOM', 'Europe', 'European', 'evaluate', 'evaluated', 'evaluates', 'Evaluating', 'evaluating', 'evaluation', 'Evaluation', 'Evaluations', 'evaluations', 'evaluator', 'evaluators', 'Evaporation', 'evaporation', 'evapotranspiration', 'even', 'Event', 'event', 'event coreference', 'event detection', 'event related potentials', 'Events', 'events', 'eventually', 'ever', 'Every', 'every', 'eviction', 'evidence', 'evident', 'evidential', 'Evidential', 'evidential database', 'Evoked', 'evoked', 'Evolution', 'evolution', 'Evolutionary', 'evolutionary', 'evolutionary algorithms', 'evolutionary based learning', 'evolutionary computing', 'Evolvable', 'evolve', 'Evolved', 'evolved', 'evolves', 'Evolving', 'evolving', 'evolving (fuzzy) classifiers', 'evolving fuzzy systems', 'evolving graph', 'evolving networks', 'EX', 'Exact', 'exact', 'exact inference', 'exactly', 'exam', 'Examination', 'examination', 'examine', 'examined', 'examiner', 'examines', 'examining', 'Examining', 'Example', 'example', 'Examples', 'examples', 'exams', 'exceed', 'exceeded', 'excellent', 'except', 'exception', 'exceptional', 'Exchange', 'exchange', 'Executable', 'execute', 'executed', 'executing', 'execution', 'executions', 'Exemplars', 'exemplars', 'exemplify', 'exerted', 'exhausting', 'exhaustive', 'exhaustively', 'exhibit', 'exhibiting', 'exhibits', 'exist', 'existence', 'existing', 'Existing', 'exists', 'expanded', 'expansion', 'expect', 'Expectation', 'expectation', 'expectation maximization', 'expected', \"expected change in classifier's accuracy\", 'expectedly', 'expense', 'expenses', 'expensive', 'experience', 'Experience', 'experienced', 'experiences', 'experiment', 'Experiment', 'experimental', 'Experimental', 'experimentally', 'experimentation', 'experimentations', 'experimented', 'Experiments', 'experiments', 'Expert', 'expert', 'expert knowledge', 'expert systems', 'expertly', 'Experts', 'experts', 'explain', 'Explainable', 'explainable', 'explaining', 'explains', 'explanation', 'explanations', 'explanatory', 'explicitly', 'exploit', 'Exploitation', 'exploitation', 'exploited', 'Exploiting', 'exploiting', 'exploits', 'exploration', 'explorations', 'explore', 'explored', 'explores', 'Exploring', 'exploring', 'explosion', 'exponential', 'Exponential', 'exponential regression', 'exponentially', 'Exponentially', 'exposed', 'exposes', 'Exposing', 'exposure', 'express', 'expressed', 'expresses', 'expression', 'Expression', 'expressions', 'expressive', 'extend', 'extended', 'Extended', 'Extending', 'extends', 'extension', 'extensive', 'Extensive', 'extensively', 'Extent', 'extent', 'External', 'external', 'extra', 'extract', 'Extracted', 'extracted', 'extracting', 'Extracting', 'extraction', 'Extraction', 'extraction patterns', 'extractive', 'extractor', 'Extractors', 'extractors', 'extracts', 'extrapolation', 'extreme', 'extreme verification latency', 'extremely', 'eye', 'EyeQual', 'eyes', 'f', 'F', 'F1', 'FA', 'face', 'Face', 'face recognition', 'Facebook', 'faces', 'facet', 'facial', 'Facial', 'facial expression recognition', 'facilitate', 'facilitated', 'facilitates', 'facilitating', 'facilities', 'facing', 'fact', 'facto', 'factor', 'Factor', 'Factorization', 'factorization', 'Factors', 'factors', 'facts', 'factuality', 'faculties', 'fail', 'failed', 'failing', 'fails', 'Failure', 'failure', 'failures', 'Failures', 'fair', 'fairly', 'Fairness', 'fairness', 'fake', 'Fake', 'fake user accounts', 'fall', 'falls', 'false', 'False', 'falsification', 'familiar', 'families', 'family', 'Family', 'famous', 'fans', 'far', 'fares', 'farmer', 'farmers', 'fashion', 'Fast', 'fast', 'faster', 'fastQ', 'Fatigue', 'fatigue', 'Fault', 'fault', 'fault data injection', 'fault detection', 'fault detection and classification (fdc)', 'fault diagnosis', 'fault fingerprint extraction', 'fault localization', 'Faults', 'faults', 'faults localization', 'faulty', 'Faulty', 'favorably', 'favors', 'FC', 'FCGPANN', 'FDC', 'fdd', 'feasibility', 'feasible', 'feature', 'Feature', 'feature aware', 'feature discovery', 'feature extraction', 'feature fusion', 'feature learning', 'feature recognition', 'feature selection', 'feature vector', 'features', 'Features', 'features selection', 'fed', 'feed', 'feed-forward networks', 'feedback', 'feeder', 'Feeder', 'feedforward', 'Feedforward', 'feel', 'female', 'females', 'FERET', 'Fetal', 'fetal', 'few', 'Few', 'fewer', 'fiber', 'Fiber', 'fibers', 'fidelity', 'fiducial', 'Field', 'field', 'Fields', 'fields', 'FIFO', 'fifty', 'fighting', 'figures', 'filament', 'file', 'Filed', 'Filer', 'files', 'fill', 'filled', 'filling', 'film', 'Film', 'filter', 'Filter', 'filterbank', 'filtered', 'filtering', 'Filtering', 'Filters', 'filters', 'filtration', 'final', 'Final', 'finally', 'Finally', 'finance', 'Financial', 'financial', 'financial markets', 'find', 'finding', 'Finding', 'findings', 'finds', 'fine', 'Fine', 'fine tuning', 'Finger', 'finger', 'Fingerprint', 'fingerprint', 'fingerprinting', 'Fingerprinting', 'Fingerprints', 'fingerprints', 'fingers', 'finite', 'Finite', 'finite-state machines', 'finiteness', 'fire', 'fires', 'firewall', 'firewalls (computing)', 'firmlp', 'FIRMLP', 'First', 'first', 'firstly', 'Firstly', 'Fisher', 'fisher vector (fv) feature representation', 'fit', 'fitness', 'fits', 'fitted', 'fittest', 'fitting', 'Five', 'five', 'fixed', 'flat', 'flaw', 'FLC', 'Fleet', 'flexibility', 'flexible', 'Flexible', 'flickering', 'Flipping', 'floods', 'flow', 'Flow', 'flow forecast', 'flowing', 'flows', 'fluctuating', 'fluctuations', 'fluid', 'fluidic', 'fluorescence', 'fly', 'Fly', 'fMLR', 'fMRI', 'focus', 'Focus', 'focused', 'focuses', 'focusing', 'fold', 'Folded', 'folding', 'follow', 'followed', 'following', 'Following', 'follows', 'food', 'foods', 'foot', 'footprint', 'Footprint', 'For', 'for', 'foraging', 'Force', 'force', 'force plate', 'forces', 'forcing', 'forecast', 'Forecast', 'forecast combination', 'Forecaster', 'forecaster', 'forecasting', 'Forecasting', 'forecasting energy demand', 'Forecasts', 'forecasts', 'foreclosure', 'Foreclosure', 'foreclosure-and-real-estate-market', 'foreground', 'foreign', 'Foreign', 'foremost', 'Forensic', 'forensic', 'forensics', 'Forest', 'forest', 'Forests', 'forests', 'forfingerprint', 'forged', 'forgery', 'Forgery', 'forgetting', 'forgotten', 'fork', 'Form', 'form', 'formal', 'Formal', 'formal modeling', 'formalism', 'formalize', 'formalized', 'formance', 'formed', 'former', 'forming', 'forms', 'formulate', 'formulated', 'formulation', 'formulations', 'forth', 'forum', 'forums', 'Forums', 'forward', 'Forward', 'forward looking sonars', 'forwarded', 'foster', 'found', 'foundation', 'founded', 'four', 'Four', 'four dimension', 'Fourier', 'Fourth', 'fourth', 'FPE', 'FRA', 'fraction', 'fragmented', 'frame', 'frames', 'framework', 'Framework', 'Frameworks', 'frameworks', 'France', 'Fraud', 'fraud', 'fraud detection', 'fraudulent', 'free', 'freelancer', 'frequencies', 'frequency', 'Frequency', 'frequency response analysis fra', 'Frequent', 'frequent', 'frequent patterns', 'frequent sequence pattern mining', 'frequent set mining', 'Frequently', 'frequently', 'freshly', 'Freund', 'friendly', 'from', 'From', 'front', 'FSS', 'fueled', 'fulfilling', 'full', 'Fuller', 'fully', 'Function', 'function', 'function approximation', 'Functional', 'functional', 'functional connectivity', 'functional dependency', 'functional time series', 'functionality', 'Functions', 'functions', 'fundamental', 'fundamentals', 'further', 'Further', 'furthermore', 'Furthermore', 'fused', 'fusing', 'Fusion', 'fusion', 'Future', 'future', 'futuristic', 'fuzzy', 'Fuzzy', 'fuzzy clustering', 'fuzzy discrete event system', 'fuzzy logic', 'fuzzy operations', 'fuzzy rules', 'fuzzy soft sets', 'fuzzy systems', 'fuzzy-logic-controller', 'fuzzy-neighborhood density-based clustering', 'FV', 'FVC2004', 'g', 'GA', 'GAEMN', 'gain', 'gain parameter and drop out technique', 'gained', 'gaining', 'gains', 'gait', 'gait analysis', 'Galaxy', 'game', 'Game', 'game theory', 'game-data', 'games', 'Gamma', 'gamma', 'gamma distribution', 'gamma-ray spectra', 'gap', 'gaps', 'Gaps', 'garden', 'GAs', 'Gate', 'gather', 'gathered', 'GATK', 'Gaussian', 'gaussian mixture', 'gaussian mixture model', 'gaussian mixture model (gmm)', 'gaussian process', 'gaussian process regression', 'gaussian processes', 'gaussian radial basis function', 'GBT', 'GCM', 'gcm data', 'GCMs', 'GCPV', 'Gender', 'gender', 'gender identification', 'Gene', 'gene', 'gene coexpression networks', 'gene expression data', 'GENEActiv', 'geneous', 'general', 'General', 'generalisation', 'generalization', 'Generalization', 'generalize', 'Generalized', 'generalized', 'generalizes', 'generalizing', 'Generally', 'generally', 'generate', 'generated', 'generates', 'generating', 'Generation', 'generation', 'generations', 'generative', 'generative learning', 'generative models', 'generator', 'generators', 'generic', 'genes', 'genetic', 'Genetic', 'genetic algorithm', 'genetic algorithms', 'genetic optimization and supervision', 'genetically', 'Genetically', 'genetics', 'genome', 'Genome', 'genome analysis toolkit (gatk)', 'genome wide association studies', 'genomic', 'genomic data', 'genre', 'geo', 'geodesic', 'geodesically', 'geograph', 'Geographic', 'geographical', 'geometric', 'Geometric', 'geometrical', 'Geometrical', 'geometrical analysis', 'geometrically', 'geometry', 'Geophysical', 'geophysical', 'Georgia', 'geospa', 'geospatial', 'gestational', 'gestational hypertension', 'Gestures', 'gestures', 'get', 'gets', 'getting', 'Gibbs', 'Gigabytes', 'Github', 'give', 'Given', 'given', 'gives', 'giving', 'glass', 'Glass', 'GLM', 'Global', 'global', 'global optimization', 'globally', 'glucose', 'glyph', 'gmm', 'GMM', 'GMMs', 'GNU', 'go', 'goal', 'goals', 'goes', 'going', 'gold', 'golden', 'Golf', 'good', 'Good', 'goodness', 'Google', 'google', 'google cloud vision api', 'got', 'governing', 'government', 'governmental', 'Gower', \"gower's measure of similarity\", 'GPA', 'gpgpu', 'GPLVM', 'gplvm', 'gps', 'GPS', 'GPU', 'gpu computing', 'GPUMLib', 'GPUs', 'GrabCut', 'grabcut', 'gracefully', 'grade', 'Gradient', 'gradient', 'gradient approximation', 'Gradients', 'gradually', 'graduation', 'Grain', 'grain', 'grained', 'Grained', 'grains', 'gram', 'Grammar', 'grammar', 'grandmasters', 'Granger', 'granger-causality', 'grants', 'granular', 'Granular', 'granular computing', 'granulation', 'granules', 'graph', 'Graph', 'graph representation', 'graph sequence', 'graph theory', 'Graphic', 'Graphical', 'graphical', 'graphical model', 'graphical models', 'graphically', 'graphics', 'Graphics', 'graphs', 'Graphs', 'gray', 'gray-level co-occurrence matrix (glcm)', 'great', 'greater', 'greatly', 'Greedy', 'greedy', 'gress', 'gression', 'grib', 'Grid', 'grid', 'grid-connected-pv-system', 'grids', 'GRNs', 'ground', 'group', 'Group', 'group based labeling', 'group diversity', 'grouped', 'grouping', 'Grouping', 'groupings', 'groups', 'groups1', 'grow', 'Growing', 'growing', 'grows', 'growth', 'GTIFRS', 'guarantee', 'guarantees', 'GUI', 'gui', 'guidance', 'guide', 'guidelines', 'Guidelines', 'guiding', 'Gustafson', 'gyroscope', 'h', 'H', 'habitat', 'habits', 'hacker', 'had', 'HadCM3', 'Hadoop', 'half', 'Hamming', 'hamming codes', 'hand', 'handcrafted', 'handle', 'handled', 'handling', 'handoff', 'handover', 'Handover', 'handpicked', 'handwritten', 'handwritten digit recognition', 'Hannan', 'happen', 'happens', 'Hard', 'hard', 'harden', 'harder', 'hardware', 'harming', 'Harmonic', 'harmonic', 'harness', 'Harnessing', 'has', 'Hashing', 'hashing', 'Hashtags', 'Hausdorff', 'have', 'having', 'Hawai', 'hazard', 'hazy', 'HC', 'HCA', 'HCI', 'HDLTex', 'HDP', 'he', 'he12', 'headlines', 'health', 'Health', 'health social networks', 'Healthcare', 'healthcare', 'healthcare fraud', 'healthcare systems', 'healthy', 'Hearing', 'hearing', 'heart', 'Heart', 'heart disease', 'heart rate', 'heartbeat', 'heater', 'Heating', 'heating', 'heavily', 'heavy', 'Hedonic', 'hedonic', 'hedonic pricing model', 'hedonic theory', 'height', 'help', 'helpful', 'helping', 'helps', 'hematocrit', 'Hematopoietic', 'Hemiplegic', 'hemiplegic', 'hemiplegic gait', 'Hemorrhagic', 'hemorrhagic', 'Hence', 'hence', 'Henze', \"henze-zirkler's multivariate normality test\", 'her', 'here', 'Here', 'Hereby', 'hetero', 'heterogeneity', 'Heterogeneous', 'heterogeneous', 'heterogeneous-data', 'Heuristic', 'heuristic', 'heuristic word alignment', 'heuristically', 'heuristics', 'hidden', 'Hidden', 'hidden markov model', 'hidden markov model (hmm)', 'hidden markov models', 'hide', 'hierachical graph neuron', 'hierarchical', 'Hierarchical', 'hierarchical bayesian model', 'hierarchical classification', 'hierarchical clustering', 'hierarchical dirichlet process', 'hierarchical learning', 'hierarchy', 'High', 'high', 'high voltage feeder', 'high-dimensional data', 'high-dimensional input', 'high-order rbms', 'higher', 'Higher', 'highest', 'highlight', 'highlights', 'Highly', 'highly', 'highresource', 'highresources', 'highway', 'Highway', 'Hilbert', 'him', 'Himalayan', 'hindered', 'hindering', 'hinge', 'Hinton', 'hip', 'hippocampal', 'hiring', 'his', 'Histogram', 'histograms', 'historical', 'history', 'hit', 'HLA', 'HMM', 'hmm', 'HMMs', 'hoc', 'HOG', 'hold', 'holders', 'holds', 'holidays', 'home', 'Home', 'home appliances', 'homeostasis', 'homeowners', 'homes', 'Homes', 'homogeneous', 'Homogenous', 'homogenous', 'homomorphic', 'Honda', 'hope', 'Horizon', 'horizon', 'horizon line detection', 'horizons', 'horizontal', 'hospital', 'Hospital', 'hospitalizations', 'hospitalized', 'hospitals', 'host', 'Hot', 'hot', 'hotspot', 'Hotspot', 'hotspot mapping', 'hotspots', 'hour', 'Hourly', 'hourly', 'hours', 'House', 'house', 'houses', 'housing', 'Housing', 'housing prices prediction', 'how', 'however', 'However', 'HQ', 'HSDPA', 'html', 'HTTP', 'huge', 'Human', 'human', 'human action recognition', 'human activity recognition', 'human behavior prediction', 'human tracking', 'Human218', 'humans', 'Humans', 'humid', 'hundreds', 'HVAC', 'hybrid', 'Hybrid', 'hybrid algorithms', 'hybrid electric vehicles', 'hybrid learning algorithms', 'hybrid-neurone-fuzzy', 'HybridElectric', 'Hybridising', 'Hydroelectric', 'hydroelectric', 'hydrologic', 'hyper', 'hypercompetitive', 'hyperparameter', 'hyperparameter optimization', 'hyperparameters', 'hyperplane', 'hypertension', 'hypopnea', 'hypotheses', 'hypothesis', 'hypothesize', 'I', 'i', 'IBM', 'IC', 'ICA', 'ical', 'ice', 'Ice', 'iClass', 'ICMC', 'ICU', 'ICUs', 'ID', 'idea', 'ideal', 'Ideally', 'ideas', 'identically', 'identifiable', 'Identification', 'identification', 'identification-recognition', 'identified', 'identifies', 'identify', 'Identifying', 'identifying', 'identities', 'identity', 'Idiopathic', 'idiopathic', 'IDP', 'IDS', 'IDSs', 'IEC', 'IEEE', 'If', 'if', 'IFF', 'ignore', 'IHT', 'ii', 'iii', 'ill', 'Illinois', 'illumination', 'Illumine', 'illustrate', 'illustrated', 'illustrates', 'illustrative', 'IM', 'im', 'Image', 'image', 'image classification', 'image descriptors', 'image forgery detection', 'image matching', 'image noise', 'image processing', 'image restoration', 'image segmentation', 'image segments', 'image synthetization', 'image-based diagnosis', 'ImageNet', 'images', 'Images', 'imaging', 'Imbalance', 'imbalance', 'imbalanced', 'imbalanced classes', 'IMCP', 'imitate', 'immediate', 'immensely', 'immunity', 'immunohistochemical', 'impact', 'Impact', 'Impacts', 'impacts', 'impaired', 'impairment', 'IMPC', 'impeding', 'imperative', 'impetus', 'implement', 'implementable', 'Implementation', 'implementation', 'implementations', 'implemented', 'implementing', 'implements', 'implicated', 'implications', 'implicit', 'implicit feedback', 'implicitly', 'implies', 'imply', 'implying', 'importance', 'Importance', 'importance sampling', 'important', 'imposed', 'imposing', 'impossible', 'impractical', 'imprecise', 'imprecision', 'impressive', 'improper', 'improve', 'Improve', 'Improved', 'improved', 'improvement', 'Improvement', 'improvements', 'improves', 'Improving', 'improving', 'impulse', 'Impulse', 'imputation', 'Impute', 'in', 'In', 'in-hospital length of stay prediction', 'in-memory distribution', 'inadequate', 'inadvertent', 'inappropriate', 'incentives', 'Incidence', 'incidence', 'incident', 'Incident', 'incident-ranking', 'incidents', 'include', 'included', 'includes', 'including', 'Including', 'inclusion', 'Inclusion', 'incoming', 'Incomplete', 'incomplete', 'inconsistency', 'Inconsistent', 'inconsistent', 'incorporate', 'incorporated', 'incorporates', 'incorporating', 'incorrect', 'incorrectly', 'increase', 'increased', 'increases', 'increasing', 'increasingly', 'Increasingly', 'Incremental', 'incremental', 'incur', 'incurred', 'incurs', 'indeed', 'Indeed', 'indefinite', 'InDegree', 'independence', 'independent', 'Independent', 'independently', 'index', 'Index', 'index and ring finger ratio', 'indexes', 'Indexing', 'indexing', 'India', 'indicate', 'indicated', 'indicates', 'indicating', 'indication', 'Indicative', 'indicator', 'Indicator', 'indicators', 'indices', 'Indira', 'Individual', 'individual', 'individually', 'individuals', 'indoor', 'Indoor', 'indoor localization', 'indoor user movement', 'induce', 'induced', 'inducing', 'Induction', 'induction', 'induction motors', 'inductive', 'inductive logic programming', 'Industrial', 'industrial', 'industries', 'industry', 'ineligible', 'inertia', 'inertial', 'inertial measurement units', 'inevitable', 'inevitably', 'inexpensive', 'inexperience', 'infeasible', 'infection', 'infections', 'infer', 'Inference', 'inference', 'Inferences', 'Inferential', 'inferential', 'inferential reasoning', 'infering', 'inferred', 'inferring', 'Inferring', 'Infinite', 'infinite', 'infinitely', 'Infinitely', 'infinity', 'inflation', 'inflectional', 'inflict', 'influence', 'Influence', 'influenced', 'influences', 'inform', 'information', 'Information', 'information extraction', 'information need modeling', 'information retrieval', 'information theoretic learning', 'information theory', 'informative', 'informative weight', 'Informed', 'informed', 'informing', 'informs', 'Infrared', 'infrared', 'infrastructure', 'ingenious', 'inhabitants', 'Inhabitants', 'inhabiting', 'inherent', 'inherently', 'inheritance', 'inherits', 'inhibiting', 'initial', 'Initial', 'initialization', 'initialize', 'initially', 'Initially', 'initiatives', 'injecting', 'injection', 'Injection', 'injuries', 'injury', 'inking', 'inner', 'innovations', 'innovative', 'inopportune', 'Inpainting', 'inpainting', 'input', 'inputs', 'Inquiry', 'insecure', 'inside', 'insight', 'Insight', 'insights', 'Insolation', 'insolation', 'insolation period', 'inspecting', 'Inspection', 'inspection', 'Inspired', 'inspired', 'Instagram', 'installation', 'installations', 'installed', 'instance', 'Instance', 'instance selection', 'instance weighting', 'Instances', 'instances', 'instant', 'Instant', 'instant message', 'Instantaneous', 'instantaneous', 'instants', 'instead', 'Instead', 'institution', 'institutional', 'institutions', 'instructors', 'instrument', 'instrumental', 'instruments', 'insufficiency', 'insufficient', 'insurance', 'integer', 'integral', 'integrate', 'Integrated', 'integrated', 'integrated circuits', 'integrates', 'integrating', 'Integrating', 'integration', 'Integration', 'integration of new classes on-the-fly', 'Integrative', 'integrative complexity', 'integrity', 'Intel', 'intellectual', 'intelligence', 'Intelligence', 'intelligent', 'Intelligent', 'intelligent agent', 'intelligent systems', 'intelligent tutoring systems', 'intelligibility', 'intend', 'intended', 'intensity', 'Intensive', 'intensive', 'intensive care units', 'intensively', 'intention', 'intentional', 'inter', 'interact', 'interacting', 'Interaction', 'interaction', 'interactions', 'Interactive', 'interactive', 'interactive evolutionary computation', 'interactive systems', 'interdisciplinary', 'interest', 'interested', 'interesting', 'Interestingly', 'interests', 'Interface', 'interface', 'interfaces', 'intermediate', 'intermittent', 'internal', 'internally', 'international', 'International', 'Internet', 'internet of things', 'interpolates', 'interpolation', 'interpret', 'interpretability', 'Interpretable', 'interpretable', 'interpretable machine learning', 'interpretable modeling', 'interpretation', 'Interpretation', 'interpreted', 'interrelation', 'interrogation', 'interrupt', 'interrupted', 'interruption', 'intersect', 'intersection', 'Intersections', 'interval', 'Interval', 'interval-radial algorithm', 'intervals', 'intervention', 'intervention systems', 'interventions', 'into', 'intra', 'Intracellular', 'intractable', 'intricacies', 'intriguing', 'intrinsic', 'introduce', 'introduced', 'introduces', 'introducing', 'Introduction', 'Intrusion', 'intrusion', 'intrusion detection', 'intrusion detection &amp; defence', 'intrusion detection system', 'intrusiondetection', 'intrusions', 'Intrusions', 'intrusive', 'intuition', 'intuitionistic', 'Intuitionistic', 'intuitionistic fuzzy stes', 'intuitions', 'intuitive', 'intuitively', 'invades', 'invalid', 'invariance', 'invariant', 'Invariant', 'invariants', 'Invasive', 'invasive', 'invention', 'inverse', 'Inverse', 'inverse gaussian regression', 'inverse reinforcement learning', 'inverse-inference', 'Inversion', 'inversion', 'inverted', 'Inverted', 'inverted dirichlet', 'invested', 'Investigate', 'investigate', 'investigated', 'investigates', 'Investigating', 'investigation', 'Investigation', 'investigators', 'investment', 'investors', 'involve', 'involved', 'involves', 'involving', 'ionosphere', 'iot', 'IoT', 'IP', 'ip networks', 'IPC', 'IR', 'iris', 'IRL', 'IRMA', 'iron', 'Iron', 'Irradiance', 'irradiance', 'irradiation', 'irregular', 'irregularities', 'irrelevant', 'irritation', 'IRS', 'is', 'Is', 'isbsg', 'island', 'isolate', 'isolates', 'isolating', 'Isolation', 'isolation', 'issue', 'issues', 'Istanbul', 'it', 'IT', 'It', 'item', 'item popularity', 'items', 'itemset', 'itemsets', 'iterated', 'iteration', 'iterations', 'Iterative', 'iterative', 'iterative methods', 'iteratively', 'Iteratively', 'Its', 'ITS', 'its', 'itself', 'iv', 'J48', 'Jackknife', 'Jacobian', 'January', 'Japan', 'Java', 'Jensen', 'jensen-shannon divergence', 'job', 'job recommendation email system', 'joint', 'Joint', 'joint inference', 'jointly', 'joints', 'jpeg', 'JPEG', 'judging', 'July', 'jumps', 'just', 'justifiable', 'justification', 'k', 'K', 'k-means', 'k-means clustering', 'k-medoids', 'k-nearest neighbor', 'k-nearest neighbor classifier (knn)', 'k-nn', 'Kaiser', 'kaiser-meyer-olkin', 'Kalman', 'Kantorovich', 'kappa', 'KBP', 'kd', 'kd-trees', 'KDDCUP', 'keep', 'keeping', 'KEGG', 'kegg signalling pathways', 'kernel', 'Kernel', 'kernel function', 'kernel functions', 'kernel k-means', 'kernel method', 'kernel methods', 'kernel online learning', 'kernel ridge regression', 'kernels', 'Kernels', 'Kessel', 'key', 'Keystroke', 'keystroke', 'keystroke dynamics', 'keystroke feature', 'keystrokes', 'keyword', 'Keyword', 'keyword spotting', 'keywords', 'KGs', 'khepera', 'KheperaIII', 'kHz', 'kicks', 'Kidney', 'kidney', 'kidney segmentation', 'kind', 'kinds', 'kinect', 'kinematic', 'kingdom', 'kmeans', 'Kmeans', 'kmeans clustering', 'KNN', 'kNN', 'knn', 'knn classification model', 'knobs', 'knocking', 'know', 'Knowledge', 'knowledge', 'knowledge base', 'knowledge discovery', 'knowledge graphs', 'knowledge topology and acquisition', 'knowledge-discovery', 'known', 'Kohonen', 'kohonen self organizing network', 'KPSS', 'KRR', 'Kullback', 'Kwiatkowski', 'L', 'L1', 'l1', 'l1 norm', 'L2', 'l2 norm', 'L2LR', 'lab', 'label', 'Label', 'label noise', 'label propagation', 'labeled', 'Labeled', 'labelers', 'Labeling', 'labeling', 'Labelled', 'labelled', 'labellers', 'Labelling', 'labelling', 'Labels', 'labels', 'laboratory', 'Laboratory', 'laborious', 'LabVIEW', 'lack', 'lacked', 'lacking', 'lacks', 'LaCova', 'LAD', 'Lanczos', 'land', 'landscapes', 'language', 'Language', 'language modeling', 'Languages', 'languages', 'Laplacian', 'LapSVM', 'Large', 'large', 'large data', 'large scale', 'large scale network flow', 'largely', 'larger', 'largest', 'Lasso', 'lasso', 'LASSO', 'lasso regression', 'last', 'late', 'Latencies', 'latency', 'Latent', 'latent', 'latent dirichlet allocation', 'latent semantic indexing', 'later', 'lateral', 'lateral movement', 'latest', 'latter', 'Layer', 'layer', 'layered', 'Layered', 'layered learning', 'layering', 'layers', 'lays', 'LBP', 'LBPs', 'lcm', 'lda', 'LDA', 'lead', 'leader', 'leading', 'Leading', 'leads', 'leaf', 'Leaf', 'Leap', 'leap', 'Learn', 'learn', 'Learned', 'learned', 'Learner', 'learner', 'Learners', 'learners', 'Learning', 'learning', 'learning (artificial intelligence)', 'learning classifier systems', 'learning convex function', 'learning from interpretation transition', 'learning systems', 'learns', 'learnt', 'least', 'Least', 'least absolute shrinkage and selection operator (lasso)', 'leave', 'leaving', 'lecture', 'Lecture', 'Lectures', 'LED', 'led', 'ledger', 'LEDs', 'left', 'leg', 'legged locomotion', 'Legitimate', 'legitimate', 'Leibler', 'leightweight', 'lenders', 'lending', 'Length', 'length', 'lengths', 'lengthy', 'lens', 'Lesion', 'lesions', 'Less', 'less', 'lessened', 'let', 'lets', 'Levee', 'Levees', 'level', 'Level', 'level-k thinking', 'levels', 'Levels', 'leverage', 'leverages', 'Leveraging', 'leveraging', 'Lexical', 'lexical', 'lexicon', 'LFU', 'Li', 'Library', 'library', 'LibriSpeech', 'libs', 'license', 'License', 'license plate recognition system', 'lie', 'Lie', 'lies', 'Life', 'life', 'lifelong', 'lifelong machine learning', 'lifestyle', 'lifetime', 'light', 'lighting', 'lightning', 'lightweight', 'like', 'Like', 'likelihood', 'likely', 'limit', 'Limitation', 'limitation', 'limitations', 'limited', 'Limited', 'limiting', 'limits', 'Line', 'line', 'linear', 'Linear', 'linear programming', 'linear regression', 'linearly', 'lines', 'Lingual', 'Linguistic', 'linguistic', 'linguistic features', 'Link', 'link', 'link prediction', 'Linkage', 'linkage', 'linked', 'Linking', 'linking', 'links', 'LIP', 'list', 'Listing', 'lists', 'literature', 'literatures', 'Little', 'little', 'Live', 'live', 'Liver', 'liver', 'liver segmentation', 'Liverpool', 'lives', 'living', 'Living', 'LIWC', 'load', 'Load', 'loading', 'loads', 'local', 'Local', 'local binary patterns', 'locality', 'Localization', 'localization', 'localizations', 'localize', 'localized', 'Localized', 'Localizing', 'locally', 'located', 'location', 'locations', 'locomotion', 'log', 'logic', 'Logic', 'logical', 'login', 'Logistic', 'logistic', 'logistic regression', 'logistics', 'logits', 'logs', 'logsigmoid function', 'Long', 'long', 'long short-term memory', 'long-short term memory', 'longer', 'longitudinal', 'Longitudinal', 'longitudinal data', 'LOOCV', 'look', 'looking', 'Looking', 'lookup', 'Loop', 'loop', 'loops', 'loosely', 'Los', 'losing', 'Loss', 'loss', 'loss minimization', 'losses', 'lost', 'lot', 'lots', 'loudness', 'Low', 'low', 'low-rank approximation', 'lower', 'lowered', 'Lowering', 'lowest', 'lows', 'Lp', 'LP', 'lp-norm estimators', 'LPCA', 'LPDS', 'LPRS', 'LR', 'LRU', 'LSB', 'LSBs', 'LSH', 'LSI', 'LSTM', 'Luckily', 'lung', 'Lung', 'lung cancer', 'lying', 'lyrics', 'Lyrics', 'm', 'M', 'm3', 'MA', 'Machine', 'machine', 'machine learning', 'machine learning algorithm (mla)', 'machine learning algorithms', 'machine learning application', 'machine learning as a service', 'machine learning techniques', 'machine-learning', 'machine-sourced', 'machines', 'Machines', 'Macro', 'made', 'Madhya', 'MAE', 'Magnetic', 'magnetic', 'magnetic field', 'magnitude', 'Mahalanobis', 'mail', 'Main', 'main', 'mainly', 'mainstream', 'maintain', 'maintainability', 'maintained', 'Maintained', 'maintaining', 'maintenance', 'major', 'Major', 'majority', 'Majority', 'majority vote rule', 'make', 'Make', 'maker', 'makers', 'makes', 'making', 'Making', 'male', 'males', 'Malicious', 'malicious', 'Malware', 'malware', 'malware classification', 'malwares', 'manage', 'manageable', 'management', 'Management', 'manages', 'managing', 'manifest', 'Manifestations', 'manifold', 'Manifold', 'manifold learning', 'manifold learning regression', 'Manifolds', 'manifolds', 'manipulated', 'manipulation', 'Manipulators', 'manner', 'manual', 'Manually', 'manually', 'manufacturers', 'manufacturing', 'Manufacturing', 'many', 'Many', 'map', 'Map', 'MAP', 'MAPE', 'MAPK', 'maple', 'Maple', 'mapped', 'mapping', 'Mapping', 'mapreduce', 'MapReduce', 'maps', 'Maps', 'MAR', 'Margin', 'margin', 'marginal', 'margins', 'mark', 'marker', 'markers', 'Market', 'market', 'marketing', 'Markets', 'markets', 'Markov', 'markov decision process', 'markov decision processes', 'markov logic networks', 'markov network', 'markov switching model', 'markov(k)', 'Markovian', 'Maryland', 'MAS', 'mashup', 'Mashups', 'mashups', 'mask', 'Mask', 'Masked', 'masked conditional neural networks', 'masking', 'masks', 'mass', 'mass deaths', 'mass transfer', 'massive', 'master', 'Master', 'master degree in information technology', 'match', 'matched', 'matches', 'Matching', 'matching', 'Matchingtching', 'material', 'mathematica', 'Mathematica', 'mathematical', 'mathematical model', 'mathematically', 'MATLAB', 'matrices', 'matrix', 'Matrix', 'matrix decomposition', 'matter', 'Matthews', 'Mattress', 'mattress', 'maturation', 'matures', 'Max', 'max', 'max-min distance algorithm', 'maxima', 'maximal', 'Maximising', 'maximization', 'Maximization', 'maximize', 'maximizes', 'Maximizing', 'maximum', 'Maximum', 'maximum a posteriori', 'maximum likelihood estimation', 'maximum-power-point-tracker', 'may', 'maze', 'mc', 'MClassification', 'mclnn', 'MCLNN', 'MCS', 'MDLClass', 'MDP', 'Mead', 'meal', 'Mean', 'mean', 'meaning', 'Meaning', 'meaningful', 'meaningfully', 'meaningless', 'means', 'Means', 'measure', 'Measure', 'measured', 'Measurement', 'measurement', 'measurements', 'Measurements', 'measures', 'Measures', 'measuring', 'Measuring', 'mechanism', 'mechanisms', 'Media', 'media', 'Medical', 'medical', 'medical image analysis', 'medical informatics', 'Medicare', 'medicine', 'medium', 'medoids', 'Medoids', 'MEE', 'meet', 'meets', 'Mel', 'Mellon', 'membership', 'memory', 'memoRy', 'Memory', 'men', 'mental', 'mention', 'mentionpair', 'mentions', 'merely', 'merge', 'merging', 'merits', 'Message', 'message', 'messages', 'Messages', 'messaging', 'Meta', 'meta', 'meta-algorithms', 'meta-heuristic prediction algorithm', 'meta-recommendation system', 'Metabolic', 'metabolic', 'metabolites', 'metabolomics', 'metadata', 'Metaheuristic', 'metaheuristic', 'metaheuristics', 'metal', 'metasoundex', 'MetaSoundex', 'meteorological', 'meteorology', 'Meter', 'metering', 'meters', 'method', 'Method', 'methodically', 'methodological', 'Methodological', 'methodologies', 'methodology', 'methods', 'Methods', 'Metric', 'metric', 'metric learning', 'Metrics', 'metrics', 'Metro', 'Meyer', 'MFCC', 'mfccs', 'MFCCs', 'MH', 'MHAD', 'mhealth', 'mHealth', 'MI', 'MIAMI', 'Michigan', 'Micro', 'micro', 'microalgae', 'Microalgae', 'microalgae classification', 'microblogging', 'microcytic', 'Microscope', 'microscopic', 'microseconds', 'Microsoft', 'microstructure', 'Microtubule', 'microtubules', 'Mid', 'mid', 'might', 'MIL', 'mild', 'military', 'million', 'millions', 'Millions', 'millisecond', 'milliseconds', 'mimicked', 'mimicking', 'mimics', 'Min', 'min', 'mind', 'mine', 'mined', 'minimal', 'Minimal', 'Minimally', 'minimally', 'minimization', 'Minimization', 'minimize', 'minimizes', 'Minimizing', 'minimizing', 'minimum', 'Minimum', 'minimum description length', 'mininet', 'mining', 'Mining', 'mining big data', 'Minneapolis', 'minor', 'minority', 'minute', 'minutes', 'minutia code', 'Minutiae', 'minutiae', 'mirrors', 'MIRS', 'misclassification', 'Mises', 'mislabeled', 'mislabeled data', 'misled', 'mismatch', 'misses', 'Missing', 'missing', 'missing at random', 'missing data', 'mission', 'mistakes', 'MIT', 'Mitigate', 'mitigate', 'mitigates', 'mitigating', 'Mitigating', 'mitigation', 'Mitigation', 'Mixed', 'mixed', 'mixed data', 'mixing', 'Mixture', 'mixture', 'mixture model', 'mixture models', 'mixture of experts', 'Mixtures', 'mixtures', 'MKRL', 'ML', 'MLA', 'MLaaS', 'mlp', 'MLP', 'MLPs', 'MLR', 'MLS', 'mm', 'MMSE', 'MN', 'mnist', 'MNIST', 'mnist variations', 'mobile', 'Mobile', 'mobile computing', 'mobile robot self-localization', 'mobile robots', 'mobile security', 'mobile store security', 'mobility', 'Mobility', 'MOCAP', 'Mocap', 'modal', 'modalities', 'modality', 'mode', 'model', 'Model', 'model building', 'model calibration', 'model checking', 'model post processing', 'model transformatiomn', 'modeled', 'Modeling', 'modeling', 'modelled', 'modelling', 'Modelling', 'models', 'Models', 'moderate', 'moderation', 'Modern', 'modern', 'modest', 'Modification', 'modification', 'modifications', 'modified', 'Modified', 'modify', 'modifying', 'modular', 'Modular', 'modulated', 'modulation', 'module', 'MOEAs', 'Molecular', 'molecular', 'molecules', 'moment', 'momentary', 'moments', 'Monge', 'monitor', 'monitored', 'monitoring', 'Monitoring', 'monitors', 'monolithic', 'monotonically', 'Monte', 'monte carlo', 'monte carlo methods', 'month', 'monthly', 'Monthly', 'months', 'mood', 'More', 'more', 'Moreover', 'morphological', 'morphologically', 'Morphologically', 'morphology', 'Mortality', 'mortality', 'mortality rate prediction', 'mortgage', 'Moscow', 'Most', 'most', 'mostly', 'motif', 'Motifs', 'motifs', 'Motion', 'motion', 'motion capture (mocap)', 'motion-based multiple object tracking', 'Motions', 'motions', 'Motivated', 'motivated', 'motivation', 'Motor', 'motor', 'motors', 'Motors', 'mouse', 'Mouse', 'move', 'Movement', 'movement', 'movements', 'moves', 'movie', 'Movie', 'MovieLens', 'movies', 'Moving', 'moving', 'moving target defense', 'MR', 'mr images', 'mRMR', 'mrmr', 'ms', 'MSA', 'MSE', 'MT', 'MTs', 'much', 'Much', 'MUE', 'Multi', 'multi', 'multi agent systems', 'multi instance classification', 'multi-armed bandit', 'multi-armed bandits', 'multi-corpora', 'multi-density clustering', 'multi-label classification', 'multi-label classifiers', 'multi-label learning', 'multi-linear regression model', 'multi-objective evolutionary algorithm', 'multi-objective particle swarm optimization', 'multi-objective reinforcement learning', 'multi-objectivization', 'multi-period prediction', 'multi-scale', 'multi-strategy learning', 'multi-task learning', 'multi-valued models', 'Multiclass', 'multiclass', 'multiclass classification', 'Multidimensional', 'multidimensional', 'multidisciplinary', 'multifaceted', 'Multifaceted', 'Multilabel', 'multilayer', 'multilayer feedforward neural network', 'multilayer network', 'multilingual', 'multimedia', 'Multimedia', 'multimedia signal processing', 'multimedia structure analysis', 'Multimodal', 'multimodal', 'Multinomial', 'multinomial', 'multiobjectivization', 'Multipath', 'Multiplayer', 'multiple', 'Multiple', 'multiple classifier systems', 'multiple instance learning', 'multiple kernel learning', 'multiple object tracking', 'Multipliers', 'Multistep', 'multistep', 'multitude', 'Multivariate', 'multivariate', 'multivariate analyses', 'multiview', 'Multiview', 'multiview data', 'muscle', 'music', 'Music', 'music event', 'Musical', 'musical', 'Musicologists', 'must', 'mutation', 'mutual', 'Mutual', 'mutual information', 'my', 'myriad', 'N', 'n', 'na', 'Na', 'NAB', 'Nai', 'Naive', 'naive', 'naive bayes', 'naive bayes classifier', 'name', 'named', 'Named', 'named entity recognition', 'namely', 'names', 'nanoseconds', 'Nari', 'narrative', 'narrowed', 'NARX', 'narx', 'narx neural network', 'NASA', 'NASDAQ', 'National', 'national', 'Natural', 'natural', 'natural language processing', 'nature', 'Nature', 'navigate', 'navigation', 'Nazarbayev', 'NB', 'NCEP', 'NDK', 'NDmin', 'ndt', 'near', 'near infrared', 'nearby', 'nearest', 'Nearest', 'nearest neighbor', 'nearest neighbor search', 'nearly', 'necessarily', 'necessary', 'Necessary', 'necessitates', 'necessitating', 'necessity', 'need', 'needed', 'needing', 'needs', 'negate', 'Negative', 'negative', 'negative images', 'negativity', 'neglect', 'neglected', 'Neighbor', 'neighbor', 'Neighborhood', 'neighborhood', 'neighborhoods', 'neighbors', 'Neighbors', 'Neighbour', 'neither', 'Nelder', 'nelder-mead algorithm (nma)', 'neoadjuvant', 'NER', 'Nested', 'nested', 'net', 'Netflow', 'Netflows', 'Nets', 'Network', 'network', 'network attacks', 'network communities', 'network data', 'network inference', 'network intrusion detection system (nids)', 'network layer', 'network representation learning', 'network topology', 'Networked', 'networked control system', 'Networking', 'networking', 'Networks', 'networks', 'neural', 'Neural', 'neural network', 'neural network based machine learning', 'neural network classifier', 'neural networks', 'neuro', 'Neuro', 'neurobiology', 'neurocrfs', 'neuroevolution', 'Neurofuzzy', 'neurofuzzy', 'neurofuzzy system', 'Neuroimaging', 'neurologic', 'neurological', 'neurology', 'neuron', 'neuronal', 'neurons', 'neurophysiological', 'neuroscience', 'neutralizes', 'never', 'Nevertheless', 'New', 'new', 'new event types', 'newly', 'News', 'news', 'newsagents', 'NewsCubeSum', 'newsgroup', 'newswire', 'newsworthy', 'Newtons', 'next', 'Next', 'next generation sequence (ngs)', 'next generation wireless networks', 'NGS', 'nice', 'nicely', 'NIDS', 'night', 'NiN', 'nir', 'NIR', 'NK', 'NlogN', 'nlp', 'NLP', 'NMA', 'NMAE', 'NMF', 'NMR', 'NN', 'nn-based fault detection algorith', 'NNBHMS', 'no', 'NOAA', 'node', 'Node', 'node similarities', 'nodes', 'Nodules', 'nodules', 'noise', 'Noise', 'noise estimation', 'noise reduction', 'noised', 'noises', 'noisy', 'Noisy', 'noisy data', 'noisy training data', 'non', 'Non', 'non intrusive load monitoring', 'non negative matrix factorization', 'non stationary time-series', 'non-linearity', 'non-personalized single heuristic strategies', 'non-stationary', 'Noncooperative', 'noncustodial', 'none', 'Nonetheless', 'nonholonomic', 'nonintrusive', 'nonlinear', 'Nonlinear', 'nonlinear dynamics', 'nonlinearity', 'Nonnegative', 'nonnegative', 'nonnegative matrix factorization', 'Nonparametric', 'nonparametric', 'nonparametric bayesian', 'nonstationarity', 'Nonstationarity', 'nonstationary processes', 'nonsurgical', 'nontechnical', 'Nontechnical', 'nontechnical loss', 'nonword', 'Nonword', 'nonword stimuli repetition', 'nonwords', 'nor', 'norm', 'Norm', 'normal', 'Normal', 'Normality', 'normality', 'normalization', 'normalized', 'normally', 'North', 'Not', 'not', 'notably', 'Notably', 'note', 'noted', 'noticeably', 'notification', 'notifications', 'notion', 'notions', 'Nottingham', 'Novel', 'novel', 'novelty', 'Novelty', 'novelty search', 'now', 'Now', 'Nowadays', 'nowadays', 'NP', 'NPI', 'NTL', 'nuclear', 'Nuclear', 'nuclear magnetic resonance', 'Number', 'number', 'number of clusters in a dataset', 'numbers', 'Numenta', 'numerical', 'numerical models', 'numerical simulation', 'numerically', 'Numerous', 'numerous', 'nutrition', 'Nutrition', 'NVIDIA', 'NWR', 'nyi', 'O', 'o', 'Oahu', 'obesity', 'object', 'Object', 'object oriented software', 'object recognition', 'object tracking', 'Objective', 'objective', 'objective selection', 'objectively', 'Objectives', 'objectives', 'Objects', 'objects', 'oblivion', 'oblivion criterion', 'oblivious', 'Oblivious', 'oblivious routing scheme', 'obscurities', 'observation', 'observational', 'observations', 'Observations', 'observe', 'observed', 'observer', 'observing', 'obstacle', 'obstructive', 'obstructive apnea', 'obtain', 'Obtained', 'obtained', 'obtaining', 'obtains', 'obvious', 'occidental', 'occluded', 'Occluded', 'occlusion', 'occlusions', 'occupancy', 'occupants', 'occupies', 'occur', 'Occurance', 'occuring', 'occurred', 'occurrence', 'occurrences', 'occurring', 'occurs', 'Oceanic', 'oceanography', 'OCNN', 'odds', 'Of', 'of', 'off', 'offchain', 'offer', 'offered', 'offering', 'offers', 'Office', 'offline', 'Offline', 'offs', 'offset', 'often', 'oil', 'Oil', 'OK', 'OLAP', 'older', 'Olkin', 'OLP', 'OLS', 'Olympics', 'ompt', 'On', 'on', 'on-line learning', 'once', 'Once', 'One', 'one', 'one-way anova', 'OneMax', 'Ones', 'ones', 'ongoing', 'Online', 'online', 'online clustering', 'online k-means clustering', 'online learning', 'online process monitoring', 'online selection', 'ONLINESEARCHSPN', 'only', 'Only', 'onset', 'onshore', 'ontological', 'ontologies', 'ontology', 'Ontology', 'ontology learning', 'OOP', 'OP', 'open', 'Open', 'opened', 'opening', 'OpenMP', 'openmp tasks', 'opens', 'OpenSimulator', 'opensource', 'Operated', 'operates', 'operating', 'operation', 'operational', 'Operational', 'operations', 'Operator', 'operator', 'operators', 'opinion', 'Opinion', 'opinion extraction', 'opinions', 'OPP', 'opportunities', 'opportunity', 'opposed', 'opposite', 'OPS', 'Optical', 'optima', 'Optimal', 'optimal', 'optimal control', 'Optimality', 'optimality', 'optimally', 'Optimally', 'Optimisation', 'optimisation', 'optimised', 'optimizatioin', 'Optimization', 'optimization', 'optimizations', 'Optimize', 'optimize', 'optimized', 'Optimized', 'optimizer', 'optimizes', 'Optimizing', 'optimizing', 'optimum', 'Optimum', 'optimum path forest', 'optimum-path forest', 'option', 'options', 'or', 'OR', 'oracle', 'order', 'orders', 'organ', 'Organ', 'organ segmentation', 'organic computing', 'organism', 'organisms', 'organization', 'organizations', 'organized', 'organizing', 'Organizing', 'organs', 'orientation', 'Oriented', 'oriented', 'origin', 'original', 'originally', 'ORL', 'orphan', 'orphan node prediction', 'orthogonal', 'Orthogonal', 'orthogonal matching pursuit', 'orthosis', 'OSA', 'other', 'others', 'Otsu', 'OUPS', 'our', 'Our', 'Out', 'out', 'outage', 'Outcome', 'outcome', 'outcomes', 'Outcomes', 'outlets', 'outlier', 'Outlier', 'outlier detection', 'Outliers', 'outliers', 'outline', 'outpeformed', 'outperform', 'outperformed', 'outperforming', 'outperforms', 'output', 'outputs', 'outside', 'outsource', 'outsourcing', 'outstanding', 'OVCLDA', 'over', 'Over', 'over dispersion', 'overall', 'overarching', 'overcome', 'overcomes', 'overcoming', 'Overfeat', 'overfit', 'overfitting', 'Overflow', 'overhead', 'overlap', 'overlapping', 'oversampling', 'Oversampling', 'overtakes', 'overview', 'owing', 'own', 'owner', 'owners', 'ownership', 'owning', 'OY', 'P', 'p', 'PA', 'pace', 'PACF', 'packages', 'Packet', 'packet', 'paediatric', 'Page', 'page', 'pages', 'paid', 'pair', 'paired', 'pairs', 'pairwise', 'palm', 'Palynologists', 'palynology', 'panel', 'PANNET', 'paper', 'par', 'paradigm', 'paradigms', 'parallel', 'Parallel', 'parallel processing', 'parallelism', 'parallelize', 'parallelized', 'parallelized sgd', 'Parallelizing', 'parallelizing', 'parameter', 'Parameter', 'parameter control', 'parameterization', 'Parameters', 'parameters', 'Parametric', 'parametric', 'paramount', 'parent', 'parents', 'Pareto', 'Paris', 'parking', 'Parkinson', \"parkinson's disease\", 'parsimonious', 'part', 'Partial', 'partial', 'partial-autocorrelation-function-(pacf)', 'Partially', 'partially', 'participant', 'Participants', 'participants', 'participate', 'particle', 'Particle', 'particle swarm optimization', 'particular', 'Particularly', 'particularly', 'partition', 'Partition', 'partitional', 'partitional clustering', 'partitioning', 'Partitioning', 'partitioning algorithms', 'partitioning clustering', 'partitions', 'parts', 'Parts', 'parts based decompositions', 'party', 'pass', 'passed', 'passenger', 'passing', 'Passive', 'passive', 'passive seismic', 'password', 'past', 'Past', 'Pasto', 'patch', 'patched', 'patent', 'Patent', 'patents', 'path', 'Path', 'pathogens', 'pathologists', 'pathology', 'paths', 'pathway', 'Pathways', 'pathways', 'Patient', 'patient', 'patients', 'Patients', 'Pattern', 'pattern', 'pattern matching', 'pattern recognition', 'patterns', 'Patterns', 'paucity', 'pave', 'paves', 'payload', 'payments', 'pca', 'PCA', 'PCC', 'pcr', 'PCR', 'PCs', 'PDEs', 'peak', 'Pearson', 'Pedagogically', 'pedagogically', 'pedestrian', 'peer', 'PELU', 'pen', 'penalization', 'penalize', 'penalizing', 'penalty', 'pencil', 'penetration', 'people', 'per', 'Per', 'perceive', 'perceived', 'percent', 'Percentage', 'percentage', 'perception', 'Perception', 'perceptron', 'Perceptron', 'perceptrons', 'perceptual', 'Perceptual', 'perfect', 'perfection', 'perform', 'Perform', 'Performance', 'performance', 'performance evaluation', 'Performances', 'performances', 'performed', 'performing', 'performs', 'Perfusion', 'perhaps', 'perinatal', 'period', 'Period', 'periodic', 'Periodic', 'periods', 'permissions', 'permittivity', 'permutations', 'persecution', 'persistence', 'persistent', 'person', 'personal', 'personalization', 'personalize', 'Personalized', 'personalized', 'personalized item', 'personalized treatment', 'personalizes', 'personnel', 'perspective', 'Perspective', 'perspectives', 'pertaining', 'pertinent', 'perturbation', 'perturbations', 'Pervasive', 'pervasive', 'pervasively', 'Petri', 'PFA', 'PFP', 'PGI', 'PHA', 'phase', 'Phase', 'phase identification', 'phases', 'phenomena', 'phenomenal', 'phenomenon', 'Phenotype', 'phenotype prediction', 'phenotypes', 'Phenotypes', 'Philips', 'phishing', 'phone', 'Phoneme', 'phoneme', 'phoneme classification', 'phoneme prediction', 'phones', 'phonetic', 'photo', 'photovoltaic', 'Photovoltaic', 'physical', 'Physical', 'physicians', 'Physics', 'physics', 'physiological', 'physiology', 'Physiology', 'PhysioNet', 'picking', 'picks', 'PID', 'pid control', 'piece', 'pieces', 'piecewise', 'Piecewise', 'piecewise linear', 'pilot', 'Pilot', 'pink', 'pinpointing', 'Pipeline', 'pipeline', 'Pipelines', 'Pitch', 'pitch', 'pitch system', 'Pitches', 'pitfalls', 'pixel', 'pixels', 'PK', 'place', 'places', 'plain', 'plan', 'plane', 'planes', 'planktonic', 'planners', 'planning', 'Planning', 'Plant', 'plant', 'plants', 'plasticity', 'Plasticity', 'plastics', 'Plate', 'plate', 'plates', 'platform', 'Platform', 'platform as a service', 'platforms', 'platoon', 'plausibility', 'plausible', 'play', 'Play', 'played', 'player', 'players', 'playing', 'plays', 'plenty', 'plot', 'plots', 'plsa', 'PLSA', 'plug', 'pluggable', 'plugin', 'plurality', 'Plus', 'plus', 'PN', 'POA', 'Point', 'point', 'Points', 'points', 'Policies', 'policies', 'policing', 'Policing', 'Policy', 'policy', 'Political', 'political', 'polled', 'Pollen', 'pollen', 'pollen classification', 'PolyKernel', 'polymorphic', 'polynomial', 'polynomials', 'polysomnograph', 'Pong', 'pong', 'pool', 'pooling', 'poor', 'poorer', 'poorly', 'pop', 'Poppelreuter', \"poppelreuter's test\", 'Popular', 'popular', 'popularity', 'popularization', 'popularly', 'population', 'Population', 'populations', 'port', 'portability', 'portable', 'Portmanteau', 'ports (computers)', 'POS', 'pose', 'posed', 'poses', 'posing', 'position', 'Positioning', 'positioning', 'positions', 'Positive', 'positive', 'positive unlabeled learning', 'positives', 'possess', 'possibility', 'possible', 'possibly', 'Post', 'post', 'post-processing', 'posted', 'Posterior', 'posterior', 'posting', 'Posts', 'posts', 'potential', 'Potential', 'potentiality', 'potentially', 'Potentials', 'potentials', 'Power', 'power', 'power density', 'power grid analysis', 'power spectral density analysis', 'power systems', 'powered', 'powerful', 'powering', 'Powerset', 'PPDM', 'PPDP', 'PPRL', 'practical', 'practicality', 'practically', 'practice', 'practising', 'practitioner', 'practitioners', 'Pradesh', 'pRBC', 'pre', 'Pre', 'pre school', 'precious', 'precipitated', 'precipitation', 'precipitations', 'precise', 'Precise', 'precisely', 'Precision', 'precision', 'predefined', 'Predicate', 'Predicative', 'Predict', 'predict', 'predictability', 'predictable', 'Predictable', 'predictands', 'predicted', 'Predicting', 'predicting', 'predicting psychosis', 'Prediction', 'prediction', 'prediction algorithms', 'Predictions', 'predictions', 'predictive', 'Predictive', 'predictive analysis', 'predictive data analytics', 'predictive model', 'predictive modelling', 'predictive models', 'predictive scoring systems', 'predictivity', 'predictor', 'predictors', 'predicts', 'predominant', 'preeclampsia', 'preference', 'preference prediction technique', 'preferences', 'Preferences', 'preferred', 'preformed', 'pregnancy', 'Pregnant', 'pregnant', 'preliminaries', 'Preliminary', 'preliminary', 'prenatal', 'preparation', 'preprocessed', 'preprocesses', 'preprocessing', 'preprocessor', 'prerequisite', 'prescribe', 'Presence', 'presence', 'present', 'presentation', 'presented', 'presenting', 'presents', 'preservation', 'Preservation', 'preserve', 'preserving', 'Preserving', 'pressing', 'pressure', 'Pressure', 'prestige', 'pretraining', 'prevalent', 'prevent', 'prevented', 'preventing', 'prevention', 'previews', 'previous', 'Previous', 'previously', 'Previously', 'price', 'Price', 'prices', 'pricing', 'Primal', 'primal', 'primal dual algorithm', 'primary', 'prime', 'Principal', 'principal', 'principal component analysis', 'principal components analysis', 'principal-component analysis', 'Principle', 'principle', 'principle component analysis', 'principled', 'principles', 'printed', 'prints', 'prior', 'Prior', 'priori', 'Prioritization', 'prioritization', 'prioritize', 'prioritized', 'priors', 'Privacy', 'privacy', 'privacy policy', 'privacy preserving', 'privacy-preserving', 'pro', 'proactively', 'Probabilistic', 'probabilistic', 'probabilistic atlas', 'probabilistic logic', 'probabilistic matrix factorization', 'probabilistic programming', 'Probabilities', 'probabilities', 'probability', 'Probability', 'probability of classification error', 'Probit', 'probit regression', 'Problem', 'problem', 'problematic', 'Problems', 'problems', 'procedure', 'procedures', 'process', 'Process', 'process control', 'processed', 'Processes', 'processes', 'processing', 'Processing', 'processor', 'produce', 'produced', 'produces', 'producing', 'Product', 'product', 'production', 'Production', 'productive', 'productivity', 'products', 'Products', 'professional', 'professionals', 'proficiency', 'proficient', 'profile', 'Profiles', 'profiles', 'profiling', 'Profiling', 'Profit', 'profitability', 'Profitability', 'profitable', 'profoundly', 'prognoses', 'Prognostic', 'Program', 'program', 'Programmable', 'programmable', 'Programme', 'programmers', 'Programmers', 'programmes', 'Programming', 'programming', 'programs', 'progress', 'progresses', 'progression', 'progressive', 'prohibitive', 'project', 'projected', 'projecting', 'projection', 'Projection', 'projections', 'projects', 'Projects', 'proliferated', 'proliferation', 'prolific', 'Prominent', 'prominent', 'promise', 'promising', 'Promontory', 'promote', 'promoted', 'promoting', 'prompt', 'Prompt', 'prompting', 'promptly', 'prompts', 'prone', 'pronounceable', 'proof', 'proofof', 'propagate', 'propagates', 'propagating', 'Propagation', 'propagation', 'propensity', 'Propensity', 'proper', 'properly', 'Properties', 'properties', 'property', 'proportion', 'proportional', 'proportions', 'proposal', 'Proposal', 'proposals', 'propose', 'proposed', 'Proposed', 'proposes', 'proposing', 'proprietary', 'prospective', 'prospects', 'prostate', 'Prostate', 'protect', 'protection', 'protein', 'Protein', 'protein conformation', 'protocol', 'protocols', 'proton', 'prototype', 'prototyped', 'prove', 'proved', 'proven', 'provide', 'provided', 'provider', 'providers', 'provides', 'providing', 'provinces', 'provision', 'proxy', 'Pruning', 'pruning', 'PS', 'PSDA', 'pseudo', 'PSG', 'PSM', 'PSO', 'psychiatric', 'psychiatry', 'psychological', 'psychology', 'psychosis', 'Psychosis', 'Psychotherapy', 'psychotherapy', 'PU', 'public', 'publicly', 'published', 'publishers', 'publishing', 'Publishing', 'pull', 'Pull', 'pull request', 'pulled', 'pulling', 'Pulmonary', 'purchasing', 'purpose', 'purposes', 'pursue', 'Pursuit', 'pursuit', 'push', 'put', 'puts', 'putting', 'PV', 'pv system', 'pyramid', 'Q', 'q', 'q learning', 'q-learning', 'Q10', 'QoS', 'qos over heterogeneous networks', 'QP', 'qpcr', 'qPCR', 'QQ', 'quadratic', 'quadratic programming', 'qualitative', 'qualities', 'quality', 'Quality', 'quality assessment', 'quantifiable', 'quantification', 'quantified', 'Quantified', 'Quantifier', 'quantify', 'quantifying', 'Quantile', 'quantitative', 'quantitatively', 'quantities', 'quantity', 'quantization', 'quantum', 'quasi', 'Quasi', 'Queries', 'queries', 'query', 'Query', 'query relaxation', 'question', 'questionable', 'questions', 'quick', 'quickest', 'quickly', 'Quinn', 'quite', 'R', 'R2', 'race', 'races', 'radar', 'Radar', 'radial', 'Radial', 'radial basis functions', 'radiality', 'radiation', 'Radiation', 'radiation hybrid mapping', 'Radio', 'radio frequency', 'Radioactive', 'radiologist', 'radiologists', 'radius', 'Railway', 'railway', 'railway crossing region', 'railway-incidents', 'rainfall', 'Rainfall', 'raise', 'random', 'Random', 'random forest', 'random forests', 'random forests ', 'random projection', 'Randomized', 'randomized', 'randomly', 'Range', 'range', 'ranges', 'rank', 'Rank', 'ranked', 'rankers', 'ranking', 'Ranking', 'rankings', 'ranks', 'rankX', 'ransom', 'ransomware', 'Ransomware', 'rapid', 'rapidly', 'rare', 'rarely', 'rate', 'rated', 'rates', 'Rates', 'Rather', 'rather', 'rating', 'ratings', 'ratio', 'Ratio', 'rationale', 'ratios', 'raw', 'Raw', 'ray', 'RBF', 'RBFNN', 'RBFs', 'RBM', 'rbm', 'RBMs', 'RBSO', 'Rc', 'RDI', 'RDIL', 'RDM', 're', 'Re', 'reach', 'reaches', 'reaching', 'react', 'reaction', 'reactive', 'reactor', 'read', 'reader', 'readers', 'readily', 'reading', 'readings', 'reads', 'real', 'Real', 'real estate prediction', 'real-time recurrent learning (rtrl)', 'real-time systems', 'Realistic', 'realistic', 'realize', 'realized', 'really', 'realm', 'realworld', 'reanalysis', 'reason', 'reasonable', 'reasonably', 'Reasoning', 'reasoning', 'reasons', 'recall', 'recall of data', 'receive', 'Received', 'received', 'receiver', 'recent', 'Recent', 'recently', 'Recently', 'Recognition', 'recognition', 'recognize', 'recognized', 'recognizer', 'recognizing', 'Recognizing', 'recommend', 'Recommendation', 'recommendation', 'recommendation emails', 'recommendations', 'recommended', 'recommender', 'Recommender', 'recommender systems', 'recommender systems survey', 'Recommenders', 'recommenders', 'Recommending', 'recommending', 'recommends', 'Recompression', 'recompression', 'reconfigured', 'reconstruct', 'reconstructed', 'reconstructing', 'Reconstruction', 'reconstruction', 'reconstruction error', 'reconstructions', 'record', 'Record', 'record linkage', 'recorded', 'recording', 'recordings', 'records', 'recover', 'recovering', 'recovery', 'recruit', 'recruitment', 'rectangular', 'Recurrent', 'recurrent', 'recurrent neural network', 'recurrent processing', 'recursive', 'Recursive', 'recursive feature addition', 'REDD', 'rediscovering', 'redness', 'Reduce', 'reduce', 'Reduced', 'reduced', 'reduces', 'reducible', 'reducing', 'Reducing', 'reduction', 'Reduction', 'redundant', 'refactored', 'refactoring', 'Refactoring', 'reference', 'Reference', 'references', 'referred', 'referring', 'refers', 'refined', 'refining', 'reflect', 'reflects', 'reformulating', 'refresh', 'regard', 'Regarding', 'regarding', 'regardless', 'regards', 'regime', 'Regime', 'regime classification', 'regimes', 'region', 'Region', 'region of interest', 'regional', 'regions', 'Regions', 'registration', 'regression', 'Regression', 'regression trees', 'regressor', 'regressors', 'regret', 'regular', 'regularisation', 'regularization', 'Regularization', 'regularize', 'regularized', 'regularly', 'regulate', 'regulators', 'regulatory', 'Regulatory', 'rehabilitation', 'reinforced', 'Reinforcement', 'reinforcement', 'reinforcement learning', 'reinstatement', 'rejected', 'rejecting', 'rejection', 'Rejection', 'relabeling', 'relate', 'Related', 'related', 'relatedness', 'relates', 'Relation', 'relation', 'relational', 'relations', 'relationship', 'relationships', 'relative', 'relatively', 'relaxing', 'released', 'releases', 'Relevance', 'relevance', 'relevant', 'reliability', 'Reliable', 'reliable', 'reliably', 'reliance', 'relied', 'ReliefF', 'relies', 'religious', 'rely', 'relying', 'remain', 'remaining', 'remains', 'remarkable', 'remedial', 'Remedial', 'remember', 'remote', 'remote health care', 'Remotely', 'removal', 'Removal', 'remove', 'removed', 'removing', 'rendered', 'renewable', 'Renewable', 'renewable energy', 'repair', 'repeatable', 'repeatedly', 'repeating', 'Repetition', 'repetition', 'repetitive', 'replaced', 'Replacement', 'replacement', 'Replacing', 'replications', 'report', 'reported', 'reporting', 'Reporting', 'reports', 'repositories', 'Repository', 'repository', 'represent', 'representation', 'Representation', 'representation learning', 'Representations', 'representations', 'representative', 'represented', 'representing', 'represents', 'reproduce', 'reproduced', 'reproducing', 'request', 'Request', 'Requests', 'requests', 'require', 'required', 'requirement', 'requirements', 'requires', 'requiring', 'resample', 'resampled', 'resamples', 'Resampling', 'resampling', 'research', 'researched', 'researcher', 'researchers', 'researches', 'researching', 'Resembling', 'reserves', 'Reservoir', 'reservoir', 'reservoir level', 'residential', 'Residential', 'residents', 'Residual', 'resistance', 'ResNet', 'Resolution', 'resolution', 'resolutions', 'resolve', 'resolving', 'resonance', 'Resonance', 'resonance frequency', 'resorting', 'Resource', 'resource', 'resource exhausting', 'resource management', 'resources', 'respect', 'respectively', 'respond', 'respondents', 'Respondents', 'response', 'Response', 'response likelihood model', 'responses', 'responsibility', 'responsible', 'responsiveness', 'rest', 'Restart', 'restarted', 'restarts', 'Restoration', 'restoration', 'restore', 'restored', 'Restricted', 'restricted', 'restricted boltzmann machine', 'restrictions', 'restructuring', 'result', 'resultant', 'resulted', 'resulting', 'Results', 'results', 'retail', 'Retail', 'retained', 'retaining', 'retargeting', 'retention', 'Retention', 'retesting', 'rethink', 'retinal', 'Retinal', 'retinal image', 'retinas', 'retrained', 'retraining', 'Retrieval', 'retrieval', 'retrieve', 'retrieved', 'retrieves', 'retrieving', 'Retrieving', 'return', 'returned', 'returning', 'reuse', 'Reusing', 'reusing', 'reveal', 'revealed', 'revealing', 'reveals', 'revenue', 'reverse', 'review', 'Review', 'reviewed', 'Reviews', 'reviews', 'revise', 'revision', 'revolve', 'reward', 'Rewarding', 'rewards', 'Reweighting', 'reweighting', 'rewrite', 'RF', 'rfe', 'RGB', 'RH', 'rho', 'Rhythm', 'Ribeiro', 'rice', 'Rice', 'Rich', 'rich', 'richer', 'Ridge', 'ridge', 'ridge regression', 'RIDL', 'Riemannian', 'rife', 'right', 'RIMARC', 'ring', 'rise', 'rising', 'risk', 'Risk', 'RITM', 'rival', 'RKHS', 'RL', 'RLS', 'RME', 'RMSE', 'RNNs', 'road', 'Road', 'road accident', 'road transportation', 'roads', 'robot', 'Robot', 'robot control', 'robot sensing systems', 'robotic', 'Robots', 'robots', 'robust', 'Robust', 'robust learning', 'robustly', 'robustness', 'Robustness', 'RobustSPAM', 'ROC', 'roc analysis', 'Rocchio', 'ROI', 'role', 'Rolling', 'room', 'root', 'Roper', 'rotated', 'rotating', 'Rotation', 'rotation', 'rotations', 'Rough', 'rough', 'rough sets', 'rounds', 'routers', 'routes', 'routine behaviours', 'routing', 'Routing', 'routing and mobility management', 'ROV', 'row', 'rp trees', 'RRKOL', 'RRT', 'RSS', 'RSSI', 'RT', 'RTRL', 'rubrics', 'Rule', 'rule', 'rule extraction', 'rule-based classification', 'Rules', 'rules', 'run', 'running', 'runs', 'runtime', 'Runtime', 'runtime analysis', 's', 'S', 'sacked sparse autoencoders', 'sacrificing', 'safe', 'Safe', 'safety', 'Sagar', 'said', 'saidi forecast', 'sake', 'Salama', 'Sale', 'sales', 'Saliency', 'saliency', 'salient', 'same', 'Same', 'Sample', 'sample', 'sample reconstruction', 'sampled', 'sampler', 'samples', 'Samples', 'sampling', 'Sampling', 'Samsung', 'Sandbox', 'sanitizer', 'SAPS', 'satellites', 'satisfaction', 'Satisfaction', 'satisfactory', 'Satisficing', 'satisficing', 'satisfies', 'satisfy', 'satisfying', 'save', 'Save', 'saves', 'savings', 'saw', 'SAX', 'SB', 'SBC', 'SBME', 'SC', 'Sc', 'SCADA', 'scada data', 'scalability', 'scalable', 'Scalable', 'scale', 'Scale', 'scaled', 'Scaled', 'scales', 'Scaling', 'scaling', 'Scalp', 'scanned', 'scanner', 'scanners', 'scanning', 'scarcity', 'scatter', 'SCEFIS', 'scenario', 'scenario generation', 'scenarios', 'Scenarios', 'Scene', 'scene', 'scene matching', 'scenes', 'SCHDP', 'schedule', 'schedules', 'Scheduling', 'scheduling', 'schema', 'Schema', 'scheme', 'Scheme', 'schemes', 'Schmidt', 'school', 'schoolers', 'Schwarz', 'science', 'Science', 'Scientific', 'scientific', 'scientists', 'SCLDA', 'sclera', 'sclera segmentation', 'scoliosis', 'Scoliosis', 'scope', 'score', 'Score', 'score systems', 'scored', 'scores', 'scoring', 'Scoring', 'Scraper', 'scraping', 'scratch', 'screen', 'Screening', 'screening', 'SDA', 'sda', 'SDAM', 'SDN', 'sdncontroller', 'SDSM', 'sdsm', 'SE', 'sea', 'Sea', 'seam', 'seamless', 'seamlessly', 'Search', 'search', 'search by multiple examples', 'searches', 'searching', 'Searching', 'SEARCHSPN', 'season', 'seasonal', 'seasons', 'second', 'Second', 'secondary', 'seconds', 'secret', 'section', 'sectional', 'Sectional', 'sections', 'sector', 'sectors', 'secure', 'Secure', 'secure data aggregation model (sdam)', 'secured', 'Security', 'security', 'security strength', 'see', 'seed', 'seek', 'seeks', 'seem', 'seems', 'seen', 'Segment', 'segment', 'segmentation', 'Segmentation', 'Segmentations', 'segmentations', 'segmented', 'segmenting', 'segments', 'Seismic', 'seismic', 'Seizure', 'seizure', 'seizure detection', 'seizures', 'select', 'selected', 'Selecting', 'selecting', 'Selection', 'selection', 'Selections', 'selects', 'self', 'Self', 'self organization', 'self-organization parallelization', 'self-organizing map', 'self-organizing maps', 'self-supervised', 'seller', 'sellers', 'selling', 'semantic', 'Semantic', 'semantic slot labelling', 'semantic web', 'semantically', 'semantics', 'semester', 'semesters', 'semi', 'Semi', 'semi-arid climate', 'semi-supervised clustering', 'semi-supervised learning', 'semiconductor', 'Semiconductor', 'semiconductor manufacturing', 'semisupervised', 'send', 'sends', 'senior', 'sense', 'sensibly', 'sensing', 'sensitive', 'Sensitive', 'sensitivity', 'sensor', 'Sensor', 'sensor node (sn)', 'Sensors', 'sensors', 'sensory', 'sent', 'sentence', 'Sentence', 'sentences', 'sentiment', 'Sentiment', 'sentiment analysis', 'Sentimental', 'sep', 'separable', 'separate', 'separated', 'separately', 'separating', 'Separation', 'separation', 'Sequence', 'sequence', 'sequence classification', 'sequences', 'Sequences', 'sequencing', 'Sequential', 'sequential', 'sequential optimization', 'sequential pattern', 'sequentially', 'serendipitous discovery', 'series', 'Series', 'serious', 'serve', 'server', 'servers', 'serves', 'Service', 'service', 'service component architecture', 'service oriented architecture', 'services', 'Services', 'serving', 'SESDMK', 'session', 'sessions', 'Set', 'set', 'sets', 'Sets', 'setting', 'settings', 'setup', 'seven', 'several', 'Several', 'severe', 'severely', 'severity', 'Severity', 'sex', 'sexes', 'SFA', 'SG', 'SGD', 'shallow', 'Shannon', 'shape', 'shape recognition', 'shaped', 'shapes', 'shaping', 'Shapire', 'sharable', 'share', 'shared', 'shares', 'sharing', 'sharp', 'she', 'sheer', 'shelf', 'shift', 'shifts', 'Shin', 'shockingly', 'short', 'Short', 'short time series', 'shortcomings', 'shorten', 'shortening', 'shorter', 'shortest', 'Shot', 'shot', 'shot classification', 'shots', 'should', 'show', 'showcase', 'showed', 'showing', 'shown', 'shows', 'shrinking', 'shrinks', 'shutting', 'ShuttleTraq', 'siblings', 'side', 'Sided', 'sided', 'sides', 'SIEM', 'sigmoid', 'Sign', 'signal', 'Signal', 'signal analysis', 'signal processing', 'Signalling', 'signalling', 'Signals', 'signals', 'signature', 'Signature', 'Signatures', 'signatures', 'significance', 'significant', 'significantly', 'signifies', 'signs', 'silhouette', 'silicon', 'SIM', 'Similar', 'similar', 'similarities', 'similarity', 'Similarity', 'similarity analysis', 'similarity-based methods', 'similarly', 'Simple', 'simple', 'simpler', 'Simplicity', 'simplicity', 'Simplified', 'simplifying', 'simulate', 'simulated', 'simulating', 'simulation', 'Simulation', 'simulation-based training', 'simulations', 'Simulations', 'Simulator', 'simulator', 'simulators', 'Simultaneous', 'simultaneous eeg & fmri', 'Simultaneously', 'simultaneously', 'since', 'Since', 'singers', 'singing', 'Singing', 'singing style', 'singings', 'single', 'Single', 'singular', 'Singular', 'singular value decomposition', 'singular-value decomposition', 'Sinus', 'sinusoidal', 'site', 'Site', 'sites', 'situation', 'situations', 'six', 'sixty', 'size', 'Size', 'SizeConnectivity', 'sizes', 'skewed', 'skill', 'skip-gram', 'skyline extraction', 'slangs', 'Sleep', 'sleep', 'slept', 'SLGMM', 'SLI', 'slice', 'slices', 'slide', 'sliding', 'slight', 'slightly', 'Slot', 'slot', 'slots', 'Slow', 'slow', 'slowly', 'SLPCA', 'SM', 'Small', 'small', 'small footprint', 'small sample size problem', 'small world', 'smaller', 'smart', 'Smart', 'smart cities', 'smart city', 'smart energy', 'smart environment', 'smart grids', 'smart homes', 'smart housing', 'smart meter', 'smart meters', 'Smartphone', 'smartphone', 'sMDP', 'SMNet', 'SMO', 'Smooth', 'smooth', 'smoother', 'SMOTE', 'SMS', 'sms spam', 'sms text', 'snack', 'snacking', 'snacks', 'snakes', 'Snakes', 'snapshots', 'SNB', 'SNP', 'snp selection', 'SNPs', 'SNR', 'so', 'SO', 'So', 'social', 'Social', 'social media', 'social network analysis', 'social networks', 'SocialEQ', 'Socialized', 'socioeconomic', 'Socioeconomic', 'sociological', 'sociology', 'SOFM', 'SOFMs', 'Soft', 'soft', 'soft clustering', 'soft sets', 'software', 'Software', 'software architecture', 'software defect prediction', 'software defined networks', 'software effort estimation', 'software engineering', 'software enhancement duration prediction', 'software maintenance duration prediction', 'software-defined networking (sdn)', 'solar', 'Solar', 'solar energy', 'solar radiation', 'solely', 'solo', 'solution', 'Solution', 'Solutions', 'solutions', 'solve', 'solved', 'solver', 'Solver', 'solvers', 'solves', 'solving', 'SOM', 'Some', 'some', 'sometimes', 'Somewhat', 'somewhat', 'Sonar', 'songs', 'soon', 'sophisticated', 'Sound', 'sound', 'Soundex', 'soundex', 'source', 'Source', 'source code attributes', 'source-aware', 'Sourced', 'sourced', 'sources', 'Southern', 'SP', 'Space', 'space', 'space exploration', 'spaces', 'SPAM', 'Spam', 'spam', 'spam review', 'spamdexing', 'spammers', 'span', 'spanning', 'sparse', 'Sparse', 'sparse autoencoders', 'sparse methods', 'sparseness', 'sparsification', 'Sparsity', 'sparsity', 'Spatial', 'spatial', 'spatially', 'Spatio', 'spatio', 'spatio-temporal data', 'spatiotemporal', 'Speaker', 'speaker', 'speaker adaptation', 'speaker identification', 'spearman', 'SPEC2000', 'special', 'specialists', 'specialized', 'specially', 'specialties', 'Species', 'species', 'specific', 'Specific', 'specifically', 'Specifically', 'specification', 'specifications', 'specificity', 'specified', 'specify', 'spectra', 'Spectra', 'Spectral', 'spectral', 'spectral clustering', 'spectral learning', 'spectrogram', 'spectrograms', 'spectroscopy', 'spectrum', 'Spectrum', 'speech', 'Speech', 'speech enhancement', 'speech intelligibility', 'speech quality', 'speech recognition', 'speech separation', 'Speed', 'speed', 'Speeding', 'speeding', 'speedup', 'SPEI', 'spending', 'spent', 'sphere', 'spheres', 'spike', 'Spike', 'spike train', 'spike-event', 'Spiking', 'spiking', 'spiking neural network (snn)', 'spine', 'split', 'Splitting', 'splitting', 'splitting criteria', 'SPNs', 'spoken', 'spontaneous', 'spores', 'sport', 'Sport', 'sports', 'Sports', 'Spotting', 'spotting', 'Spread', 'spread', 'spreading', 'SQL', 'sql injection attack', 'sqli', 'Square', 'square', 'Squared', 'squared', 'Squares', 'SSH', 'SSL', 'SSVEP', 'stability', 'Stability', 'stability analysis', 'stability-plasticity dilemma', 'stable', 'stack', 'Stack', 'Stacked', 'stacked', 'stacked denoising autoencoders', 'stacking', 'Stacking', 'stacks', 'staff', 'staffing', 'stage', 'Stage', 'stages', 'stakeholders', 'stance', 'Standard', 'standard', 'standardized', 'standardized precipitation index', 'standards', 'Standards', 'standing', 'star', 'star glyph plot', 'start', 'starting', 'starts', 'stat', 'state', 'State', 'state abstraction', 'state-space model', 'stated', 'statements', 'stateof', 'states', 'static', 'Station', 'station', 'Stationarity', 'stationary', 'Stations', 'stations', 'statistic', 'statistical', 'Statistical', 'statistical analysis', 'statistical downscaling', 'statistical image clutter metrics', 'statistical learning', 'statistical methods', 'statistical process control', 'statistical regression', 'statistical word alignment', 'statistically', 'statistics', 'Status', 'status', 'stay', 'Stay', 'steady', 'steady state visual evoked potential', 'steganography', 'Steganography', 'stem', 'Stem', 'stem cell transplant', 'stems', 'step', 'steps', 'Stick', 'sticky', 'still', 'stimuli', 'stimulus', 'Stochastic', 'stochastic', 'stochastic gradient descent', 'stochastic local search', 'stochastic processes', 'stochastically', 'stock', 'Stock', 'stock trading points', 'stoke', 'stone', 'Stop', 'stops', 'storage', 'storage system', 'store', 'stored', 'stores', 'Stores', 'stories', 'storing', 'storm', 'Storm', 'storylines', 'straggler', 'stragglers', 'Stragglers', 'straight', 'strategic', 'strategies', 'Strategies', 'strategy', 'Strategy', 'stream', 'streamflow', 'Streamflow', 'streaming', 'Streaming', 'streaming data', 'streamline', 'Streams', 'streams', 'Strength', 'strength', 'strengths', 'stress', 'stresses', 'strict', 'stride', 'strike', 'striking', 'string', 'stringent', 'strings', 'striving', 'Stroke', 'stroke', 'strong', 'Strong', 'strongly', 'structural', 'Structure', 'structure', 'structure learning', 'structured', 'Structures', 'structures', 'structuring', 'struggling', 'stuck', 'student', 'Student', 'student dropout', 'student retention', 'student success', 'students', 'studied', 'Studies', 'studies', 'Studio', 'Study', 'study', 'studying', 'style', 'Style', 'styles', 'stylistic', 'stylometric', 'Stylometry', 'stylometry', 'stylus', 'sub', 'subatomic', 'subbands', 'subclass', 'subgroup', 'subgroups', 'Subject', 'subject', 'subjective', 'subjects', 'submarket', 'submarkets', 'submetering', 'submitted', 'suboptimal', 'subpopulations', 'subregions', 'subsampling', 'subsequences', 'subsequent', 'subsequently', 'Subsequently', 'subset', 'Subset', 'subsethood', 'subsets', 'subsetting', 'subsignals', 'subspace learning', 'subspaces', 'substantial', 'substantially', 'substi', 'substitutability', 'substitute', 'substitutions', 'subsystems', 'subtask', 'subtle', 'subtly', 'subtraction', 'Subtraction', 'subtypes', 'suburb', 'success', 'Success', 'Successes', 'successes', 'successful', 'successfully', 'successively', 'such', 'Such', 'sudden', 'suffer', 'suffers', 'sufficiency', 'sufficient', 'sufficiently', 'suggest', 'suggested', 'suggests', 'suitability', 'suitable', 'suite', 'suited', 'Sum', 'sum', 'sum product networks', 'summaries', 'summarization', 'Summarization', 'summarize', 'summarizes', 'summarizing', 'summary', 'Summary', 'summer', 'sundown', 'sunshine', 'Sunspot', 'sunspot', 'superfunction', 'superfunctions', 'superior', 'superiority', 'Superposed', 'superposed', 'Supervised', 'supervised', 'supervised classification', 'supervised learning', 'supervised machine learning', 'Supervision', 'Supervisory', 'supplemented', 'supplied', 'suppliers', 'supply', 'Support', 'support', 'support vector egression', 'support vector machine', 'support vector machine learning', 'support vector machines', 'support vector machines (svm)', 'support vector machines plus', 'support vector regression', 'supported', 'supporting', 'Supporting', 'Supportive', 'supports', 'surely', 'surface', 'Surface', 'surface images', 'surfaces', 'surpass', 'surpasses', 'surrogate', 'surrogates', 'surrounding', 'surveillance', 'Surveillance', 'survey', 'Survey', 'survey datasets', 'surveys', 'survive', 'susceptible', 'suspiciousness', 'sustainability', 'SVD', 'SVHN', 'SVM', 'svm', 'svm classification', 'SVMs', 'svr', 'SVR', 'SVRs', 'swap', 'Swarm', 'swarm', 'swiftly', 'Swing', 'swing', 'swing detection', 'swing sports', 'Switch', 'switched', 'Switched', 'switching', 'Sybil', 'sybil account', 'Sybils', 'syllable', 'syllable segmentation', 'Symbolic', 'symbolically', 'symbolized', 'symbols', 'symptoms', 'synapses', 'Synchronization', 'synchronization', 'synchronized', 'Synchronous', 'synchronous', 'synergistic', 'synergy', 'syntactics', 'Syntax', 'syntax', 'synthesisers', 'synthetic', 'Synthetic', 'synthetic oversampling', 'synthetization', 'Synthetizing', 'System', 'system', 'system-level testing', 'systematic', 'systematically', 'systems', 'Systems', 'systems biology', 't', 'T', 'tables', 'tablet', 'tackle', 'tackled', 'tag', 'tagging', 'tags', 'tail', 'tailored', 'take', 'taken', 'takes', 'taking', 'talker', 'talking', 'taller', 'tampering', 'tan', 'tangent bundle manifold learning', 'tapes', 'target', 'target detection', 'target tracking', 'targeted', 'targeting', 'Tariff', 'tariff', 'Task', 'task', 'tasking', 'tasks', 'Tasks', 'taxonomic', 'taxonomical', 'taxonomy', 'TCGA', 'TCP', 'tcp/ip model', 'TD', 'teach', 'teachers', 'teaches', 'teaching', 'Team', 'team', 'teams', 'tear', 'tech', 'technical', 'technicians', 'technique', 'Technique', 'techniques', 'Techniques', 'technological', 'technologies', 'Technology', 'technology', 'tecture', 'tedious', 'teeth', 'telecommunication', 'tells', 'temperature', 'Temperature', 'temperature measurement', 'temperatures', 'template', 'template matching', 'template-security', 'temporal', 'Temporal', 'temporal pattern', 'temporal segmentation', 'temporally', 'Temporally', 'temporary', 'ten', 'tend', 'tended', 'tendencies', 'tends', 'tenfold', 'tennis', 'Tennis', 'TennisTraq', 'Term', 'term', 'termed', 'terminal', 'terminology', 'terms', 'territory', 'tertiary', 'TEs', 'test', 'TEST', 'Test', 'test case prioritization', 'test code size', 'testability', 'testbed', 'tested', 'testing', 'tests', 'Tests', 'Text', 'text', 'text analysis', 'text categorization', 'text mining', 'text similarity', 'text summarization', 'texts', 'textual', 'TFBS', 'th', 'thalassemia', 'than', 'thanks', 'That', 'that', 'the', 'The', 'the lasso estimate', 'theft', 'their', 'Their', 'them', 'theme', 'themselves', 'then', 'Then', 'theorem', 'theoretic', 'Theoretical', 'theoretical', 'theoretically', 'theories', 'theory', 'Theory', 'therapeutic', 'therapy', 'there', 'There', 'thereby', 'Therefore', 'therefore', 'thereof', 'thermal', 'These', 'these', 'thesis', 'they', 'They', 'thin', 'Thin', 'thin film flow equation', 'things', 'Things', 'thinking', 'third', 'Third', 'This', 'this', 'Thompson', 'Thoracolumbosacral', 'thorough', 'thoroughly', 'those', 'Though', 'though', 'thought', 'thousands', 'thread', 'Threat', 'threat', 'threaten', 'threatened', 'threatening', 'threats', 'Three', 'three', 'threefold', 'threshold', 'Threshold', 'Thresholding', 'thresholding', 'thresholds', 'thriving', 'through', 'Through', 'throughout', 'throw', 'Thus', 'thus', 'Thyme', 'tial', 'tightness', 'time', 'Time', 'time series', 'time series analysis', 'time series classification', 'time series clustering', 'time series forecasting', 'time series prediction', 'time series representation', 'time-frequency analysis', 'time-series analysis', 'time-series data', 'time-varying impact', 'timed', 'timeframes', 'Timeline', 'timeline', 'timely', 'times', 'timescales', 'timeseries', 'timestamped', 'timestamping', 'timestamps', 'timetabling', 'Timing', 'timing', 'TIMIT', 'Tissue', 'tissue', 'TLSO', 'to', 'To', 'today', 'Together', 'together', 'toll', 'Tomography', 'tomography', 'tomorrow', 'too', 'took', 'Tool', 'tool', 'tools', 'Tools', 'top', 'Top', 'topic', 'Topic', 'topic detection', 'topic model', 'topic model labeling', 'topic modeling', 'topic models', 'topic novelty detection', 'topic-semantic indexing (tsi)', 'topical', 'topical ontology', 'topics', 'topmost', 'topological', 'Topologically', 'topologies', 'topology', 'Topology', 'topology mamagement', 'Toponogov', 'total', 'Touchless', 'TourMiner', 'tours', 'Toward', 'toward', 'Towards', 'towards', 'TPU', 'trace', 'traces', 'Track', 'track', 'tracked', 'tracker', 'Tracker', 'trackers', 'Tracking', 'trackIng', 'tracking', 'tracks', 'TRACLUS', 'traclus clustering', 'tractable', 'TRACULUS', 'trade', 'tradeoff', 'trading', 'Trading', 'Traditional', 'traditional', 'traditional machine learning', 'Traditionally', 'traditionally', 'Traffic', 'traffic', 'traffic flow prediciton', 'traffic flow prediction', 'traffic prediction', 'Train', 'train', 'trained', 'Training', 'training', 'training data', 'training simulations', 'training speed', 'training with noisy data', 'trains', 'trait', 'traits', 'trajectories', 'Trajectories', 'trajectory', 'Trajectory', 'trajectory analysis', 'trajectory planning in road traffic', 'transaction', 'transactional', 'transactions', 'transcribe', 'Transcription', 'transcription', 'transductive', 'Transductive', 'transductive learning', 'Transfer', 'transfer', 'transfer learning', 'transferable', 'transferred', 'transferring', 'Transform', 'transform', 'transformation', 'transformations', 'transformed', 'transformer', 'Transformer', 'transforming', 'transforms', 'transfusion', 'Transient', 'transient', 'transit', 'transition', 'transitions', 'translate', 'translated', 'translating', 'translation', 'transmission', 'Transmission', 'transmit', 'transmitted', 'transmitters', 'transparency', 'transparent', 'Transplant', 'transport', 'transportation', 'Transposable', 'travel', 'TRCM', 'treasure', 'treat', 'treated', 'Treating', 'treating', 'Treatment', 'treatment', 'treats', 'tree', 'Tree', 'trees', 'Trees', 'trend', 'Trend', 'trend prediction', 'trends', 'Trends', 'trial', 'trials', 'triangles', 'triaxial', 'trick', 'tried', 'tries', 'trigger', 'triggers', 'trimmed', 'trips', 'trivial', 'troublesome', 'true', 'Trunk', 'trusted', 'truth', 'truthful', 'truthfulness', 'truths', 'try', 'trying', 'TSD', 'TSI', 'tsvm', 'TubeSpam', 'tumour', 'tuned', 'Tuning', 'tuning', 'tuning curve', 'turbidity', 'Turbine', 'turbine', 'turbines', 'Turbines', 'Turbulence', 'turbulence', 'turbulence modeling', 'turbulent', 'Turing', 'Turkey', 'Turkish', 'turkish ner', 'turkish universities', 'turn', 'turning', 'turns', 'tutability', 'tutorials', 'Tutoring', 'TV', 'Tweet', 'tweet', 'tweet mining', 'tweets', 'Tweets', 'twenty', 'Twin', 'twin', 'twitter', 'Twitter', 'two', 'Two', 'two-sided markets', 'twovalued', 'type', 'Type', 'types', 'Types', 'Typical', 'typical', 'Typically', 'typically', 'U', 'ubiquitous', 'ubiquitous monitoring', 'UCB1', 'UCF50', 'UCI', 'UCP', 'UCR', 'UK', 'UK2006', 'UK2007', 'Ukraine', 'ultimate', 'ultimately', 'ultra', 'Ultra', 'ultra-wide band radar', 'UMTS', 'un', 'unable', 'unaffected', 'unavailability', 'unavailable', 'unavoidable', 'unaware', 'Unbalanced', 'unbalanced', 'unbalanced data', 'unbiased', 'uncertain', 'uncertain labels', 'uncertainties', 'uncertainty', 'Uncertainty', 'uncertainty quantification', 'unclear', 'unconventional', 'uncoupled', 'uncover', 'Under', 'under', 'undergoes', 'undergraduate', 'underlying', 'underpinning', 'Understading', 'understand', 'Understand', 'understanding', 'Understanding', 'understood', 'undertaken', 'underused', 'underwater', 'undesirable', 'unequal', 'Unexpected', 'unexpected', 'unexpectedly', 'unfamiliar', 'unfavorable', 'Unfortunately', 'uni', 'unicellular', 'Unification', 'unifies', 'uniformly', 'unifying', 'uninterrupted', 'Union', 'union of intersections', 'unique', 'Unique', 'uniqueness', 'Unit', 'unit', 'units', 'Units', 'Univariate', 'univariate', 'universal', 'universality', 'Universities', 'universities', 'university', 'University', 'unknown', 'Unlabeled', 'unlabeled', 'unlabelled', 'Unlike', 'unlike', 'unordered', 'unpleasant', 'unpractical', 'unprecedented', 'unrealistic', 'unregistered', 'unreliable', 'unscheduled', 'unseen', 'unsolicited electronic mail', 'unsolved', 'unstructured', 'unsubscribe', 'Unsupervised', 'unsupervised', 'unsupervised clustering', 'unsupervised feature learning', 'unsupervised learning', 'unsupervised machine learning', 'unsupervised-learning', 'until', 'Until', 'untruthful', 'unvetted', 'unwanted', 'unwavering', 'UoI', 'Up', 'up', 'Update', 'update', 'updated', 'updates', 'updating', 'uploaded', 'uploading', 'upon', 'upper', 'upper bound', 'upright', 'upstairs', 'URAP', 'urap rankings', 'urban', 'Urbansound8k', 'urgent', 'UrSGP', 'US', 'us', 'USA', 'usability', 'usable', 'Usage', 'usage', 'usages', 'use', 'Use', 'Used', 'used', 'Useful', 'useful', 'usefulness', 'useless', 'Useless', 'useless words', 'User', 'user', 'user modeling', 'user profiles', 'Users', 'users', 'uses', 'Using', 'using', 'USP', 'usual', 'Usual', 'Usually', 'usually', 'utilise', 'utilities', 'utility', 'utilization', 'utilize', 'utilized', 'utilizes', 'utilizing', 'Utilizing', 'utmost', 'UWB', 'v', 'valid', 'validate', 'validated', 'validating', 'validation', 'Validation', 'validity', 'valuable', 'value', 'Value', 'Valued', 'valued', 'values', 'valves', 'Vancouver', 'variability', 'Variable', 'variable', 'variable selection', 'variables', 'Variance', 'variance', 'variance inflation factor', 'variance of query response', 'variant', 'variants', 'variation', 'Variational', 'variational', 'variational bayes', 'variational em', 'variational inference', 'Variations', 'variations', 'varied', 'varies', 'variety', 'Various', 'various', 'variously', 'vary', 'varying', 'Varying', 'varying coefficient model', 'vascularization', 'vast', 'VC', 'VCPSs', 'Vdeo', 've', 'Vector', 'vector', 'vectors', 'Vectors', 'vegetation', 'Vehicle', 'vehicle', 'vehicles', 'vehicular', 'Vehicular', 'vehicular cyber-physical systems', 'velocity', 'vendor', 'ventilation', 'Ventilation', 'veracity', 'verbal', 'Verification', 'verified', 'verifies', 'verify', 'version', 'versions', 'versus', 'Versus', 'Vertical', 'vertical', 'vertical handoff (vho)', 'vertical scaling', 'vertices', 'very', 'Very', 'vetting', 'VGG', 'Vgg', 'VHO', 'via', 'victim', 'victims', 'Victoria', 'Video', 'video', 'video event', 'video indexing', 'video steganography', 'video understanding', 'videos', 'view', 'viewed', 'viewing', 'viewpoint', 'views', 'VIF', 'violated', 'violating', 'violations', 'violent', 'VIRAT', 'virtual', 'Virtual', 'virtual world', 'virtually', 'virus', 'viruses', 'viscous', 'viscous reconstruction', 'visibility', 'visible', 'visibly', 'vision', 'Vision', 'visitors', 'visual', 'Visual', 'visual classification', 'visual inspection', 'visualise', 'Visualising', 'visualising', 'visualization', 'visually', 'vital', 'viz', 'VLP', 'VOC', 'vocal', 'vocalist', 'vocalists', 'vocalizations', 'voice', 'Voice', 'Voiceprint', 'voiceprint', 'volatile', 'volatility', 'voltage', 'Voltage', 'volume', 'volumes', 'voluminous', 'volunteers', 'von', 'von mises distribution', 'VOR', 'vote', 'Vote', 'votes', 'voting', 'vs', 'vulnerabilities', 'vulnerability', 'Vulnerable', 'vulnerable', 'W', 'waikato environment for knowledge analysis (weka)', 'walk', 'walking', 'WannaCry', 'want', 'war', 'warehouse', 'warm', 'warming', 'warning', 'Warning', 'warns', 'warping', 'Warping', 'was', 'Washington', 'waste', 'wasting', 'water', 'Water', 'Watershed', 'Watson', 'wave', 'wavelengths', 'wavelet', 'Wavelet', 'wavelet analysis', 'wavelet coefficients', 'Wavelets', 'waves', 'way', 'ways', 'wban security', 'WBANs', 'WCDN', 'WCDNs', 'We', 'WE', 'we', 'weak', 'weakly supervised learning', 'weaknesses', 'weapon', 'wear', 'wearable', 'Wearable', 'wearable sensors', 'wearables', 'weather', 'Weather', 'weather forecasting', 'web', 'Web', 'web application', 'web based games', 'web based information sources', 'web caching', 'web robots', 'web scraping', 'web servers', 'web spam', 'website', 'websites', 'WEBSPAM', 'weed', 'weekly', 'weeks', 'weighed', 'weight', 'Weight', 'weight convergence and robust stability', 'weighted', 'Weighted', 'weighting', 'weights', 'weka', 'WEKA', 'Welch', 'well', 'wellknown', 'were', 'wet', 'WH', 'what', 'What', 'whatever', 'wheel', 'Wheel', 'wheel alignment', 'wheeze', 'Wheezing', 'When', 'when', 'whenever', 'where', 'whereas', 'whereby', 'whether', 'Whether', 'Which', 'which', 'While', 'while', 'Whilst', 'white', 'who', 'whole', 'whose', 'why', 'Wide', 'wide', 'widely', 'widespread', 'width', 'widths', 'WiFi', 'wifi', 'wifi csi data mining', 'wifi slam', 'Wilcoxon', 'wild', 'wildlife', 'will', 'Wilsons', 'Wind', 'wind', 'wind power forecasting', 'wind power plant', 'wind speed', 'wind turbine', 'winding', 'Windings', 'window', 'windows', 'winner', 'winning', 'winter', 'wire', 'Wireless', 'wireless', 'wireless communication', 'wireless sensor network (wsn)', 'wireless sensor networks (wsns)', 'with', 'With', 'within', 'Within', 'Without', 'without', 'witnessed', 'WMA', 'Women', 'women', 'word', 'Word', 'word embedding', 'word embeddings', 'word vectors', 'words', 'Words', 'Work', 'work', 'worked', 'workers', 'working', 'workload', 'workload characterization', 'workloads', 'Workloads', 'works', 'World', 'world', 'worlds', 'worldwide', 'worn', 'worse', 'worst', 'worth', 'worthwhile', 'would', 'Wrapped', 'Wrapper', 'wrapper', 'wrist', 'writing', 'written', 'wrong', 'wrote', 'WSN', 'WSNs', 'www', 'Wyoming', 'x', 'X', 'xgboost', 'XGBoost', 'XOR', 'xray', 'Yale', 'year', 'yearly', 'years', 'yet', 'Yet', 'yield', 'yielded', 'yielding', 'yields', 'YorNoise', 'your', 'YouTube', 'youtube', 'Youtube', 'zero', 'Zero', 'zero-shot learning', 'Zirkler']\n"
     ]
    }
   ],
   "source": [
    "# Lo ordenamos\n",
    "seenGenerico = list(set(listaPalabrasTotal))\n",
    "#seenGenerico.sort()\n",
    "otroTes = sorted(seenGenerico, key=str.lower)\n",
    "#print(len(seenGenerico))\n",
    "#print(seenGenerico)\n",
    "print(len(otroTes))\n",
    "print(otroTes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9847e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1534\n",
      "['2-dim distance measure', '2d:4d', '3d shapes', '3d-convnets', 'abnormal event detection', 'academic success', 'accelerometer', 'accelerometer data', 'accelerometers', 'accreditation and assesments', 'accuracy', 'achievements information', 'acoustic feature learning', 'action bank features', 'activation function', 'active contour method', 'active learning', 'active set shrinking', 'activity detection', 'activity forecasting', 'activity recognition', 'adaptation method', 'adaptation models', 'adaptive approaches', 'adaptive learning', 'adaptive scheduling', 'adaptive threshold', 'adenoviral conjunctivitis (pink eye)', 'adversarial machine learning', 'afis', 'age', 'aggregated netflows', 'aggression', 'agriculture', 'air combat', 'algorithm', 'algorithm design and analysis', 'algorithm recognition', 'algorithm selection', \"alzheimer's disease\", \"alzheimer's disease stage detection\", 'american sign language', 'anaemia', 'anchored synchronization', 'android', 'anns', 'anomaly', 'anomaly detection', 'anomaly prediction', 'anonymity', 'anonymization', 'ant colony optimization', 'anytime algorithm', 'ap imashups', 'appearance-based learning', 'application', 'application essay', 'application layer ddos', 'applications', 'approximate computing', 'approximate inference', 'approximation algorithms', 'approximation methods', 'arctic sea ice', 'arima', 'arma', 'artifial neural network model', 'artificial defects', 'artificial intelligence', 'artificial neural network', 'artificial neural network (ann)', 'artificial neural networks', 'artificial-neural-network', 'association map', 'association rules', 'associative classification', 'associative memory', 'attack', 'attacks', 'audio', 'audio captcha', 'audio equalizer', 'audio signal', 'audiogram', 'authentication', 'authentication graphs', 'author classification', 'autism spectrum disorder', 'autocorrelation-function-(acf)', 'autoencoder', 'autoencoders', 'automated classification', 'automatic', 'automatic diagnosis', 'automatic gender estimation', 'automatic scoring', 'automatic speech recognition', 'automation', 'automobiles', 'automotive security', 'autoregressive processes', 'auxiliary objectives', 'availability', 'back-propagation-algorithm', 'backpropagation', 'badminton', 'bag-of-concepts', 'bag-of-pattern', 'bagging', 'balanced k-means', 'ballistocardiogram artifact', 'bandwidth', 'bartlett tests', 'base station (bs)', 'basis selection', 'batteries', 'bayes classifier', 'bayes methods', 'bayesian', 'bayesian analysis', 'bayesian classification', 'bayesian inference', 'bayesian network', 'bayesian networks', 'bayesian nonparametrics', 'bayesian-networks', 'bearing defects', 'benchmarks', 'best subset linear regression', 'bifurcation', 'big data', 'big data analytics', 'big data clustering', 'big healthcare data', 'big mobile social data', 'big-data', 'bilateral filter', 'binary classification', 'binary codes', 'bio-acoustics', 'bio-detection', 'bioinformatics', 'biological neural networks', 'biological system modeling', 'biomarker', 'biomedical informatics', 'biometric', 'biometric recognition', 'biometrics', 'bipartite graphs', 'bipartite ranking problem', 'bird call identification', 'bitcoin', 'black-box testing', 'blind source seperation', 'blockchain', 'blog spam', 'blogs', 'blunder', 'boolean networks', 'boosting', 'bootstrap', 'bootstrap approaches', 'boundary value problems', 'box office', 'brace treatment', 'brain', 'brain computer interface', 'brand perception', 'breaking news', 'breast cancer', 'brute force', 'budgeted learning', 'buildings', 'bus transportation', 'business', 'c++ languages', 'cameras', 'can bus', 'canal command', 'cancer', 'cancer detection', 'canonical correlation analysis', 'canopy algorithm', 'car following model', 'careerbuilder', 'cascaded sparse autoencoders', 'cascading style sheets', 'case management', 'case-based reasoning', 'causal discovery', 'cell images', 'cepstral coefficients', 'cfrp', 'cgp', 'cgpann', 'challenging behaviors', 'chess', 'child support', 'choice', 'chord', 'churn prediction', 'class decomposition', 'class imbalance', 'classification', 'classification algorithms', 'classification techniques', 'classifier ensemble', 'climate', 'climate science', 'clnn', 'clo', 'clone refactoring', 'cloud computing', 'cloud data security', 'cloud-oriented architecture', 'cluster analysis', 'cluster data', 'cluster forest', 'cluster head (ch)', 'cluster size distribution', 'cluster validation', 'cluster validity', 'clustering', 'clustering algorithms', 'cm-knn', 'cma-es', 'cnn', 'cold-start problem', 'collaboration', 'collaboration network', 'collaborative filtering', 'collaborative learning', 'collaborative recommendation', 'collector apis', 'colorization', 'coloured petri nets', 'combination forgery', 'combinatorial optimization', 'combinatorial reverse auctions', 'comment features', 'comment spam detection', 'common metric learning', 'compactness measure of clusters', 'companies', 'comparative market analysis', 'comparative study', 'completeness', 'complex event programming', 'complexity reduction', 'component based design petri nets', 'compounds', 'compression algorithms', 'computational modeling', 'computer crime', 'computer generated forces', 'computer science', 'computer vision', 'computer-aided detection (cad)', 'computer-aided diagnosis', 'computers', 'conditional neural networks', 'conditional restricted boltzmann machine', 'conferences', 'confidence region', 'conformal prediction', 'conformation motion', 'confusion matrix', 'connected vehicles', 'constraint programming', 'constraint satisfaction problem', 'content caching', 'content spam', 'context', 'context aware', 'contextual similarity', 'contour recognition', 'contour representations', 'control', 'control period computational burden', 'control system', 'control systems', 'convergence', 'convolution filtering', 'convolutional neural nets', 'convolutional neural network', 'convolutional neural networks', 'convolutional neural networks (cnn)', 'convolutional neural networks (cnns)', 'cooperative adaptive cruise control', 'cooperative systems', 'coordinate descent', 'coreference', 'correlation', 'cost sensitive classification', 'cost-sensitive learning', 'counters', 'covariance matrix', 'cpd', 'crbm', 'credit default swap', 'credit scoring', 'crime prediction', 'cross lingual', 'cross-validation', 'crowd-sourcing', 'crowdsourcing', 'crude oil price forecasting', 'cruise control', 'ct images', 'ct prediction', 'curve simplification', 'cwt', 'cyber forensic', 'cyber security', 'cyber-security vulnerabilities', 'cyberattack', 'cybersecurity', 'cybersecurity applications', 'cyclic contrastive divergence learning', 'cytoskeleton', 'czech ner', 'data analysis', 'data analytics', 'data augmentation', 'data clustering', 'data contamination', 'data diversity', 'data integration', 'data mining', 'data models', 'data modification intrusion detection', 'data privacy', 'data stream', 'data stream with concept drift', 'data warehouse', 'data-acquisition', 'data-driven', 'databases', 'dbn', 'dbpedia ontology', 'dc-dc converter', 'dc/dc-boost-converter', 'dct', 'decision making', 'decision support', 'decision support system', 'decision tree', 'decision trees', 'declarative learning', 'decomposition-based reinforcement learning', 'deconvolutional networks (deconvnet)', 'decorrelation', 'deep convolutional network', 'deep learning', 'deep neural network', 'deep neural networks', 'deep regression model', 'deep reinforcement learning', 'dehazing', 'delay', 'delayed labels', 'demand forecast', 'demographic group prediction', 'denial-of-service (dos)', 'depressive disorders', 'dh-hemts', 'diabetes', 'diagnosabiliy', 'dimensional reduction', 'dimensionality reduction', 'dirichlet process', 'disaggregation', 'discourse', 'discrete cosine transforms', 'discrete event systems', 'discrete fourier', 'discrete-event systems', 'discretization', 'discretize', 'diseases', 'distinctness measure of clusters', 'distributed computing', 'distributed data clustering', 'distributed sgd', 'distributed simulation', 'divisive analysis', 'dnn', 'document classification', 'documentation', 'domain class imbalance', 'domain knowledge', 'domestic hot water', 'donor selection', 'dos attack', 'driver behavior', 'drives', 'drop out technique', 'drought modelling', 'drug-design', 'dwt', 'dynamic clustering', 'dynamic factor analysis', 'dynamic kernels', 'dynamic programming', 'dynamic system', 'dynamic web domain', 'dynamical systems', 'e-commerce', 'ea+rl', 'earth levee', 'ecg', 'education', 'educational analytics', 'educational data mining', 'educational data mining (edm)', 'educational institutions', 'eeg signals', 'eembedding payload', 'effective sample size', 'efficiency', 'effort prediction', 'eigenfaces', 'eigenvalues', 'eigenvector', 'electrical engineering', 'electricity market', 'electricity retail markets', 'electrocardiography', 'electroencephalogram', 'electronic mail', 'embedded methods', 'embedding efficiency', 'empirical mode decomposition', 'encryption', 'energy end-use model', 'energy management', 'energy saving', 'engagement detection', 'ensemble', 'ensemble clustering', 'ensemble learning', 'ensemble method', 'ensemble methods', 'ensembles', 'entity extraction', 'environmental sound recognition', 'epilepsy', 'epileptogenesis', 'equal loudness contour', 'equations', 'equipment condition diagnosis (ecd)', 'error analysis', 'error entropy', 'esm', 'esr', 'estimation', 'estimation of students successes', 'evaporation', 'event coreference', 'event detection', 'event related potentials', 'evidential database', 'evolutionary algorithms', 'evolutionary based learning', 'evolutionary computing', 'evolving (fuzzy) classifiers', 'evolving fuzzy systems', 'evolving graph', 'evolving networks', 'exact inference', 'expectation maximization', \"expected change in classifier's accuracy\", 'expert knowledge', 'expert systems', 'exponential regression', 'extraction patterns', 'extreme verification latency', 'face', 'face recognition', 'facial expression recognition', 'fake user accounts', 'fans', 'fault data injection', 'fault detection', 'fault detection and classification (fdc)', 'fault diagnosis', 'fault fingerprint extraction', 'fault localization', 'faults localization', 'fdd', 'feature', 'feature aware', 'feature discovery', 'feature extraction', 'feature fusion', 'feature learning', 'feature recognition', 'feature selection', 'feature vector', 'features selection', 'feed-forward networks', 'filtering', 'financial markets', 'fine tuning', 'fingerprint', 'fingerprinting', 'finite-state machines', 'firewalls (computing)', 'firmlp', 'fisher vector (fv) feature representation', 'flexibility', 'floods', 'flow forecast', 'folding', 'force plate', 'forecast combination', 'forecasting', 'forecasting energy demand', 'foreclosure-and-real-estate-market', 'formal modeling', 'forums', 'forward looking sonars', 'four dimension', 'fraud detection', 'frequency response analysis fra', 'frequent patterns', 'frequent sequence pattern mining', 'frequent set mining', 'function approximation', 'functional connectivity', 'functional dependency', 'functional time series', 'fusion', 'fuzzy', 'fuzzy clustering', 'fuzzy discrete event system', 'fuzzy logic', 'fuzzy operations', 'fuzzy rules', 'fuzzy soft sets', 'fuzzy systems', 'fuzzy-logic-controller', 'fuzzy-neighborhood density-based clustering', 'gain parameter and drop out technique', 'gait analysis', 'game theory', 'game-data', 'games', 'gamma distribution', 'gamma-ray spectra', 'gaussian mixture', 'gaussian mixture model', 'gaussian mixture model (gmm)', 'gaussian process', 'gaussian process regression', 'gaussian processes', 'gaussian radial basis function', 'gcm data', 'gender identification', 'gene coexpression networks', 'gene expression data', 'generative learning', 'generative models', 'genetic algorithm', 'genetic algorithms', 'genetic optimization and supervision', 'genetics', 'genome analysis toolkit (gatk)', 'genome wide association studies', 'genomic data', 'geometrical analysis', 'geophysical', 'gestational hypertension', 'glass', 'global optimization', 'gmm', 'google', 'google cloud vision api', 'government', \"gower's measure of similarity\", 'gpgpu', 'gplvm', 'gps', 'gpu computing', 'grabcut', 'gradient approximation', 'grammar', 'granger-causality', 'granular computing', 'graph representation', 'graph sequence', 'graph theory', 'graphical model', 'graphical models', 'gray-level co-occurrence matrix (glcm)', 'grib', 'grid-connected-pv-system', 'group based labeling', 'group diversity', 'gui', 'hamming codes', 'handwritten digit recognition', 'health social networks', 'healthcare fraud', 'healthcare systems', 'heart disease', 'heart rate', 'hedonic pricing model', 'hedonic theory', 'hemiplegic gait', \"henze-zirkler's multivariate normality test\", 'heterogeneous-data', 'heuristic word alignment', 'hidden markov model', 'hidden markov model (hmm)', 'hidden markov models', 'hierachical graph neuron', 'hierarchical bayesian model', 'hierarchical classification', 'hierarchical clustering', 'hierarchical dirichlet process', 'hierarchical learning', 'high voltage feeder', 'high-dimensional data', 'high-dimensional input', 'high-order rbms', 'histograms', 'history', 'hmm', 'home appliances', 'horizon line detection', 'hotspot mapping', 'housing prices prediction', 'html', 'human action recognition', 'human activity recognition', 'human behavior prediction', 'human tracking', 'hybrid', 'hybrid algorithms', 'hybrid electric vehicles', 'hybrid learning algorithms', 'hybrid-neurone-fuzzy', 'hydroelectric', 'hyperparameter optimization', 'hypopnea', 'identification-recognition', 'image classification', 'image descriptors', 'image forgery detection', 'image matching', 'image noise', 'image processing', 'image restoration', 'image segmentation', 'image segments', 'image synthetization', 'image-based diagnosis', 'imbalance', 'imbalanced classes', 'implicit feedback', 'importance sampling', 'improvement', 'imputation', 'in-hospital length of stay prediction', 'in-memory distribution', 'incident-ranking', 'inconsistency', 'index and ring finger ratio', 'indexes', 'indoor localization', 'indoor user movement', 'induction motors', 'inductive logic programming', 'inertial measurement units', 'inferential reasoning', 'information extraction', 'information need modeling', 'information retrieval', 'information theoretic learning', 'information theory', 'informative weight', 'inpainting', 'insolation period', 'inspection', 'instance selection', 'instance weighting', 'instant message', 'integrated circuits', 'integration of new classes on-the-fly', 'integrative complexity', 'intelligent agent', 'intelligent systems', 'intelligent tutoring systems', 'intensive care units', 'interactive evolutionary computation', 'interactive systems', 'internet of things', 'interpretability', 'interpretable machine learning', 'interpretable modeling', 'interpretation', 'interval-radial algorithm', 'intervention systems', 'intrusion detection', 'intrusion detection &amp; defence', 'intrusion detection system', 'intrusiondetection', 'intuitionistic fuzzy stes', 'inverse gaussian regression', 'inverse reinforcement learning', 'inverse-inference', 'inverted dirichlet', 'iot', 'ip networks', 'iris', 'irradiance', 'isbsg', 'item popularity', 'iterative methods', 'jensen-shannon divergence', 'job recommendation email system', 'joint inference', 'jpeg', 'k-means', 'k-means clustering', 'k-medoids', 'k-nearest neighbor', 'k-nearest neighbor classifier (knn)', 'k-nn', 'kaiser-meyer-olkin', 'kd-trees', 'kegg signalling pathways', 'kernel', 'kernel function', 'kernel functions', 'kernel k-means', 'kernel method', 'kernel methods', 'kernel online learning', 'kernel ridge regression', 'keystroke dynamics', 'keystroke feature', 'keyword spotting', 'khepera', 'kidney segmentation', 'kmeans clustering', 'knn', 'knn classification model', 'knowledge base', 'knowledge discovery', 'knowledge graphs', 'knowledge topology and acquisition', 'knowledge-discovery', 'kohonen self organizing network', 'l1 norm', 'l2 norm', 'label noise', 'label propagation', 'labeling', 'language modeling', 'large data', 'large scale', 'large scale network flow', 'lasso regression', 'latent dirichlet allocation', 'latent semantic indexing', 'lateral movement', 'layered learning', 'lcm', 'lda', 'learning (artificial intelligence)', 'learning classifier systems', 'learning convex function', 'learning from interpretation transition', 'learning systems', 'least absolute shrinkage and selection operator (lasso)', 'legged locomotion', 'lesions', 'level-k thinking', 'libs', 'license plate recognition system', 'lifelong machine learning', 'linear programming', 'linear regression', 'linguistic features', 'link prediction', 'liver segmentation', 'local binary patterns', 'logistic regression', 'logistics', 'logsigmoid function', 'long short-term memory', 'long-short term memory', 'longitudinal data', 'loss minimization', 'low-rank approximation', 'lp-norm estimators', 'lung cancer', 'machine learning', 'machine learning algorithm (mla)', 'machine learning algorithms', 'machine learning application', 'machine learning as a service', 'machine learning techniques', 'machine-learning', 'machine-sourced', 'magnetic field', 'majority vote rule', 'malware', 'malware classification', 'manifold learning', 'manifold learning regression', 'manufacturing', 'maple', 'mapreduce', 'margin', 'markov decision process', 'markov decision processes', 'markov logic networks', 'markov network', 'markov switching model', 'markov(k)', 'masked conditional neural networks', 'mass deaths', 'mass transfer', 'master degree in information technology', 'mathematica', 'mathematical model', 'matrix decomposition', 'max-min distance algorithm', 'maximum a posteriori', 'maximum likelihood estimation', 'maximum-power-point-tracker', 'mclnn', 'measurement', 'medical image analysis', 'medical informatics', 'meta-algorithms', 'meta-heuristic prediction algorithm', 'meta-recommendation system', 'metabolomics', 'metadata', 'metasoundex', 'meteorology', 'metric learning', 'metrics', 'mfccs', 'mhealth', 'microalgae classification', 'microtubules', 'mimics', 'minimum description length', 'mininet', 'mining big data', 'minutia code', 'minutiae', 'mislabeled data', 'missing at random', 'missing data', 'mixed data', 'mixture model', 'mixture models', 'mixture of experts', 'mlp', 'mnist', 'mnist variations', 'mobile computing', 'mobile robot self-localization', 'mobile robots', 'mobile security', 'mobile store security', 'model building', 'model calibration', 'model checking', 'model post processing', 'model transformatiomn', 'modeling', 'monitoring', 'monte carlo', 'monte carlo methods', 'mortality rate prediction', 'motion capture (mocap)', 'motion-based multiple object tracking', 'movie', 'moving target defense', 'mr images', 'mrmr', 'multi agent systems', 'multi instance classification', 'multi-armed bandit', 'multi-armed bandits', 'multi-corpora', 'multi-density clustering', 'multi-label classification', 'multi-label classifiers', 'multi-label learning', 'multi-linear regression model', 'multi-objective evolutionary algorithm', 'multi-objective particle swarm optimization', 'multi-objective reinforcement learning', 'multi-objectivization', 'multi-period prediction', 'multi-scale', 'multi-strategy learning', 'multi-task learning', 'multi-valued models', 'multiclass classification', 'multilayer feedforward neural network', 'multilayer network', 'multilingual', 'multimedia signal processing', 'multimedia structure analysis', 'multimodal', 'multiobjectivization', 'multiple classifier systems', 'multiple instance learning', 'multiple kernel learning', 'multiple object tracking', 'multivariate analyses', 'multiview data', 'music', 'music event', 'mutual information', 'naive bayes', 'naive bayes classifier', 'named entity recognition', 'narx', 'narx neural network', 'natural language processing', 'ndt', 'near infrared', 'nearest neighbor', 'nearest neighbor search', 'negative images', 'nelder-mead algorithm (nma)', 'network attacks', 'network communities', 'network data', 'network inference', 'network intrusion detection system (nids)', 'network layer', 'network representation learning', 'network topology', 'networked control system', 'networks', 'neural network', 'neural network based machine learning', 'neural network classifier', 'neural networks', 'neurocrfs', 'neuroevolution', 'neurofuzzy system', 'neurons', 'neuroscience', 'new event types', 'next generation sequence (ngs)', 'next generation wireless networks', 'nir', 'nlp', 'nn-based fault detection algorith', 'node similarities', 'noise', 'noise estimation', 'noise reduction', 'noisy data', 'noisy training data', 'non intrusive load monitoring', 'non negative matrix factorization', 'non stationary time-series', 'non-linearity', 'non-personalized single heuristic strategies', 'non-stationary', 'nonlinear dynamics', 'nonnegative matrix factorization', 'nonparametric bayesian', 'nonstationary processes', 'nontechnical loss', 'nonword stimuli repetition', 'normalization', 'notifications', 'novelty search', 'nuclear magnetic resonance', 'number of clusters in a dataset', 'numerical models', 'numerical simulation', 'nutrition', 'object oriented software', 'object recognition', 'object tracking', 'objective selection', 'oblivion criterion', 'oblivious routing scheme', 'obstructive apnea', 'occlusion', 'oceanography', 'ompt', 'on-line learning', 'one-way anova', 'online clustering', 'online k-means clustering', 'online learning', 'online process monitoring', 'online selection', 'ontology learning', 'openmp tasks', 'opinion extraction', 'optimal control', 'optimization', 'optimum path forest', 'optimum-path forest', 'organ segmentation', 'organic computing', 'orphan node prediction', 'orthogonal matching pursuit', 'outlier', 'outlier detection', 'outliers', 'outsourcing', 'over dispersion', 'palynology', 'parallel processing', 'parallelized sgd', 'parameter control', \"parkinson's disease\", 'partial-autocorrelation-function-(pacf)', 'particle swarm optimization', 'partitional clustering', 'partitioning', 'partitioning algorithms', 'partitioning clustering', 'parts based decompositions', 'passive seismic', 'patent', 'pattern matching', 'pattern recognition', 'pca', 'pcr', 'penalization', 'performance', 'performance evaluation', 'personalized item', 'personalized treatment', 'phase identification', 'phenotype prediction', 'phoneme', 'phoneme classification', 'phoneme prediction', 'pid control', 'piecewise linear', 'pipeline', 'pitch system', 'platform', 'platform as a service', 'plsa', 'pollen classification', \"poppelreuter's test\", 'ports (computers)', 'positive unlabeled learning', 'post-processing', 'potentials', 'power density', 'power grid analysis', 'power spectral density analysis', 'power systems', 'pre school', 'predict', 'predictability', 'predicting psychosis', 'prediction', 'prediction algorithms', 'predictive analysis', 'predictive data analytics', 'predictive model', 'predictive modelling', 'predictive models', 'predictive scoring systems', 'preference prediction technique', 'preprocessing', 'primal dual algorithm', 'principal component analysis', 'principal components analysis', 'principal-component analysis', 'principle component analysis', 'privacy', 'privacy policy', 'privacy preserving', 'privacy-preserving', 'probabilistic atlas', 'probabilistic logic', 'probabilistic matrix factorization', 'probabilistic programming', 'probability', 'probability of classification error', 'probit regression', 'process control', 'profitability', 'programmers', 'programming', 'protein conformation', 'protocols', 'pruning', 'pull request', 'pv system', 'q learning', 'q-learning', 'qos over heterogeneous networks', 'qpcr', 'quadratic programming', 'quality assessment', 'query relaxation', 'radial basis functions', 'radiality', 'radiation hybrid mapping', 'radio frequency', 'railway crossing region', 'railway-incidents', 'random forest', 'random forests', 'random forests ', 'random projection', 'rbm', 'real estate prediction', 'real-time recurrent learning (rtrl)', 'real-time systems', 'recall of data', 'recognition', 'recommendation emails', 'recommender systems', 'recommender systems survey', 'recompression', 'reconstruction', 'reconstruction error', 'record linkage', 'recurrent neural network', 'recurrent processing', 'recursive feature addition', 'regime classification', 'region of interest', 'regression', 'regression trees', 'regularization', 'reinforcement learning', 'rejection', 'reliability', 'remote health care', 'renewable energy', 'repair', 'representation', 'representation learning', 'resampling', 'reservoir level', 'resonance frequency', 'resource exhausting', 'resource management', 'response likelihood model', 'restricted boltzmann machine', 'resultant', 'retinal image', 'rfe', 'ridge', 'ridge regression', 'road accident', 'road transportation', 'roads', 'robot control', 'robot sensing systems', 'robots', 'robust', 'robust learning', 'robustness', 'roc analysis', 'rough sets', 'routine behaviours', 'routing and mobility management', 'rp trees', 'rubrics', 'rule extraction', 'rule-based classification', 'runtime', 'runtime analysis', 'sacked sparse autoencoders', 'saidi forecast', 'saliency', 'sample reconstruction', 'sanitizer', 'satisficing', 'scada data', 'scalability', 'scenario generation', 'scene matching', 'sclera segmentation', 'scoliosis', 'score systems', 'sda', 'sdncontroller', 'sdsm', 'search by multiple examples', 'secure data aggregation model (sdam)', 'security', 'security strength', 'segmentation', 'seizure detection', 'selection', 'self organization', 'self-organization parallelization', 'self-organizing map', 'self-organizing maps', 'self-supervised', 'semantic slot labelling', 'semantic web', 'semantics', 'semi-arid climate', 'semi-supervised clustering', 'semi-supervised learning', 'semiconductor manufacturing', 'sensitivity', 'sensor node (sn)', 'sensors', 'sentiment analysis', 'sequence classification', 'sequential optimization', 'sequential pattern', 'serendipitous discovery', 'servers', 'service component architecture', 'service oriented architecture', 'shape recognition', 'short time series', 'shot classification', 'sigmoid', 'signal analysis', 'signal processing', 'signature', 'silicon', 'similarity analysis', 'similarity-based methods', 'simulation', 'simulation-based training', 'simultaneous eeg & fmri', 'singing style', 'singular value decomposition', 'singular-value decomposition', 'skip-gram', 'skyline extraction', 'small footprint', 'small sample size problem', 'small world', 'smart cities', 'smart city', 'smart energy', 'smart environment', 'smart grids', 'smart homes', 'smart housing', 'smart meter', 'smart meters', 'smartphone', 'sms spam', 'sms text', 'snacks', 'snakes', 'snp selection', 'social media', 'social network analysis', 'social networks', 'sociology', 'soft clustering', 'soft sets', 'software', 'software architecture', 'software defect prediction', 'software defined networks', 'software effort estimation', 'software engineering', 'software enhancement duration prediction', 'software maintenance duration prediction', 'software-defined networking (sdn)', 'solar energy', 'solar radiation', 'soundex', 'source code attributes', 'source-aware', 'space exploration', 'spam', 'spam review', 'spamdexing', 'sparse autoencoders', 'sparse methods', 'sparsification', 'spatio-temporal data', 'speaker adaptation', 'speaker identification', 'spectral clustering', 'spectral learning', 'speech enhancement', 'speech intelligibility', 'speech quality', 'speech recognition', 'speech separation', 'spike train', 'spike-event', 'spiking neural network (snn)', 'splitting criteria', 'sql injection attack', 'sqli', 'stability', 'stability analysis', 'stability-plasticity dilemma', 'stacked denoising autoencoders', 'stacking', 'standard', 'standardized precipitation index', 'standards', 'star glyph plot', 'state abstraction', 'state-space model', 'statistical analysis', 'statistical downscaling', 'statistical image clutter metrics', 'statistical learning', 'statistical methods', 'statistical process control', 'statistical regression', 'statistical word alignment', 'statistics', 'steady state visual evoked potential', 'stem cell transplant', 'stochastic gradient descent', 'stochastic local search', 'stochastic processes', 'stock trading points', 'storage system', 'straggler', 'streamflow', 'streaming', 'streaming data', 'structure learning', 'student dropout', 'student retention', 'student success', 'stylometry', 'subspace learning', 'sum product networks', 'summarization', 'superfunctions', 'supervised classification', 'supervised learning', 'supervised machine learning', 'support vector egression', 'support vector machine', 'support vector machine learning', 'support vector machines', 'support vector machines (svm)', 'support vector machines plus', 'support vector regression', 'surface images', 'survey datasets', 'svm', 'svm classification', 'svr', 'swing detection', 'swing sports', 'sybil account', 'syllable segmentation', 'synchronization', 'syntactics', 'synthetic oversampling', 'system-level testing', 'systems biology', 'tangent bundle manifold learning', 'target detection', 'target tracking', 'tariff', 'taxonomy', 'tcp/ip model', 'teeth', 'temperature measurement', 'template matching', 'template-security', 'temporal pattern', 'temporal segmentation', 'tennis', 'test case prioritization', 'test code size', 'testing', 'text analysis', 'text categorization', 'text mining', 'text similarity', 'text summarization', 'the lasso estimate', 'thin film flow equation', 'thresholding', 'time series', 'time series analysis', 'time series classification', 'time series clustering', 'time series forecasting', 'time series prediction', 'time series representation', 'time-frequency analysis', 'time-series analysis', 'time-series data', 'time-varying impact', 'timetabling', 'tools', 'topic detection', 'topic model', 'topic model labeling', 'topic modeling', 'topic models', 'topic novelty detection', 'topic-semantic indexing (tsi)', 'topical ontology', 'topology', 'topology mamagement', 'traclus clustering', 'traditional machine learning', 'traffic flow prediciton', 'traffic flow prediction', 'traffic prediction', 'training', 'training data', 'training simulations', 'training speed', 'training with noisy data', 'trajectory analysis', 'trajectory planning in road traffic', 'transductive learning', 'transfer learning', 'transformer', 'transforms', 'transparency', 'trend prediction', 'tsvm', 'tuning', 'tuning curve', 'turbulence modeling', 'turkish ner', 'turkish universities', 'tweet mining', 'twitter', 'two-sided markets', 'ubiquitous monitoring', 'ultra-wide band radar', 'unbalanced data', 'uncertain labels', 'uncertainty', 'uncertainty quantification', 'underwater', 'union of intersections', 'unordered', 'unsolicited electronic mail', 'unsupervised clustering', 'unsupervised feature learning', 'unsupervised learning', 'unsupervised machine learning', 'unsupervised-learning', 'upper bound', 'urap rankings', 'useless words', 'user modeling', 'user profiles', 'validation', 'validity', 'valves', 'variable selection', 'variance inflation factor', 'variance of query response', 'variational bayes', 'variational em', 'variational inference', 'varying coefficient model', 'vascularization', 'vectors', 'vegetation', 'vehicles', 'vehicular cyber-physical systems', 'vertical handoff (vho)', 'vertical scaling', 'video event', 'video indexing', 'video steganography', 'video understanding', 'virtual world', 'viscous reconstruction', 'visual classification', 'visual inspection', 'visualising', 'visualization', 'voice', 'voiceprint', 'von mises distribution', 'vulnerability', 'waikato environment for knowledge analysis (weka)', 'wavelet', 'wavelet analysis', 'wavelet coefficients', 'wban security', 'weakly supervised learning', 'wearable sensors', 'weather', 'weather forecasting', 'web application', 'web based games', 'web based information sources', 'web caching', 'web robots', 'web scraping', 'web servers', 'web spam', 'weight convergence and robust stability', 'weka', 'wheel alignment', 'wheeze', 'wifi', 'wifi csi data mining', 'wifi slam', 'wind power forecasting', 'wind power plant', 'wind speed', 'wind turbine', 'wireless communication', 'wireless sensor network (wsn)', 'wireless sensor networks (wsns)', 'word embedding', 'word embeddings', 'word vectors', 'workload characterization', 'xgboost', 'youtube', 'zero-shot learning']\n"
     ]
    }
   ],
   "source": [
    "seenKeywords = list(set(listaTotalKeywords))\n",
    "keywordsOrigin = sorted(seenKeywords, key=str.lower)\n",
    "print(len(keywordsOrigin))\n",
    "print(keywordsOrigin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2828e18",
   "metadata": {},
   "source": [
    "Ahora este resultado se debe guardar para un uso posterior. No debemos ejecutar las líneas de arriba de nuevo a menos que debamos corregir algo.\n",
    "\n",
    "Tras leer del fichero, debemos crear el diccionario y un array adecuado para definir dichas palabras como números. Tambiñen es útil sacar los keywords para hacer lo mismo y optimizar el resultado de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e92fe7a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open(\"palabrasEntrada.txt\", \"w\")\n",
    "f.write(str(otroTes))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "12e07bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"keywordsIniciales.txt\", \"w\")\n",
    "f.write(str(keywordsOrigin))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8d0aa67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9727\n"
     ]
    }
   ],
   "source": [
    "# FASE 1: Los de arriba ya no se vuelven a ejecutar, reabrimos y pasamos a lista\n",
    "try:\n",
    "    f = open(\"palabrasEntrada.txt\", \"r\")\n",
    "    cadenaMensaje = f.read()\n",
    "except:\n",
    "    print(\"FILE NOT FOUND!\")\n",
    "    cadenaMensaje = \"ERROR\"\n",
    "finally:  \n",
    "    res = ast.literal_eval(cadenaMensaje)\n",
    "    print(len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11c5b03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1534\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    f = open(\"keywordsIniciales.txt\", \"r\")\n",
    "    cadenaRetornoKeywords = f.read()\n",
    "except:\n",
    "    print(\"FILE NOT FOUND!\")\n",
    "    cadenaRetornoKeywords = \"[]\"\n",
    "finally:  \n",
    "    misKeywordsRetornadas = ast.literal_eval(cadenaRetornoKeywords)\n",
    "    print(len(misKeywordsRetornadas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86123a00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<UNU>': 0, 'EsteValorEstaMuyDesconocido': 1, '': 2, '0': 3, '000': 4, '0003': 5, '01': 6, '04': 7, '05': 8, '06': 9, '09': 10, '1': 11, '10': 12, '100': 13, '1000': 14, '100s': 15, '101': 16, '104': 17, '106': 18, '108': 19, '109': 20, '11': 21, '116': 22, '12': 23, '120': 24, '123': 25, '13': 26, '130': 27, '14': 28, '15': 29, '153600': 30, '16': 31, '160': 32, '1635': 33, '17': 34, '178': 35, '18': 36, '1833': 37, '1874': 38, '19': 39, '1915': 40, '1H': 41, '2': 42, '2-dim distance measure': 43, '20': 44, '2004': 45, '2006': 46, '2007': 47, '2009': 48, '2010': 49, '2011': 50, '2012': 51, '2013': 52, '2015': 53, '2016': 54, '2017': 55, '2099': 56, '21': 57, '211': 58, '216': 59, '22': 60, '23': 61, '24': 62, '243': 63, '25': 64, '250': 65, '2586': 66, '26': 67, '27': 68, '28': 69, '29': 70, '2D': 71, '2d:4d': 72, '2v1': 73, '2v2': 74, '3': 75, '30': 76, '31': 77, '31m': 78, '33': 79, '34': 80, '35': 81, '3521': 82, '36': 83, '37': 84, '39': 85, '3960': 86, '3D': 87, '3d': 88, '3d shapes': 89, '3d-convnets': 90, '3MW': 91, '4': 92, '40': 93, '41': 94, '410': 95, '412': 96, '42': 97, '43': 98, '44160': 99, '47': 100, '49': 101, '4D': 102, '4th': 103, '5': 104, '50': 105, '500': 106, '5000': 107, '53': 108, '54': 109, '55': 110, '56': 111, '563': 112, '59': 113, '6': 114, '60': 115, '61': 116, '63': 117, '65': 118, '67': 119, '68': 120, '7': 121, '70': 122, '72': 123, '74': 124, '75': 125, '76': 126, '77': 127, '78': 128, '79': 129, '8': 130, '80': 131, '800': 132, '81': 133, '82': 134, '83': 135, '85': 136, '86': 137, '87': 138, '88': 139, '89': 140, '9': 141, '90': 142, '901': 143, '91': 144, '92': 145, '93': 146, '94': 147, '95': 148, '97': 149, '98': 150, '99': 151, 'A': 152, 'a': 153, 'A2': 154, 'AAL': 155, 'AAPL': 156, 'abbreviations': 157, 'ABC': 158, 'abdominal': 159, 'Abdominal': 160, 'Abductive': 161, 'abilities': 162, 'Ability': 163, 'ability': 164, 'able': 165, 'abnormal': 166, 'Abnormal': 167, 'abnormal event detection': 168, 'abound': 169, 'about': 170, 'above': 171, 'ABP': 172, 'absence': 173, 'absent': 174, 'absolute': 175, 'Absolute': 176, 'Abstraction': 177, 'abstraction': 178, 'abstractions': 179, 'abundance': 180, 'abundant': 181, 'ACA': 182, 'academia': 183, 'Academic': 184, 'academic': 185, 'academic success': 186, 'acapella': 187, 'accelerate': 188, 'Accelerated': 189, 'accelerates': 190, 'accelerating': 191, 'acceleration': 192, 'accelerometer': 193, 'Accelerometer': 194, 'accelerometer data': 195, 'accelerometers': 196, 'acceptable': 197, 'Acceptance': 198, 'acceptance': 199, 'accepting': 200, 'access': 201, 'Access': 202, 'accessible': 203, 'accessing': 204, 'accession': 205, 'accident': 206, 'Accident': 207, 'accidents': 208, 'accommodate': 209, 'accompanying': 210, 'accomplish': 211, 'accomplished': 212, 'accorded': 213, 'According': 214, 'according': 215, 'accordingly': 216, 'Account': 217, 'account': 218, 'accounting': 219, 'Accounting': 220, 'accounts': 221, 'Accounts': 222, 'accreditation': 223, 'accreditation and assesments': 224, 'accumulate': 225, 'accumulator': 226, 'accuracies': 227, 'accuractely': 228, 'Accuracy': 229, 'accuracy': 230, 'Accurate': 231, 'accurate': 232, 'accurately': 233, 'ACF': 234, 'achievable': 235, 'achieve': 236, 'achieved': 237, 'Achievement': 238, 'achievement': 239, 'achievements': 240, 'Achievements': 241, 'achievements information': 242, 'achieves': 243, 'achieving': 244, 'acid': 245, 'acids': 246, 'acoustic': 247, 'Acoustic': 248, 'acoustic feature learning': 249, 'acquire': 250, 'acquired': 251, 'acquiring': 252, 'Acquiring': 253, 'acquisition': 254, 'Acquisition': 255, 'across': 256, 'Action': 257, 'action': 258, 'action bank features': 259, 'actionable': 260, 'Actions': 261, 'actions': 262, 'activation': 263, 'activation function': 264, 'activations': 265, 'Active': 266, 'active': 267, 'active contour method': 268, 'active learning': 269, 'active set shrinking': 270, 'actively': 271, 'Activities': 272, 'activities': 273, 'activity': 274, 'Activity': 275, 'activity detection': 276, 'activity forecasting': 277, 'activity recognition': 278, 'actual': 279, 'actually': 280, 'actuation': 281, 'acute': 282, 'Acute': 283, 'Acyclic': 284, 'acyclic': 285, 'Adaboost': 286, 'ADAGRAD': 287, 'adapt': 288, 'adaptable': 289, 'Adaptation': 290, 'adaptation': 291, 'adaptation method': 292, 'adaptation models': 293, 'adaptations': 294, 'adapted': 295, 'adapting': 296, 'adaptive': 297, 'Adaptive': 298, 'adaptive approaches': 299, 'adaptive learning': 300, 'adaptive scheduling': 301, 'adaptive threshold': 302, 'adaptively': 303, 'Adaptively': 304, 'adapts': 305, 'Adatron': 306, 'add': 307, 'added': 308, 'Added': 309, 'adding': 310, 'Adding': 311, 'Addition': 312, 'addition': 313, 'additional': 314, 'additionally': 315, 'Additionally': 316, 'Address': 317, 'address': 318, 'addressed': 319, 'addresses': 320, 'addressing': 321, 'adds': 322, 'Adenoviral': 323, 'adenoviral conjunctivitis (pink eye)': 324, 'adequate': 325, 'adequately': 326, 'adjacent': 327, 'adjust': 328, 'adjusted': 329, 'Adjustment': 330, 'adjustment': 331, 'adjustments': 332, 'Administration': 333, 'Administrators': 334, 'administrators': 335, 'Admission': 336, 'admission': 337, 'admitted': 338, 'ADMM': 339, 'adolescent': 340, 'adolescents': 341, 'adopt': 342, 'adopted': 343, 'Adopted': 344, 'adopting': 345, 'adopts': 346, 'adult': 347, 'advance': 348, 'advanced': 349, 'Advanced': 350, 'advancement': 351, 'advancements': 352, 'advances': 353, 'Advances': 354, 'advantage': 355, 'advantages': 356, 'Adventure': 357, 'Adversarial': 358, 'adversarial': 359, 'adversarial machine learning': 360, 'adversaries': 361, 'adversary': 362, 'adverse': 363, 'advertising': 364, 'advice': 365, 'advise': 366, 'AF': 367, 'affect': 368, 'affected': 369, 'affecting': 370, 'affective': 371, 'affects': 372, 'Affinity': 373, 'affordability': 374, 'affordable': 375, 'afforded': 376, 'affords': 377, 'afingerprint': 378, 'afis': 379, 'aforementioned': 380, 'after': 381, 'After': 382, 'afterstate': 383, 'Afterward': 384, 'Afterwards': 385, 'again': 386, 'against': 387, 'Age': 388, 'age': 389, 'aged': 390, 'agencies': 391, 'agent': 392, 'Agent': 393, 'agents': 394, 'ages': 395, 'agglomerations': 396, 'agglomerative': 397, 'aggregate': 398, 'Aggregate': 399, 'Aggregated': 400, 'aggregated': 401, 'aggregated netflows': 402, 'aggregates': 403, 'aggregating': 404, 'aggregation': 405, 'Aggregation': 406, 'aggregator': 407, 'aggression': 408, 'Aggressive': 409, 'agricultural': 410, 'agriculture': 411, 'Ahead': 412, 'ahead': 413, 'AHTD': 414, 'AI': 415, 'AIC': 416, 'aid': 417, 'aided': 418, 'aiding': 419, 'aids': 420, 'ailments': 421, 'aim': 422, 'Aim': 423, 'aimed': 424, 'aiming': 425, 'aims': 426, 'air': 427, 'Air': 428, 'air combat': 429, 'aircraft': 430, 'Akaike': 431, 'al': 432, 'Alamos': 433, 'Alarm': 434, 'alarm': 435, 'alarmingly': 436, 'Alarms': 437, 'alarms': 438, 'alerts': 439, 'Alfortville': 440, 'algebraic': 441, 'algorithm': 442, 'Algorithm': 443, 'algorithm design and analysis': 444, 'algorithm recognition': 445, 'algorithm selection': 446, 'algorithmic': 447, 'Algorithms': 448, 'algorithms': 449, 'alicious': 450, 'align': 451, 'aligned': 452, 'Aligned': 453, 'Aligning': 454, 'alignment': 455, 'Alignment': 456, 'alignments': 457, 'All': 458, 'all': 459, 'alleviating': 460, 'AllMusic': 461, 'allocation': 462, 'Allocation': 463, 'allocations': 464, 'allow': 465, 'allowed': 466, 'allowing': 467, 'allows': 468, 'almost': 469, 'alone': 470, 'along': 471, 'already': 472, 'Also': 473, 'also': 474, 'alter': 475, 'altering': 476, 'alternate': 477, 'Alternating': 478, 'alternative': 479, 'alternatives': 480, 'although': 481, 'Although': 482, 'always': 483, 'Always': 484, 'Alzheimer': 485, \"alzheimer's disease\": 486, \"alzheimer's disease stage detection\": 487, 'Amazon': 488, 'ambient': 489, 'Ambient': 490, 'ambulatory': 491, 'America': 492, 'American': 493, 'american sign language': 494, 'amino': 495, 'Among': 496, 'among': 497, 'amount': 498, 'amounts': 499, 'Amphiphilic': 500, 'amplification': 501, 'amplitude': 502, 'An': 503, 'an': 504, 'anaemia': 505, 'analogue': 506, 'analyse': 507, 'analysed': 508, 'analyses': 509, 'Analyses': 510, 'analysis': 511, 'Analysis': 512, 'analytic': 513, 'analytical': 514, 'analytics': 515, 'Analytics': 516, 'analyze': 517, 'analyzed': 518, 'Analyzer': 519, 'analyzer': 520, 'analyzes': 521, 'analyzing': 522, 'Analyzing': 523, 'anatomical': 524, 'anatomy': 525, 'anchored': 526, 'anchored synchronization': 527, 'AND': 528, 'And': 529, 'and': 530, 'android': 531, 'Android': 532, 'Anemia': 533, 'anemia': 534, 'angels': 535, 'angle': 536, 'angles': 537, 'animal': 538, 'ANN': 539, 'annotated': 540, 'annotations': 541, 'Annotations': 542, 'annoyance': 543, 'ANNs': 544, 'anns': 545, 'annual': 546, 'anomalies': 547, 'anomalous': 548, 'Anomaly': 549, 'anomaly': 550, 'anomaly detection': 551, 'anomaly prediction': 552, 'anonymity': 553, 'anonymization': 554, 'anonymized': 555, 'anonymizing': 556, 'anonymous': 557, 'another': 558, 'Another': 559, 'ANOVA': 560, 'answer': 561, 'answered': 562, 'ANT': 563, 'ant colony optimization': 564, 'antecedent': 565, 'Antecedent': 566, 'anti': 567, 'anticipated': 568, 'antivirus': 569, 'anxiety': 570, 'Anxiety': 571, 'any': 572, 'Any': 573, 'anytime': 574, 'Anytime': 575, 'anytime algorithm': 576, 'ap imashups': 577, 'APACHE': 578, 'APARF': 579, 'aparments': 580, 'apart': 581, 'API': 582, 'APIs': 583, 'Apnea': 584, 'apnea': 585, 'App': 586, 'appear': 587, 'Appearance': 588, 'appearance': 589, 'appearance-based learning': 590, 'appears': 591, 'Appliance': 592, 'appliance': 593, 'appliances': 594, 'applicability': 595, 'applicable': 596, 'applicants': 597, 'Applicants': 598, 'application': 599, 'Application': 600, 'application essay': 601, 'application layer ddos': 602, 'Applications': 603, 'applications': 604, 'applied': 605, 'Applied': 606, 'applies': 607, 'apply': 608, 'Applying': 609, 'applying': 610, 'appraised': 611, 'appraisers': 612, 'approach': 613, 'Approach': 614, 'approached': 615, 'approaches': 616, 'Approaches': 617, 'appropriate': 618, 'approximate': 619, 'approximate computing': 620, 'approximate inference': 621, 'approximated': 622, 'approximately': 623, 'Approximately': 624, 'approximates': 625, 'approximating': 626, 'approximation': 627, 'approXimation': 628, 'Approximation': 629, 'approximation algorithms': 630, 'approximation methods': 631, 'approximations': 632, 'approximator': 633, 'Approximators': 634, 'approximators': 635, 'apps': 636, 'Apps': 637, 'Appstore': 638, 'arbitrary': 639, 'Archi': 640, 'Architecture': 641, 'architecture': 642, 'architectures': 643, 'archives': 644, 'Arctic': 645, 'arctic sea ice': 646, 'are': 647, 'Are': 648, 'area': 649, 'Area': 650, 'areas': 651, 'arenas': 652, 'arguably': 653, 'argue': 654, 'argued': 655, 'Argument': 656, 'arguments': 657, 'Arid': 658, 'arid': 659, 'ARIMA': 660, 'arima': 661, 'arise': 662, 'arises': 663, 'Arising': 664, 'arising': 665, 'arm': 666, 'arma': 667, 'ARMA': 668, 'armed': 669, 'arms': 670, 'arose': 671, 'around': 672, 'Array': 673, 'Arrhythmia': 674, 'arrhythmias': 675, 'arrival': 676, 'arrivals': 677, 'arrive': 678, 'arriving': 679, 'ARSpread': 680, 'art': 681, 'arterial': 682, 'article': 683, 'articles': 684, 'Artifact': 685, 'artifact': 686, 'artifacts': 687, 'artifial neural network model': 688, 'artificial': 689, 'Artificial': 690, 'artificial defects': 691, 'artificial intelligence': 692, 'artificial neural network': 693, 'artificial neural network (ann)': 694, 'artificial neural networks': 695, 'artificial-neural-network': 696, 'artificially': 697, 'Artist': 698, 'artist': 699, 'ARTL': 700, 'As': 701, 'as': 702, 'Ascending': 703, 'ascertain': 704, 'ASD': 705, 'ask': 706, 'aspect': 707, 'aspects': 708, 'ASR': 709, 'assembling': 710, 'asses': 711, 'assess': 712, 'assessed': 713, 'assesses': 714, 'Assessing': 715, 'assessment': 716, 'Assessment': 717, 'asset': 718, 'assets': 719, 'assign': 720, 'assigned': 721, 'assigning': 722, 'assignment': 723, 'assigns': 724, 'assist': 725, 'Assisted': 726, 'assisted': 727, 'assisting': 728, 'associated': 729, 'Association': 730, 'association': 731, 'association map': 732, 'association rules': 733, 'associative': 734, 'associative classification': 735, 'associative memory': 736, 'associatively': 737, 'assume': 738, 'assumed': 739, 'assumes': 740, 'assuming': 741, 'assumption': 742, 'assumptions': 743, 'Assurance': 744, 'assuring': 745, 'Asthma': 746, 'Astroturf': 747, 'at': 748, 'At': 749, 'atlas': 750, 'Atlas': 751, 'Atlases': 752, 'atlases': 753, 'atmospheric': 754, 'Atmospheric': 755, 'ATMS': 756, 'attach': 757, 'attack': 758, 'Attack': 759, 'attackers': 760, 'Attackers': 761, 'attacking': 762, 'Attacks': 763, 'attacks': 764, 'attain': 765, 'attained': 766, 'attaining': 767, 'attainment': 768, 'attains': 769, 'attempt': 770, 'attempts': 771, 'attention': 772, 'attentions': 773, 'attracted': 774, 'attractive': 775, 'Attribute': 776, 'attribute': 777, 'attributes': 778, 'Attributes': 779, 'ATTs': 780, 'AUC': 781, 'Auction': 782, 'auction': 783, 'auctions': 784, 'audio': 785, 'Audio': 786, 'audio captcha': 787, 'audio equalizer': 788, 'audio signal': 789, 'audiogram': 790, 'auditory': 791, 'augment': 792, 'augmentation': 793, 'augmented': 794, 'Augmented': 795, 'augmenting': 796, 'Augmenting': 797, 'August': 798, 'aurally': 799, 'Australia': 800, 'authentication': 801, 'Authentication': 802, 'authentication graphs': 803, 'Authentications': 804, 'author': 805, 'author classification': 806, 'authoring': 807, 'authoritative': 808, 'authority': 809, 'authors': 810, 'authorship': 811, 'autism': 812, 'Autism': 813, 'autism spectrum disorder': 814, 'auto': 815, 'Auto': 816, 'Autocorrelation': 817, 'autocorrelation-function-(acf)': 818, 'autoencod': 819, 'autoencoder': 820, 'Autoencoder': 821, 'autoencoders': 822, 'Autoencoders': 823, 'automate': 824, 'automated': 825, 'Automated': 826, 'automated classification': 827, 'automates': 828, 'automatic': 829, 'Automatic': 830, 'automatic diagnosis': 831, 'automatic gender estimation': 832, 'automatic scoring': 833, 'automatic speech recognition': 834, 'Automatically': 835, 'automatically': 836, 'Automating': 837, 'automating': 838, 'automation': 839, 'automobiles': 840, 'Automotive': 841, 'automotive security': 842, 'autonomous': 843, 'autonomously': 844, 'Autoregressive': 845, 'autoregressive': 846, 'autoregressive processes': 847, 'auxiliary': 848, 'Auxiliary': 849, 'auxiliary objectives': 850, 'AV': 851, 'availabilities': 852, 'availability': 853, 'available': 854, 'avenue': 855, 'average': 856, 'Average': 857, 'averaged': 858, 'averages': 859, 'averaging': 860, 'avoid': 861, 'avoided': 862, 'aware': 863, 'Aware': 864, 'awareness': 865, 'Awareness': 866, 'away': 867, 'axis': 868, 'b': 869, 'B': 870, 'Back': 871, 'back': 872, 'back-propagation-algorithm': 873, 'Backblaze': 874, 'background': 875, 'Background': 876, 'backpropagation': 877, 'bacteria': 878, 'bacterial': 879, 'bad': 880, 'Badminton': 881, 'badminton': 882, 'Bag': 883, 'bag': 884, 'bag-of-concepts': 885, 'bag-of-pattern': 886, 'Bagged': 887, 'bagging': 888, 'Bagging': 889, 'bags': 890, 'Bags': 891, 'balance': 892, 'Balanced': 893, 'balanced': 894, 'balanced k-means': 895, 'balances': 896, 'balancing': 897, 'ball': 898, 'Ballistocardiogram': 899, 'ballistocardiogram artifact': 900, 'Baltimore': 901, 'Band': 902, 'Bandit': 903, 'bandit': 904, 'bands': 905, 'bandwidth': 906, 'bank': 907, 'banks': 908, 'bare': 909, 'barrier': 910, 'Bartlett': 911, 'bartlett tests': 912, 'BAS': 913, 'base': 914, 'Base': 915, 'base station (bs)': 916, 'based': 917, 'Based': 918, 'baseline': 919, 'baselines': 920, 'bases': 921, 'basic': 922, 'Basis': 923, 'basis': 924, 'basis selection': 925, 'batch': 926, 'batches': 927, 'batteries': 928, 'battery': 929, 'Baum': 930, 'Bayes': 931, 'bayes classifier': 932, 'bayes methods': 933, 'bayesian': 934, 'Bayesian': 935, 'bayesian analysis': 936, 'bayesian classification': 937, 'bayesian inference': 938, 'bayesian network': 939, 'bayesian networks': 940, 'bayesian nonparametrics': 941, 'bayesian-networks': 942, 'BBC': 943, 'BCI': 944, 'be': 945, 'Bearing': 946, 'bearing defects': 947, 'bearings': 948, 'became': 949, 'because': 950, 'Because': 951, 'become': 952, 'becomes': 953, 'becoming': 954, 'bedrooms': 955, 'bedside': 956, 'been': 957, 'before': 958, 'befriend': 959, 'began': 960, 'beginning': 961, 'begins': 962, 'behave': 963, 'behavior': 964, 'Behavior': 965, 'behavioral': 966, 'Behavioral': 967, 'behaviors': 968, 'Behaviors': 969, 'behaviour': 970, 'Behaviours': 971, 'behind': 972, 'being': 973, 'Being': 974, 'belief': 975, 'beliefs': 976, 'believe': 977, 'Bellman': 978, 'Bellmans': 979, 'belong': 980, 'belonging': 981, 'belongs': 982, 'benchmark': 983, 'Benchmark': 984, 'Benchmarking': 985, 'benchmarks': 986, 'beneficial': 987, 'benefit': 988, 'benefits': 989, 'benign': 990, 'Berkeley': 991, 'Bernoulli': 992, 'Besides': 993, 'Best': 994, 'best': 995, 'best subset linear regression': 996, 'better': 997, 'Better': 998, 'between': 999, 'Between': 1000, 'betweens': 1001, 'beyond': 1002, 'BF': 1003, 'BG': 1004, 'BHPMF': 1005, 'bias': 1006, 'biased': 1007, 'biases': 1008, 'BIC': 1009, 'bidder': 1010, 'bidders': 1011, 'bidding': 1012, 'bidiagonalization': 1013, 'bids': 1014, 'bifurcation': 1015, 'big': 1016, 'Big': 1017, 'big data': 1018, 'big data analytics': 1019, 'big data clustering': 1020, 'big healthcare data': 1021, 'big mobile social data': 1022, 'big-data': 1023, 'biggest': 1024, 'BIH': 1025, 'bike': 1026, 'bilateral filter': 1027, 'Bilevel': 1028, 'bilevel': 1029, 'bilinear': 1030, 'billions': 1031, 'bimodal': 1032, 'bin': 1033, 'binarization': 1034, 'binary': 1035, 'Binary': 1036, 'binary classification': 1037, 'binary codes': 1038, 'Binding': 1039, 'binding': 1040, 'bins': 1041, 'bio': 1042, 'bio-acoustics': 1043, 'bio-detection': 1044, 'Bioinformatics': 1045, 'bioinformatics': 1046, 'biological': 1047, 'Biological': 1048, 'biological neural networks': 1049, 'biological system modeling': 1050, 'biology': 1051, 'biomarker': 1052, 'biomarkers': 1053, 'biomedical informatics': 1054, 'biometric': 1055, 'Biometric': 1056, 'biometric recognition': 1057, 'biometrics': 1058, 'Biometry': 1059, 'biopsy': 1060, 'bipartite': 1061, 'Bipartite': 1062, 'bipartite graphs': 1063, 'bipartite ranking problem': 1064, 'Bird': 1065, 'bird': 1066, 'bird call identification': 1067, 'birds': 1068, 'Birdsong': 1069, 'birdsong': 1070, 'birth': 1071, 'Bit': 1072, 'bitcoin': 1073, 'Bitcoin': 1074, 'Bitcoins': 1075, 'bits': 1076, 'black': 1077, 'black-box testing': 1078, 'blackout': 1079, 'blade': 1080, 'bleeding': 1081, 'blends': 1082, 'blind': 1083, 'blind source seperation': 1084, 'blindness': 1085, 'blobs': 1086, 'Block': 1087, 'block': 1088, 'Blockchain': 1089, 'blockchain': 1090, 'blocks': 1091, 'blog spam': 1092, 'blogs': 1093, 'blood': 1094, 'Blood': 1095, 'BLPCA': 1096, 'BLSTM': 1097, 'blunder': 1098, 'BN': 1099, 'BNP': 1100, 'board': 1101, 'BoB': 1102, 'BOC': 1103, 'body': 1104, 'Body': 1105, 'Boltzmann': 1106, 'bone': 1107, 'bookings': 1108, 'Boolean': 1109, 'boolean networks': 1110, 'boost': 1111, 'boosted': 1112, 'Boosted': 1113, 'Boosting': 1114, 'boosting': 1115, 'bootstrap': 1116, 'bootstrap approaches': 1117, 'Bootstrapping': 1118, 'bootstrapping': 1119, 'BoP': 1120, 'border': 1121, 'borders': 1122, 'borrowing': 1123, 'bot': 1124, 'Both': 1125, 'both': 1126, 'botnets': 1127, 'bots': 1128, 'bottlenecks': 1129, 'bottom': 1130, 'bound': 1131, 'boundaries': 1132, 'boundary': 1133, 'boundary value problems': 1134, 'Bounded': 1135, 'bounded': 1136, 'bounding': 1137, 'bounds': 1138, 'BOW': 1139, 'box': 1140, 'Box': 1141, 'box office': 1142, 'boxes': 1143, 'BP': 1144, 'Brace': 1145, 'brace': 1146, 'brace treatment': 1147, 'brain': 1148, 'Brain': 1149, 'brain computer interface': 1150, 'Brains': 1151, 'brains': 1152, 'braking': 1153, 'branch': 1154, 'branches': 1155, 'branching': 1156, 'Brand': 1157, 'brand': 1158, 'brand perception': 1159, 'brands': 1160, 'breach': 1161, 'break': 1162, 'BreakFast': 1163, 'Breaking': 1164, 'breaking': 1165, 'breaking news': 1166, 'breast': 1167, 'Breast': 1168, 'breast cancer': 1169, 'breathing': 1170, 'breeding': 1171, 'Bregman': 1172, 'bridges': 1173, 'brief': 1174, 'brightness': 1175, 'bring': 1176, 'brings': 1177, 'broad': 1178, 'broadcast': 1179, 'broadcasting': 1180, 'broken': 1181, 'brought': 1182, 'Brown': 1183, 'browser': 1184, 'browsing': 1185, 'brute': 1186, 'Brute': 1187, 'brute force': 1188, 'BSO': 1189, 'bubbled': 1190, 'bucket': 1191, 'budget': 1192, 'budgeted': 1193, 'Budgeted': 1194, 'budgeted learning': 1195, 'budgets': 1196, 'build': 1197, 'building': 1198, 'Building': 1199, 'Buildings': 1200, 'buildings': 1201, 'Builds': 1202, 'builds': 1203, 'Built': 1204, 'built': 1205, 'burden': 1206, 'burdensome': 1207, 'bus': 1208, 'Bus': 1209, 'bus transportation': 1210, 'business': 1211, 'businesses': 1212, 'busted': 1213, 'but': 1214, 'But': 1215, 'buyers': 1216, 'buying': 1217, 'BW': 1218, 'by': 1219, 'By': 1220, 'bypass': 1221, 'byte': 1222, 'c': 1223, 'C': 1224, 'c++ languages': 1225, 'C4': 1226, 'cache': 1227, 'Caches': 1228, 'Caching': 1229, 'caching': 1230, 'CAD': 1231, 'Cagman': 1232, 'calculate': 1233, 'calculated': 1234, 'calculates': 1235, 'calculating': 1236, 'calculation': 1237, 'Calculation': 1238, 'calculations': 1239, 'calculus': 1240, 'calibrate': 1241, 'calibrated': 1242, 'Calibration': 1243, 'calibration': 1244, 'California': 1245, 'call': 1246, 'Call': 1247, 'called': 1248, 'calls': 1249, 'Caltech': 1250, 'camera': 1251, 'cameras': 1252, 'campaigns': 1253, 'campus': 1254, 'CAN': 1255, 'can': 1256, 'Can': 1257, 'can bus': 1258, 'Canada': 1259, 'Canal': 1260, 'canal': 1261, 'canal command': 1262, 'Cancer': 1263, 'cancer': 1264, 'cancer detection': 1265, 'cancerous': 1266, 'candidate': 1267, 'candidates': 1268, 'cannot': 1269, 'canonical': 1270, 'Canonical': 1271, 'canonical correlation analysis': 1272, 'Canopy': 1273, 'canopy algorithm': 1274, 'capabilities': 1275, 'capability': 1276, 'capable': 1277, 'capacity': 1278, 'capella': 1279, 'CAPTCHA': 1280, 'CAPTCHAs': 1281, 'capture': 1282, 'captured': 1283, 'captures': 1284, 'capturing': 1285, 'car': 1286, 'Car': 1287, 'car following model': 1288, 'Carbon': 1289, 'carbon': 1290, 'card': 1291, 'Card': 1292, 'cardiac': 1293, 'cardinality': 1294, 'Care': 1295, 'care': 1296, 'career': 1297, 'CareerBuilder': 1298, 'careerbuilder': 1299, 'careers': 1300, 'carefully': 1301, 'caregivers': 1302, 'Carlo': 1303, 'Carnegie': 1304, 'carried': 1305, 'carry': 1306, 'carrying': 1307, 'cars': 1308, 'Cartesian': 1309, 'cartesian': 1310, 'Carthagene': 1311, 'carving': 1312, 'Cascaded': 1313, 'cascaded': 1314, 'cascaded sparse autoencoders': 1315, 'cascading style sheets': 1316, 'case': 1317, 'Case': 1318, 'case management': 1319, 'case-based reasoning': 1320, 'caseload': 1321, 'Cases': 1322, 'cases': 1323, 'caseworkers': 1324, 'CAST': 1325, 'catalyst': 1326, 'catastrophe': 1327, 'catastrophic': 1328, 'categorical': 1329, 'categories': 1330, 'categorise': 1331, 'categorization': 1332, 'categorized': 1333, 'category': 1334, 'causal': 1335, 'Causal': 1336, 'causal discovery': 1337, 'Causality': 1338, 'causality': 1339, 'Causation': 1340, 'cause': 1341, 'caused': 1342, 'causes': 1343, 'causing': 1344, 'CBR': 1345, 'CCA': 1346, 'CCD': 1347, 'CCQ': 1348, 'CD': 1349, 'CDFTSVM': 1350, 'CDK': 1351, 'celebrated': 1352, 'Celerity': 1353, 'cell': 1354, 'Cell': 1355, 'cell images': 1356, 'cells': 1357, 'cellular': 1358, 'cember': 1359, 'center': 1360, 'Center': 1361, 'centerbased': 1362, 'Centered': 1363, 'centers': 1364, 'Central': 1365, 'central': 1366, 'Centric': 1367, 'centric': 1368, 'Centroid': 1369, 'centroids': 1370, 'CEP': 1371, 'Cepstral': 1372, 'cepstral': 1373, 'cepstral coefficients': 1374, 'certain': 1375, 'Certainly': 1376, 'CF': 1377, 'cfrp': 1378, 'CFRP': 1379, 'CGP': 1380, 'cgp': 1381, 'cgpann': 1382, 'CGPANN': 1383, 'chain': 1384, 'Chain': 1385, 'Challenge': 1386, 'challenge': 1387, 'challenges': 1388, 'Challenging': 1389, 'challenging': 1390, 'challenging behaviors': 1391, 'chance': 1392, 'Change': 1393, 'change': 1394, 'changed': 1395, 'Changes': 1396, 'changes': 1397, 'changing': 1398, 'channel': 1399, 'Channel': 1400, 'channels': 1401, 'chaotic': 1402, 'character': 1403, 'Character': 1404, 'characterisation': 1405, 'characteristic': 1406, 'characteristics': 1407, 'Characteristics': 1408, 'characterization': 1409, 'characterize': 1410, 'characterized': 1411, 'characterizing': 1412, 'charge': 1413, 'chart': 1414, 'chatting': 1415, 'cheaper': 1416, 'check': 1417, 'checked': 1418, 'checking': 1419, 'Chelsea': 1420, 'Chemical': 1421, 'chemical': 1422, 'Chennai': 1423, 'chess': 1424, 'Chess': 1425, 'Chi': 1426, 'Chicago': 1427, 'child': 1428, 'Child': 1429, 'child support': 1430, 'children': 1431, 'Chinese': 1432, 'chips': 1433, 'Chisini': 1434, 'choice': 1435, 'choices': 1436, 'choose': 1437, 'choosing': 1438, 'Chord': 1439, 'chord': 1440, 'chosen': 1441, 'chronic': 1442, 'Chronic': 1443, 'chronically': 1444, 'chronological': 1445, 'churn': 1446, 'Churn': 1447, 'churn prediction': 1448, 'CIFAR': 1449, 'circuit': 1450, 'circular': 1451, 'circulation': 1452, 'circumstances': 1453, 'circumvent': 1454, 'cite': 1455, 'Cities': 1456, 'cities': 1457, 'citizens': 1458, 'city': 1459, 'City': 1460, 'CL': 1461, 'claim': 1462, 'claimant': 1463, 'claims': 1464, 'Claims': 1465, 'clamp': 1466, 'clamped': 1467, 'Class': 1468, 'class': 1469, 'class decomposition': 1470, 'class imbalance': 1471, 'classes': 1472, 'classic': 1473, 'Classical': 1474, 'classical': 1475, 'Classification': 1476, 'classification': 1477, 'classification algorithms': 1478, 'classification techniques': 1479, 'classifications': 1480, 'classified': 1481, 'classifier': 1482, 'Classifier': 1483, 'classifier ensemble': 1484, 'classifiers': 1485, 'Classifiers': 1486, 'classifies': 1487, 'classify': 1488, 'Classify': 1489, 'Classifying': 1490, 'classifying': 1491, 'clauses': 1492, 'CLE': 1493, 'clean': 1494, 'cleaned': 1495, 'cleaning': 1496, 'clear': 1497, 'clearances': 1498, 'clearer': 1499, 'clearly': 1500, 'clicking': 1501, 'clients': 1502, 'climate': 1503, 'Climate': 1504, 'climate science': 1505, 'climatic': 1506, 'climbing': 1507, 'clinical': 1508, 'Clinical': 1509, 'clinicians': 1510, 'clips': 1511, 'CLNN': 1512, 'clnn': 1513, 'clo': 1514, 'CLO': 1515, 'clone': 1516, 'Clone': 1517, 'clone refactoring': 1518, 'CLOs': 1519, 'close': 1520, 'Close': 1521, 'closed': 1522, 'closely': 1523, 'closer': 1524, 'closures': 1525, 'cloud': 1526, 'Cloud': 1527, 'cloud computing': 1528, 'cloud data security': 1529, 'cloud-oriented architecture': 1530, 'clouds': 1531, 'CLP': 1532, 'CLUE': 1533, 'cluster': 1534, 'Cluster': 1535, 'cluster analysis': 1536, 'cluster data': 1537, 'cluster forest': 1538, 'cluster head (ch)': 1539, 'cluster size distribution': 1540, 'cluster validation': 1541, 'cluster validity': 1542, 'clustered': 1543, 'Clustering': 1544, 'clustering': 1545, 'clustering algorithms': 1546, 'clusters': 1547, 'Clusters': 1548, 'Clutter': 1549, 'clutter': 1550, 'cm': 1551, 'CM': 1552, 'cm-knn': 1553, 'CMA': 1554, 'cma-es': 1555, 'CMU': 1556, 'cnn': 1557, 'CNN': 1558, 'CNNs': 1559, 'co': 1560, 'coarse': 1561, 'coauthorship': 1562, 'Code': 1563, 'code': 1564, 'codebases': 1565, 'coded': 1566, 'Codes': 1567, 'codes': 1568, 'CoDis': 1569, 'Coefficient': 1570, 'coefficient': 1571, 'Coefficients': 1572, 'coefficients': 1573, 'cognitive': 1574, 'coherency': 1575, 'Coherent': 1576, 'coherent': 1577, 'coherently': 1578, 'cohesive': 1579, 'cohorts': 1580, 'Cohorts': 1581, 'coil': 1582, 'cold': 1583, 'cold-start problem': 1584, 'collaborate': 1585, 'collaboration': 1586, 'Collaboration': 1587, 'collaboration network': 1588, 'Collaborative': 1589, 'collaborative': 1590, 'collaborative filtering': 1591, 'collaborative learning': 1592, 'collaborative recommendation': 1593, 'collect': 1594, 'collected': 1595, 'collecting': 1596, 'Collection': 1597, 'collection': 1598, 'collections': 1599, 'collective': 1600, 'Collective': 1601, 'collector apis': 1602, 'collects': 1603, 'Colleges': 1604, 'collision': 1605, 'Colombia': 1606, 'color': 1607, 'colorization': 1608, 'Colorization': 1609, 'Coloured': 1610, 'coloured petri nets': 1611, 'com': 1612, 'combat': 1613, 'Combat': 1614, 'Combating': 1615, 'Combination': 1616, 'combination': 1617, 'combination forgery': 1618, 'combinations': 1619, 'combinatorial': 1620, 'combinatorial optimization': 1621, 'combinatorial reverse auctions': 1622, 'combine': 1623, 'combined': 1624, 'Combined': 1625, 'combiner': 1626, 'Combiner': 1627, 'combines': 1628, 'combining': 1629, 'Combining': 1630, 'come': 1631, 'comes': 1632, 'comfirms': 1633, 'Comfort': 1634, 'comfort': 1635, 'coming': 1636, 'Command': 1637, 'command': 1638, 'Commands': 1639, 'commands': 1640, 'Comment': 1641, 'comment': 1642, 'comment features': 1643, 'comment spam detection': 1644, 'Commentary': 1645, 'comments': 1646, 'commerce': 1647, 'Commerce': 1648, 'commercial': 1649, 'commercialized': 1650, 'commercially': 1651, 'commodity': 1652, 'common': 1653, 'Common': 1654, 'common metric learning': 1655, 'commonly': 1656, 'commonplace': 1657, 'communicate': 1658, 'Communication': 1659, 'communication': 1660, 'communications': 1661, 'communities': 1662, 'Community': 1663, 'community': 1664, 'commutating': 1665, 'compactness': 1666, 'compactness measure of clusters': 1667, 'companies': 1668, 'Company': 1669, 'company': 1670, 'comparable': 1671, 'Comparative': 1672, 'comparative': 1673, 'comparative market analysis': 1674, 'comparative study': 1675, 'comparatively': 1676, 'compare': 1677, 'Compared': 1678, 'compared': 1679, 'compares': 1680, 'comparing': 1681, 'Comparing': 1682, 'Comparison': 1683, 'comparison': 1684, 'comparisons': 1685, 'compatibility': 1686, 'Compatibility': 1687, 'compatible': 1688, 'competent': 1689, 'competing': 1690, 'competition': 1691, 'competitions': 1692, 'competitive': 1693, 'competitiveness': 1694, 'compiler': 1695, 'compilers': 1696, 'complete': 1697, 'completed': 1698, 'completely': 1699, 'completeness': 1700, 'Completeness': 1701, 'Completion': 1702, 'completion': 1703, 'Complex': 1704, 'complex': 1705, 'complex event programming': 1706, 'complexities': 1707, 'complexity': 1708, 'Complexity': 1709, 'complexity reduction': 1710, 'compliance': 1711, 'compliant': 1712, 'complicated': 1713, 'complication': 1714, 'complications': 1715, 'component': 1716, 'Component': 1717, 'component based design petri nets': 1718, 'Components': 1719, 'components': 1720, 'composed': 1721, 'composers': 1722, 'composing': 1723, 'composition': 1724, 'compound': 1725, 'compounded': 1726, 'compounds': 1727, 'comprehend': 1728, 'comprehension': 1729, 'comprehensive': 1730, 'comprehensively': 1731, 'compressed': 1732, 'compression': 1733, 'compression algorithms': 1734, 'comprised': 1735, 'comprises': 1736, 'comprising': 1737, 'compromise': 1738, 'compromised': 1739, 'compromising': 1740, 'computation': 1741, 'Computation': 1742, 'computational': 1743, 'Computational': 1744, 'computational modeling': 1745, 'computationally': 1746, 'computations': 1747, 'compute': 1748, 'Computed': 1749, 'computed': 1750, 'Computer': 1751, 'computer': 1752, 'computer crime': 1753, 'computer generated forces': 1754, 'computer science': 1755, 'computer vision': 1756, 'computer-aided detection (cad)': 1757, 'computer-aided diagnosis': 1758, 'computers': 1759, 'computes': 1760, 'Computing': 1761, 'computing': 1762, 'concatenating': 1763, 'concentrate': 1764, 'concentrates': 1765, 'concentration': 1766, 'concept': 1767, 'Concept': 1768, 'conception': 1769, 'concepts': 1770, 'Concepts': 1771, 'Conceptual': 1772, 'conceptualization': 1773, 'conceptually': 1774, 'concern': 1775, 'concerned': 1776, 'concerning': 1777, 'conclude': 1778, 'concluded': 1779, 'conclusion': 1780, 'Conclusion': 1781, 'conclusions': 1782, 'concurrent': 1783, 'condition': 1784, 'Condition': 1785, 'conditional': 1786, 'ConditionaL': 1787, 'Conditional': 1788, 'conditional neural networks': 1789, 'conditional restricted boltzmann machine': 1790, 'Conditioning': 1791, 'conditioning': 1792, 'conditions': 1793, 'Conditions': 1794, 'conduct': 1795, 'conducted': 1796, 'conducting': 1797, 'cone': 1798, 'conferences': 1799, 'confidence': 1800, 'Confidence': 1801, 'confidence region': 1802, 'confident': 1803, 'Configuration': 1804, 'configuration': 1805, 'configurations': 1806, 'configure': 1807, 'configuring': 1808, 'Configuring': 1809, 'confirm': 1810, 'confirmed': 1811, 'conflating': 1812, 'conflicting': 1813, 'Conformal': 1814, 'conformal': 1815, 'conformal prediction': 1816, 'conformalized': 1817, 'Conformalized': 1818, 'conformation': 1819, 'Conformation': 1820, 'conformation motion': 1821, 'conformations': 1822, 'confronting': 1823, 'confusion matrix': 1824, 'congested': 1825, 'congestion': 1826, 'conjecture': 1827, 'conjugate': 1828, 'conjunction': 1829, 'Conjunctivitis': 1830, 'conjunctivitis': 1831, 'connect': 1832, 'connected': 1833, 'Connected': 1834, 'connected vehicles': 1835, 'connection': 1836, 'connections': 1837, 'connectivities': 1838, 'connectivity': 1839, 'Connects': 1840, 'conquer': 1841, 'consciousness': 1842, 'consecutive': 1843, 'consensus': 1844, 'Consensus': 1845, 'consequence': 1846, 'consequences': 1847, 'consequent': 1848, 'consequently': 1849, 'Consequently': 1850, 'conservation': 1851, 'consider': 1852, 'Consider': 1853, 'considerable': 1854, 'considerably': 1855, 'consideration': 1856, 'considered': 1857, 'considering': 1858, 'Considering': 1859, 'considers': 1860, 'consist': 1861, 'consisted': 1862, 'consistency': 1863, 'consistent': 1864, 'Consistently': 1865, 'consistently': 1866, 'consisting': 1867, 'consists': 1868, 'consolidate': 1869, 'consolidation': 1870, 'Consortium': 1871, 'constant': 1872, 'Constant': 1873, 'constituent': 1874, 'constitutes': 1875, 'Constrained': 1876, 'constrained': 1877, 'Constraint': 1878, 'constraint': 1879, 'constraint programming': 1880, 'constraint satisfaction problem': 1881, 'constraints': 1882, 'Constraints': 1883, 'construct': 1884, 'constructed': 1885, 'Constructed': 1886, 'Constructing': 1887, 'constructing': 1888, 'construction': 1889, 'constructive': 1890, 'constructs': 1891, 'consume': 1892, 'consumed': 1893, 'Consumer': 1894, 'consumer': 1895, 'consumers': 1896, 'consumes': 1897, 'consuming': 1898, 'consumption': 1899, 'Consumption': 1900, 'contacted': 1901, 'contagious': 1902, 'contain': 1903, 'contained': 1904, 'containing': 1905, 'contains': 1906, 'contaminant': 1907, 'contemporary': 1908, 'Content': 1909, 'content': 1910, 'content caching': 1911, 'content spam': 1912, 'contents': 1913, 'context': 1914, 'Context': 1915, 'context aware': 1916, 'contexts': 1917, 'Contextual': 1918, 'contextual similarity': 1919, 'continental': 1920, 'Continental': 1921, 'continue': 1922, 'continues': 1923, 'continuing': 1924, 'continuous': 1925, 'Continuous': 1926, 'continuously': 1927, 'contour': 1928, 'Contour': 1929, 'contour recognition': 1930, 'contour representations': 1931, 'contours': 1932, 'Contours': 1933, 'contracted': 1934, 'contracts': 1935, 'contrary': 1936, 'contrast': 1937, 'contrasting': 1938, 'Contrastive': 1939, 'contrasts': 1940, 'contribute': 1941, 'contributes': 1942, 'contributing': 1943, 'contribution': 1944, 'Contribution': 1945, 'contributions': 1946, 'contributor': 1947, 'control': 1948, 'Control': 1949, 'control period computational burden': 1950, 'control system': 1951, 'control systems': 1952, 'controlled': 1953, 'Controlled': 1954, 'Controller': 1955, 'controller': 1956, 'controllers': 1957, 'controlling': 1958, 'controls': 1959, 'controversial': 1960, 'convenience': 1961, 'convenient': 1962, 'conventional': 1963, 'convergence': 1964, 'convergent': 1965, 'converges': 1966, 'converging': 1967, 'conversions': 1968, 'convert': 1969, 'converted': 1970, 'converter': 1971, 'Converter': 1972, 'Converters': 1973, 'converters': 1974, 'Convex': 1975, 'convex': 1976, 'convexity': 1977, 'ConvNet': 1978, 'convoluted': 1979, 'convolution': 1980, 'convolution filtering': 1981, 'convolutional': 1982, 'Convolutional': 1983, 'convolutional neural nets': 1984, 'convolutional neural network': 1985, 'convolutional neural networks': 1986, 'convolutional neural networks (cnn)': 1987, 'convolutional neural networks (cnns)': 1988, 'coooperative': 1989, 'cooperated': 1990, 'cooperation': 1991, 'Cooperation': 1992, 'Cooperative': 1993, 'cooperative': 1994, 'cooperative adaptive cruise control': 1995, 'cooperative systems': 1996, 'Coordinate': 1997, 'coordinate': 1998, 'coordinate descent': 1999, 'coordinated': 2000, 'coordinates': 2001, 'cope': 2002, 'copies': 2003, 'copious': 2004, 'copy': 2005, 'core': 2006, 'Core': 2007, 'coreference': 2008, 'Coreference': 2009, 'coreferent': 2010, 'corneal': 2011, 'Corneal': 2012, 'corner': 2013, 'Corpora': 2014, 'corpora': 2015, 'corporate': 2016, 'corpses': 2017, 'corpus': 2018, 'correct': 2019, 'correction': 2020, 'corrections': 2021, 'correctly': 2022, 'correctness': 2023, 'correlate': 2024, 'correlated': 2025, 'Correlated': 2026, 'correlating': 2027, 'Correlating': 2028, 'Correlation': 2029, 'correlation': 2030, 'correlations': 2031, 'correspond': 2032, 'corresponding': 2033, 'corresponds': 2034, 'cortex': 2035, 'Cosine': 2036, 'Cost': 2037, 'cost': 2038, 'cost sensitive classification': 2039, 'cost-sensitive learning': 2040, 'costly': 2041, 'costs': 2042, 'could': 2043, 'couldn': 2044, 'Count': 2045, 'Counter': 2046, 'countermeasure': 2047, 'countermeasures': 2048, 'counterpart': 2049, 'counterparts': 2050, 'counters': 2051, 'counties': 2052, 'countries': 2053, 'country': 2054, 'counts': 2055, 'Coupled': 2056, 'coupled': 2057, 'coupling': 2058, 'couplings': 2059, 'Course': 2060, 'course': 2061, 'Covariance': 2062, 'covariance': 2063, 'covariance matrix': 2064, 'covariates': 2065, 'cover': 2066, 'coverability': 2067, 'coverage': 2068, 'covered': 2069, 'covers': 2070, 'CPD': 2071, 'cpd': 2072, 'CPLM': 2073, 'CPU': 2074, 'crafted': 2075, 'crafting': 2076, 'crawlers': 2077, 'crbm': 2078, 'create': 2079, 'created': 2080, 'creates': 2081, 'creating': 2082, 'creation': 2083, 'credible': 2084, 'Credible': 2085, 'credit': 2086, 'Credit': 2087, 'credit default swap': 2088, 'credit scoring': 2089, 'Crescendo': 2090, 'CRF': 2091, 'CRFs': 2092, 'crime': 2093, 'crime prediction': 2094, 'criminal': 2095, 'crises': 2096, 'crisis': 2097, 'criteria': 2098, 'criterion': 2099, 'Criterion': 2100, 'critical': 2101, 'Critical': 2102, 'criticality': 2103, 'critically': 2104, 'criticized': 2105, 'crop': 2106, 'crops': 2107, 'cross': 2108, 'Cross': 2109, 'cross lingual': 2110, 'cross-validation': 2111, 'crosses': 2112, 'Crossing': 2113, 'crossing': 2114, 'crosslingual': 2115, 'crowd': 2116, 'crowd-sourcing': 2117, 'crowdsourcing': 2118, 'Crowdsourcing': 2119, 'crucial': 2120, 'crude': 2121, 'Crude': 2122, 'crude oil price forecasting': 2123, 'cruise': 2124, 'cruise control': 2125, 'cryptocurrency': 2126, 'CS1': 2127, 'CSI': 2128, 'CSP': 2129, 'CT': 2130, 'ct images': 2131, 'ct prediction': 2132, 'cube': 2133, 'Cuckoo': 2134, 'cue': 2135, 'cues': 2136, 'culture': 2137, 'cumbersome': 2138, 'cumulative': 2139, 'Cup': 2140, 'cure': 2141, 'curiosity': 2142, 'currency': 2143, 'Current': 2144, 'current': 2145, 'Currently': 2146, 'currently': 2147, 'Curriculum': 2148, 'curse': 2149, 'Curvature': 2150, 'curvature': 2151, 'curve': 2152, 'Curve': 2153, 'curve simplification': 2154, 'curves': 2155, 'custodial': 2156, 'custom': 2157, 'customer': 2158, 'customers': 2159, 'customize': 2160, 'customized': 2161, 'cuts': 2162, 'cwt': 2163, 'CWT': 2164, 'cyber': 2165, 'Cyber': 2166, 'cyber forensic': 2167, 'cyber security': 2168, 'cyber-security vulnerabilities': 2169, 'cyberattack': 2170, 'Cyberattack': 2171, 'cyberattacks': 2172, 'Cyberattacks': 2173, 'Cybersecurity': 2174, 'cybersecurity': 2175, 'cybersecurity applications': 2176, 'Cycle': 2177, 'Cyclic': 2178, 'cyclic contrastive divergence learning': 2179, 'cycling': 2180, 'cylinder': 2181, 'cytoskeleton': 2182, 'Czech': 2183, 'czech ner': 2184, 'D': 2185, 'd': 2186, 'DAG': 2187, 'daily': 2188, 'Daily': 2189, 'Dalvik': 2190, 'Dam': 2191, 'dam': 2192, 'damage': 2193, 'Damage': 2194, 'damaged': 2195, 'damages': 2196, 'damp': 2197, 'Dams': 2198, 'danger': 2199, 'dangerous': 2200, 'darker': 2201, 'DARPA': 2202, 'dasgupta13': 2203, 'dashboards': 2204, 'Data': 2205, 'data': 2206, 'data analysis': 2207, 'data analytics': 2208, 'data augmentation': 2209, 'data clustering': 2210, 'data contamination': 2211, 'data diversity': 2212, 'data integration': 2213, 'data mining': 2214, 'data models': 2215, 'data modification intrusion detection': 2216, 'data privacy': 2217, 'data stream': 2218, 'data stream with concept drift': 2219, 'data warehouse': 2220, 'data-acquisition': 2221, 'data-driven': 2222, 'Database': 2223, 'database': 2224, 'databaselike': 2225, 'Databases': 2226, 'databases': 2227, 'datagrapple': 2228, 'Dataset': 2229, 'dataset': 2230, 'datasets': 2231, 'Datasets': 2232, 'DataStreams': 2233, 'date': 2234, 'dating': 2235, 'day': 2236, 'Day': 2237, 'days': 2238, 'dB': 2239, 'DB': 2240, 'DB1': 2241, 'DBLP': 2242, 'DBMS': 2243, 'DBMSs': 2244, 'dbn': 2245, 'dbpedia ontology': 2246, 'DC': 2247, 'dc': 2248, 'dc-dc converter': 2249, 'dc/dc-boost-converter': 2250, 'dct': 2251, 'DCT': 2252, 'DDC': 2253, 'DDoS': 2254, 'DDPG': 2255, 'de': 2256, 'De': 2257, 'deal': 2258, 'dealing': 2259, 'Dealing': 2260, 'deals': 2261, 'dealt': 2262, 'deaths': 2263, 'Debates': 2264, 'debates': 2265, 'decade': 2266, 'decades': 2267, 'decaying': 2268, 'Decaying': 2269, 'deceive': 2270, 'decent': 2271, 'decentralized': 2272, 'Decentralized': 2273, 'deception': 2274, 'deceptive': 2275, 'Deceptive': 2276, 'decide': 2277, 'decided': 2278, 'decidedly': 2279, 'decides': 2280, 'Decision': 2281, 'decision': 2282, 'decision making': 2283, 'decision support': 2284, 'decision support system': 2285, 'decision tree': 2286, 'decision trees': 2287, 'Decisions': 2288, 'decisions': 2289, 'declarative learning': 2290, 'decode': 2291, 'decoder': 2292, 'decoding': 2293, 'Decoding': 2294, 'decompose': 2295, 'decomposing': 2296, 'Decomposition': 2297, 'decomposition': 2298, 'decomposition-based reinforcement learning': 2299, 'decompositions': 2300, 'deconvolutional': 2301, 'deconvolutional networks (deconvnet)': 2302, 'Decorrelated': 2303, 'decorrelating': 2304, 'decorrelation': 2305, 'decrease': 2306, 'decreases': 2307, 'decreasing': 2308, 'dedicated': 2309, 'deemed': 2310, 'Deep': 2311, 'deep': 2312, 'deep convolutional network': 2313, 'deep learning': 2314, 'deep neural network': 2315, 'deep neural networks': 2316, 'deep regression model': 2317, 'deep reinforcement learning': 2318, 'deepening': 2319, 'Deepness': 2320, 'DeepPositioning': 2321, 'default': 2322, 'defect': 2323, 'Defect': 2324, 'Defects': 2325, 'defects': 2326, 'Defences': 2327, 'defend': 2328, 'defense': 2329, 'deficiencies': 2330, 'deficiency': 2331, 'deficient': 2332, 'define': 2333, 'defined': 2334, 'Defined': 2335, 'defines': 2336, 'defining': 2337, 'definitely': 2338, 'definition': 2339, 'deformations': 2340, 'degradation': 2341, 'degrade': 2342, 'degraded': 2343, 'degrades': 2344, 'degree': 2345, 'Degree': 2346, 'degrees': 2347, 'dehazing': 2348, 'delay': 2349, 'delayed': 2350, 'Delayed': 2351, 'delayed labels': 2352, 'delaying': 2353, 'delays': 2354, 'Delays': 2355, 'delimited': 2356, 'delineated': 2357, 'delivered': 2358, 'delivering': 2359, 'delivers': 2360, 'delivery': 2361, 'Delivery': 2362, 'demand': 2363, 'Demand': 2364, 'demand forecast': 2365, 'demands': 2366, 'Demographic': 2367, 'demographic': 2368, 'demographic group prediction': 2369, 'demographics': 2370, 'demonstrate': 2371, 'demonstrated': 2372, 'demonstrates': 2373, 'demonstrating': 2374, 'demonstration': 2375, 'Demonstration': 2376, 'dendrograms': 2377, 'Denial': 2378, 'denial-of-service (dos)': 2379, 'Denoising': 2380, 'denoising': 2381, 'dense': 2382, 'Dense': 2383, 'Densities': 2384, 'densities': 2385, 'Density': 2386, 'density': 2387, 'depend': 2388, 'dependable': 2389, 'dependence': 2390, 'dependencies': 2391, 'Dependency': 2392, 'dependency': 2393, 'dependent': 2394, 'Dependent': 2395, 'depending': 2396, 'depends': 2397, 'depicting': 2398, 'deploy': 2399, 'deployed': 2400, 'deploying': 2401, 'deployment': 2402, 'deploys': 2403, 'depot': 2404, 'depressed': 2405, 'depression': 2406, 'Depression': 2407, 'Depressive': 2408, 'depressive disorders': 2409, 'depth': 2410, 'deregulation': 2411, 'DERIV': 2412, 'derivation': 2413, 'derive': 2414, 'derived': 2415, 'deriving': 2416, 'Descending': 2417, 'descent': 2418, 'Descent': 2419, 'describe': 2420, 'described': 2421, 'describes': 2422, 'describing': 2423, 'Description': 2424, 'description': 2425, 'descriptions': 2426, 'descriptors': 2427, 'desensitization': 2428, 'desensitized': 2429, 'deserving': 2430, 'design': 2431, 'Design': 2432, 'designed': 2433, 'designer': 2434, 'designing': 2435, 'desirable': 2436, 'desired': 2437, 'Despite': 2438, 'despite': 2439, 'destabilize': 2440, 'destinations': 2441, 'DET': 2442, 'detail': 2443, 'detailed': 2444, 'Detailed': 2445, 'details': 2446, 'detect': 2447, 'Detect': 2448, 'detected': 2449, 'Detecting': 2450, 'detecting': 2451, 'detection': 2452, 'Detection': 2453, 'detector': 2454, 'Detector': 2455, 'detectors': 2456, 'detects': 2457, 'deteriorated': 2458, 'deterioration': 2459, 'Determination': 2460, 'determination': 2461, 'determine': 2462, 'determined': 2463, 'determines': 2464, 'determining': 2465, 'Determining': 2466, 'Deterministic': 2467, 'deterministic': 2468, 'Detrimental': 2469, 'detrimental': 2470, 'develop': 2471, 'Developed': 2472, 'developed': 2473, 'developers': 2474, 'Developers': 2475, 'developing': 2476, 'Developing': 2477, 'Development': 2478, 'development': 2479, 'developments': 2480, 'developping': 2481, 'develops': 2482, 'Deviance': 2483, 'deviates': 2484, 'deviation': 2485, 'deviations': 2486, 'device': 2487, 'Device': 2488, 'Devices': 2489, 'devices': 2490, 'devise': 2491, 'devised': 2492, 'devoted': 2493, 'Dewey': 2494, 'DEX': 2495, 'dh-hemts': 2496, 'diabetes': 2497, 'Diabetes': 2498, 'Diabetic': 2499, 'diabetic': 2500, 'diagnosability': 2501, 'diagnosabiliy': 2502, 'diagnose': 2503, 'diagnosed': 2504, 'diagnoser': 2505, 'diagnosing': 2506, 'Diagnosis': 2507, 'diagnosis': 2508, 'diagnostic': 2509, 'diagnostics': 2510, 'Diagnostics': 2511, 'diagram': 2512, 'diary': 2513, 'Dice': 2514, 'Dickey': 2515, 'dictated': 2516, 'dictionary': 2517, 'did': 2518, 'Diet': 2519, 'diet': 2520, 'differ': 2521, 'difference': 2522, 'Difference': 2523, 'differences': 2524, 'Different': 2525, 'different': 2526, 'Differential': 2527, 'differential': 2528, 'differentiated': 2529, 'Differentiation': 2530, 'differentiation': 2531, 'differently': 2532, 'differs': 2533, 'difficult': 2534, 'difficulties': 2535, 'difficulty': 2536, 'digit': 2537, 'Digit': 2538, 'digital': 2539, 'digitalize': 2540, 'digitalSTROM': 2541, 'digitized': 2542, 'digits': 2543, 'DIL': 2544, 'dilemma': 2545, 'dim': 2546, 'dimension': 2547, 'Dimension': 2548, 'dimensional': 2549, 'Dimensional': 2550, 'dimensional reduction': 2551, 'dimensionality': 2552, 'Dimensionality': 2553, 'dimensionality reduction': 2554, 'dimensioning': 2555, 'dimensions': 2556, 'Dimensions': 2557, 'Diminuendo': 2558, 'diodes': 2559, 'DIP': 2560, 'dips': 2561, 'Direct': 2562, 'direct': 2563, 'Directed': 2564, 'directed': 2565, 'direction': 2566, 'Direction': 2567, 'directions': 2568, 'directly': 2569, 'directs': 2570, 'Dirichlet': 2571, 'dirichlet process': 2572, 'disable': 2573, 'disabled': 2574, 'disadvantages': 2575, 'disaggregate': 2576, 'Disaggregation': 2577, 'disaggregation': 2578, 'disappear': 2579, 'disasters': 2580, 'discard': 2581, 'discarded': 2582, 'discarding': 2583, 'discern': 2584, 'disciplinary': 2585, 'discipline': 2586, 'disciplined': 2587, 'disclosure': 2588, 'discontinuous': 2589, 'discourse': 2590, 'discover': 2591, 'discovered': 2592, 'Discovering': 2593, 'discovering': 2594, 'discovery': 2595, 'Discovery': 2596, 'discrete': 2597, 'Discrete': 2598, 'discrete cosine transforms': 2599, 'discrete event systems': 2600, 'discrete fourier': 2601, 'discrete-event systems': 2602, 'discretization': 2603, 'discretize': 2604, 'discretizing': 2605, 'discriminant': 2606, 'Discriminant': 2607, 'discriminate': 2608, 'discriminates': 2609, 'discriminating': 2610, 'discrimination': 2611, 'Discrimination': 2612, 'discriminative': 2613, 'Discriminative': 2614, 'discriminatory': 2615, 'discs': 2616, 'discuss': 2617, 'discussed': 2618, 'discusses': 2619, 'discussion': 2620, 'disease': 2621, 'Disease': 2622, 'diseased': 2623, 'diseases': 2624, 'disjoint': 2625, 'disjunctive': 2626, 'disorder': 2627, 'Disorder': 2628, 'disorders': 2629, 'Disorders': 2630, 'disparate': 2631, 'disparity': 2632, 'dispatch': 2633, 'dispersed': 2634, 'dispersion': 2635, 'Dispersion': 2636, 'display': 2637, 'displays': 2638, 'disputed': 2639, 'disregarded': 2640, 'disruption': 2641, 'dissatisfaction': 2642, 'disseminate': 2643, 'dissemination': 2644, 'dissimilarity': 2645, 'Distance': 2646, 'distance': 2647, 'distances': 2648, 'distinct': 2649, 'distinctions': 2650, 'distinctive': 2651, 'distinctness': 2652, 'distinctness measure of clusters': 2653, 'distinguish': 2654, 'distinguished': 2655, 'distinguishing': 2656, 'distorted': 2657, 'distortion': 2658, 'distress': 2659, 'Distributable': 2660, 'distribute': 2661, 'distributed': 2662, 'DistributEd': 2663, 'Distributed': 2664, 'distributed computing': 2665, 'distributed data clustering': 2666, 'distributed sgd': 2667, 'distributed simulation': 2668, 'distribution': 2669, 'Distribution': 2670, 'Distributions': 2671, 'distributions': 2672, 'divergence': 2673, 'Divergence': 2674, 'diverse': 2675, 'diversification': 2676, 'diversifying': 2677, 'diversity': 2678, 'Diversity': 2679, 'divide': 2680, 'divided': 2681, 'dividing': 2682, 'division': 2683, 'divisive': 2684, 'Divisive': 2685, 'divisive analysis': 2686, 'DK': 2687, 'DL': 2688, 'DNK': 2689, 'DNN': 2690, 'dnn': 2691, 'DNNs': 2692, 'do': 2693, 'docetaxel': 2694, 'doctor': 2695, 'document': 2696, 'Document': 2697, 'document classification': 2698, 'documentation': 2699, 'documented': 2700, 'documents': 2701, 'does': 2702, 'Does': 2703, 'doing': 2704, 'Doing': 2705, 'dollars': 2706, 'DOM': 2707, 'Domain': 2708, 'domain': 2709, 'domain class imbalance': 2710, 'domain knowledge': 2711, 'domains': 2712, 'Domestic': 2713, 'domestic': 2714, 'domestic hot water': 2715, 'dominant': 2716, 'dominate': 2717, 'dominated': 2718, 'don': 2719, 'done': 2720, 'donor': 2721, 'Donor': 2722, 'donor selection': 2723, 'donors': 2724, 'dont': 2725, 'doors': 2726, 'DoS': 2727, 'dos attack': 2728, 'dot': 2729, 'Dot': 2730, 'Doubles': 2731, 'doubles': 2732, 'down': 2733, 'downscale': 2734, 'Downscaling': 2735, 'downscaling': 2736, 'downstairs': 2737, 'downstream': 2738, 'downtime': 2739, 'DP': 2740, 'DPFNN': 2741, 'DQN': 2742, 'drastically': 2743, 'draw': 2744, 'drawback': 2745, 'Drawbacks': 2746, 'drawing': 2747, 'Drawn': 2748, 'drawn': 2749, 'draws': 2750, 'DREAM4': 2751, 'drift': 2752, 'Drift': 2753, 'drifted': 2754, 'Drifting': 2755, 'drifting': 2756, 'drifts': 2757, 'drive': 2758, 'Drive': 2759, 'Driven': 2760, 'driven': 2761, 'driver': 2762, 'driver behavior': 2763, 'drivers': 2764, 'drives': 2765, 'driving': 2766, 'DRL': 2767, 'drop': 2768, 'drop out technique': 2769, 'Dropout': 2770, 'dropout': 2771, 'dropping': 2772, 'drought': 2773, 'drought modelling': 2774, 'Drug': 2775, 'drug': 2776, 'drug-design': 2777, 'drugs': 2778, 'DTNMF': 2779, 'DTSCluster': 2780, 'DTW': 2781, 'dual': 2782, 'Dual': 2783, 'DUC2002': 2784, 'due': 2785, 'Due': 2786, 'Duration': 2787, 'duration': 2788, 'durations': 2789, 'Durbin': 2790, 'during': 2791, 'During': 2792, 'dwt': 2793, 'DWT': 2794, 'Dynamic': 2795, 'dynamic': 2796, 'dynamic clustering': 2797, 'dynamic factor analysis': 2798, 'dynamic kernels': 2799, 'dynamic programming': 2800, 'dynamic system': 2801, 'dynamic web domain': 2802, 'dynamical': 2803, 'dynamical systems': 2804, 'dynamically': 2805, 'dynamicity': 2806, 'Dynamics': 2807, 'dynamics': 2808, 'e': 2809, 'e-commerce': 2810, 'EA': 2811, 'ea+rl': 2812, 'Each': 2813, 'each': 2814, 'Eager': 2815, 'Earlier': 2816, 'earlier': 2817, 'Early': 2818, 'early': 2819, 'earned': 2820, 'eart': 2821, 'earth': 2822, 'Earth': 2823, 'earth levee': 2824, 'ease': 2825, 'eases': 2826, 'easier': 2827, 'easily': 2828, 'easing': 2829, 'Eastern': 2830, 'easy': 2831, 'eating': 2832, 'Eating': 2833, 'Eazy': 2834, 'ECD': 2835, 'ECG': 2836, 'ecg': 2837, 'ECHMM': 2838, 'ECHMMs': 2839, 'Eclipse': 2840, 'ecognition': 2841, 'ecology': 2842, 'econometric': 2843, 'economic': 2844, 'economically': 2845, 'economy': 2846, 'ECU': 2847, 'Ecuador': 2848, 'ECUs': 2849, 'Edge': 2850, 'edge': 2851, 'edges': 2852, 'Edison': 2853, 'editors': 2854, 'EDL': 2855, 'EDLs': 2856, 'education': 2857, 'Education': 2858, 'educational': 2859, 'Educational': 2860, 'educational analytics': 2861, 'educational data mining': 2862, 'educational data mining (edm)': 2863, 'educational institutions': 2864, 'EEG': 2865, 'eeg signals': 2866, 'eembedding payload': 2867, 'EFC': 2868, 'Effect': 2869, 'effect': 2870, 'effective': 2871, 'Effective': 2872, 'effective sample size': 2873, 'effectively': 2874, 'Effectively': 2875, 'effectiveness': 2876, 'Effects': 2877, 'effects': 2878, 'efficacy': 2879, 'efficiency': 2880, 'Efficiency': 2881, 'efficient': 2882, 'Efficient': 2883, 'efficiently': 2884, 'Effort': 2885, 'effort': 2886, 'effort prediction': 2887, 'efforts': 2888, 'EFIS': 2889, 'EFSM': 2890, 'EGO': 2891, 'eigenfaces': 2892, 'eigenvalue': 2893, 'eigenvalues': 2894, 'eigenvector': 2895, 'eigenvectors': 2896, 'eight': 2897, 'eikonal': 2898, 'either': 2899, 'elaborates': 2900, 'elagant': 2901, 'elapsed': 2902, 'elderly': 2903, 'electric': 2904, 'Electric': 2905, 'electrical': 2906, 'electrical engineering': 2907, 'electricity': 2908, 'Electricity': 2909, 'electricity market': 2910, 'electricity retail markets': 2911, 'electrocardiogram': 2912, 'electrocardiograms': 2913, 'electrocardiography': 2914, 'electroencephalogram': 2915, 'Electroencephalogram': 2916, 'electroencephalography': 2917, 'Electronic': 2918, 'electronic mail': 2919, 'element': 2920, 'Elements': 2921, 'elements': 2922, 'elevated': 2923, 'elicited': 2924, 'eliminates': 2925, 'Eliminating': 2926, 'eliminating': 2927, 'elimination': 2928, 'ellipse': 2929, 'elliptic': 2930, 'Elman': 2931, 'else': 2932, 'ELU': 2933, 'EM': 2934, 'email': 2935, 'emails': 2936, 'embankment': 2937, 'embed': 2938, 'embedded': 2939, 'Embedded': 2940, 'embedded methods': 2941, 'Embedding': 2942, 'embedding': 2943, 'embedding efficiency': 2944, 'embeddings': 2945, 'Embeddings': 2946, 'embodies': 2947, 'embody': 2948, 'embraced': 2949, 'EMD': 2950, 'emerge': 2951, 'emerged': 2952, 'emergence': 2953, 'emerges': 2954, 'emerging': 2955, 'emitting': 2956, 'emotion': 2957, 'emotions': 2958, 'emphasis': 2959, 'Empirical': 2960, 'empirical': 2961, 'empirical mode decomposition': 2962, 'empirically': 2963, 'employ': 2964, 'employed': 2965, 'employing': 2966, 'Employing': 2967, 'employment': 2968, 'employs': 2969, 'empowered': 2970, 'empowers': 2971, 'empty': 2972, 'emulates': 2973, 'enable': 2974, 'enabled': 2975, 'enables': 2976, 'encapsulate': 2977, 'encode': 2978, 'encoded': 2979, 'encoders': 2980, 'Encoders': 2981, 'encoding': 2982, 'Encoding': 2983, 'encompassing': 2984, 'encountered': 2985, 'encourage': 2986, 'encouraging': 2987, 'encrypted': 2988, 'encryption': 2989, 'end': 2990, 'endanger': 2991, 'endeavor': 2992, 'energy': 2993, 'Energy': 2994, 'energy end-use model': 2995, 'energy management': 2996, 'energy saving': 2997, 'enforce': 2998, 'enforced': 2999, 'enforcement': 3000, 'enforcing': 3001, 'engage': 3002, 'engagement': 3003, 'Engagement': 3004, 'engagement detection': 3005, 'engine': 3006, 'engineer': 3007, 'engineering': 3008, 'engineers': 3009, 'engines': 3010, 'English': 3011, 'english': 3012, 'enhance': 3013, 'Enhanced': 3014, 'enhanced': 3015, 'Enhanceing': 3016, 'Enhancement': 3017, 'enhancement': 3018, 'enhancements': 3019, 'enhances': 3020, 'enhancing': 3021, 'enjoys': 3022, 'enormous': 3023, 'enough': 3024, 'enriches': 3025, 'enriching': 3026, 'enrolled': 3027, 'Ensemble': 3028, 'ensemble': 3029, 'ensemble clustering': 3030, 'ensemble learning': 3031, 'ensemble method': 3032, 'ensemble methods': 3033, 'ensembles': 3034, 'ensue': 3035, 'ensues': 3036, 'ensure': 3037, 'ensures': 3038, 'ensuring': 3039, 'entails': 3040, 'enterprise': 3041, 'enterprises': 3042, 'enthusiastic': 3043, 'entiated': 3044, 'entire': 3045, 'entirely': 3046, 'entities': 3047, 'entitled': 3048, 'entity': 3049, 'Entity': 3050, 'entity extraction': 3051, 'entrance': 3052, 'entries': 3053, 'entropy': 3054, 'Entropy': 3055, 'entropy0': 3056, 'entry': 3057, 'envelope': 3058, 'Environment': 3059, 'environment': 3060, 'Environmental': 3061, 'environmental': 3062, 'environmental sound recognition': 3063, 'environments': 3064, 'Environments': 3065, 'epilepsy': 3066, 'Epilepsy': 3067, 'Epileptic': 3068, 'epileptic': 3069, 'epileptogenesis': 3070, 'Epileptogenesis': 3071, 'episode': 3072, 'episodes': 3073, 'epoch': 3074, 'epochs': 3075, 'EPP': 3076, 'EQ': 3077, 'EQs': 3078, 'equal': 3079, 'equal loudness contour': 3080, 'equality': 3081, 'equalization': 3082, 'Equalization': 3083, 'equalizer': 3084, 'equalizers': 3085, 'equally': 3086, 'equation': 3087, 'Equation': 3088, 'Equations': 3089, 'equations': 3090, 'Equi': 3091, 'equipment': 3092, 'Equipment': 3093, 'equipment condition diagnosis (ecd)': 3094, 'equipped': 3095, 'equivalent': 3096, 'era': 3097, 'Erdos': 3098, 'Ergodic': 3099, 'Erosion': 3100, 'erosion': 3101, 'erred': 3102, 'erroneous': 3103, 'error': 3104, 'Error': 3105, 'error analysis': 3106, 'error entropy': 3107, 'errors': 3108, 'ers': 3109, 'erupted': 3110, 'es': 3111, 'ES': 3112, 'ESC': 3113, 'ESDMK': 3114, 'ESDMKs': 3115, 'ESM': 3116, 'esm': 3117, 'especially': 3118, 'esr': 3119, 'essays': 3120, 'Essays': 3121, 'essence': 3122, 'essential': 3123, 'establish': 3124, 'established': 3125, 'establishes': 3126, 'establishing': 3127, 'estate': 3128, 'estimate': 3129, 'estimated': 3130, 'Estimates': 3131, 'estimates': 3132, 'estimating': 3133, 'Estimation': 3134, 'estimation': 3135, 'estimation of students successes': 3136, 'estimator': 3137, 'estimators': 3138, 'et': 3139, 'etalon': 3140, 'etc': 3141, 'etiologies': 3142, 'EUC': 3143, 'Euclidean': 3144, 'EURECOM': 3145, 'Europe': 3146, 'European': 3147, 'evaluate': 3148, 'evaluated': 3149, 'evaluates': 3150, 'evaluating': 3151, 'Evaluating': 3152, 'evaluation': 3153, 'Evaluation': 3154, 'Evaluations': 3155, 'evaluations': 3156, 'evaluator': 3157, 'evaluators': 3158, 'evaporation': 3159, 'Evaporation': 3160, 'evapotranspiration': 3161, 'even': 3162, 'Event': 3163, 'event': 3164, 'event coreference': 3165, 'event detection': 3166, 'event related potentials': 3167, 'Events': 3168, 'events': 3169, 'eventually': 3170, 'ever': 3171, 'Every': 3172, 'every': 3173, 'eviction': 3174, 'evidence': 3175, 'evident': 3176, 'Evidential': 3177, 'evidential': 3178, 'evidential database': 3179, 'evoked': 3180, 'Evoked': 3181, 'Evolution': 3182, 'evolution': 3183, 'Evolutionary': 3184, 'evolutionary': 3185, 'evolutionary algorithms': 3186, 'evolutionary based learning': 3187, 'evolutionary computing': 3188, 'Evolvable': 3189, 'evolve': 3190, 'evolved': 3191, 'Evolved': 3192, 'evolves': 3193, 'Evolving': 3194, 'evolving': 3195, 'evolving (fuzzy) classifiers': 3196, 'evolving fuzzy systems': 3197, 'evolving graph': 3198, 'evolving networks': 3199, 'EX': 3200, 'exact': 3201, 'Exact': 3202, 'exact inference': 3203, 'exactly': 3204, 'exam': 3205, 'Examination': 3206, 'examination': 3207, 'examine': 3208, 'examined': 3209, 'examiner': 3210, 'examines': 3211, 'examining': 3212, 'Examining': 3213, 'Example': 3214, 'example': 3215, 'Examples': 3216, 'examples': 3217, 'exams': 3218, 'exceed': 3219, 'exceeded': 3220, 'excellent': 3221, 'except': 3222, 'exception': 3223, 'exceptional': 3224, 'Exchange': 3225, 'exchange': 3226, 'Executable': 3227, 'execute': 3228, 'executed': 3229, 'executing': 3230, 'execution': 3231, 'executions': 3232, 'exemplars': 3233, 'Exemplars': 3234, 'exemplify': 3235, 'exerted': 3236, 'exhausting': 3237, 'exhaustive': 3238, 'exhaustively': 3239, 'exhibit': 3240, 'exhibiting': 3241, 'exhibits': 3242, 'exist': 3243, 'existence': 3244, 'Existing': 3245, 'existing': 3246, 'exists': 3247, 'expanded': 3248, 'expansion': 3249, 'expect': 3250, 'expectation': 3251, 'Expectation': 3252, 'expectation maximization': 3253, 'expected': 3254, \"expected change in classifier's accuracy\": 3255, 'expectedly': 3256, 'expense': 3257, 'expenses': 3258, 'expensive': 3259, 'Experience': 3260, 'experience': 3261, 'experienced': 3262, 'experiences': 3263, 'Experiment': 3264, 'experiment': 3265, 'experimental': 3266, 'Experimental': 3267, 'experimentally': 3268, 'experimentation': 3269, 'experimentations': 3270, 'experimented': 3271, 'Experiments': 3272, 'experiments': 3273, 'expert': 3274, 'Expert': 3275, 'expert knowledge': 3276, 'expert systems': 3277, 'expertly': 3278, 'experts': 3279, 'Experts': 3280, 'explain': 3281, 'Explainable': 3282, 'explainable': 3283, 'explaining': 3284, 'explains': 3285, 'explanation': 3286, 'explanations': 3287, 'explanatory': 3288, 'explicitly': 3289, 'exploit': 3290, 'Exploitation': 3291, 'exploitation': 3292, 'exploited': 3293, 'Exploiting': 3294, 'exploiting': 3295, 'exploits': 3296, 'exploration': 3297, 'explorations': 3298, 'explore': 3299, 'explored': 3300, 'explores': 3301, 'Exploring': 3302, 'exploring': 3303, 'explosion': 3304, 'Exponential': 3305, 'exponential': 3306, 'exponential regression': 3307, 'Exponentially': 3308, 'exponentially': 3309, 'exposed': 3310, 'exposes': 3311, 'Exposing': 3312, 'exposure': 3313, 'express': 3314, 'expressed': 3315, 'expresses': 3316, 'expression': 3317, 'Expression': 3318, 'expressions': 3319, 'expressive': 3320, 'extend': 3321, 'extended': 3322, 'Extended': 3323, 'Extending': 3324, 'extends': 3325, 'extension': 3326, 'Extensive': 3327, 'extensive': 3328, 'extensively': 3329, 'Extent': 3330, 'extent': 3331, 'external': 3332, 'External': 3333, 'extra': 3334, 'extract': 3335, 'Extracted': 3336, 'extracted': 3337, 'extracting': 3338, 'Extracting': 3339, 'extraction': 3340, 'Extraction': 3341, 'extraction patterns': 3342, 'extractive': 3343, 'extractor': 3344, 'extractors': 3345, 'Extractors': 3346, 'extracts': 3347, 'extrapolation': 3348, 'extreme': 3349, 'extreme verification latency': 3350, 'extremely': 3351, 'eye': 3352, 'EyeQual': 3353, 'eyes': 3354, 'f': 3355, 'F': 3356, 'F1': 3357, 'FA': 3358, 'Face': 3359, 'face': 3360, 'face recognition': 3361, 'Facebook': 3362, 'faces': 3363, 'facet': 3364, 'Facial': 3365, 'facial': 3366, 'facial expression recognition': 3367, 'facilitate': 3368, 'facilitated': 3369, 'facilitates': 3370, 'facilitating': 3371, 'facilities': 3372, 'facing': 3373, 'fact': 3374, 'facto': 3375, 'factor': 3376, 'Factor': 3377, 'factorization': 3378, 'Factorization': 3379, 'Factors': 3380, 'factors': 3381, 'facts': 3382, 'factuality': 3383, 'faculties': 3384, 'fail': 3385, 'failed': 3386, 'failing': 3387, 'fails': 3388, 'failure': 3389, 'Failure': 3390, 'Failures': 3391, 'failures': 3392, 'fair': 3393, 'fairly': 3394, 'fairness': 3395, 'Fairness': 3396, 'fake': 3397, 'Fake': 3398, 'fake user accounts': 3399, 'fall': 3400, 'falls': 3401, 'False': 3402, 'false': 3403, 'falsification': 3404, 'familiar': 3405, 'families': 3406, 'Family': 3407, 'family': 3408, 'famous': 3409, 'fans': 3410, 'far': 3411, 'fares': 3412, 'farmer': 3413, 'farmers': 3414, 'fashion': 3415, 'fast': 3416, 'Fast': 3417, 'faster': 3418, 'fastQ': 3419, 'Fatigue': 3420, 'fatigue': 3421, 'Fault': 3422, 'fault': 3423, 'fault data injection': 3424, 'fault detection': 3425, 'fault detection and classification (fdc)': 3426, 'fault diagnosis': 3427, 'fault fingerprint extraction': 3428, 'fault localization': 3429, 'Faults': 3430, 'faults': 3431, 'faults localization': 3432, 'Faulty': 3433, 'faulty': 3434, 'favorably': 3435, 'favors': 3436, 'FC': 3437, 'FCGPANN': 3438, 'FDC': 3439, 'fdd': 3440, 'feasibility': 3441, 'feasible': 3442, 'feature': 3443, 'Feature': 3444, 'feature aware': 3445, 'feature discovery': 3446, 'feature extraction': 3447, 'feature fusion': 3448, 'feature learning': 3449, 'feature recognition': 3450, 'feature selection': 3451, 'feature vector': 3452, 'features': 3453, 'Features': 3454, 'features selection': 3455, 'fed': 3456, 'feed': 3457, 'feed-forward networks': 3458, 'feedback': 3459, 'feeder': 3460, 'Feeder': 3461, 'Feedforward': 3462, 'feedforward': 3463, 'feel': 3464, 'female': 3465, 'females': 3466, 'FERET': 3467, 'Fetal': 3468, 'fetal': 3469, 'few': 3470, 'Few': 3471, 'fewer': 3472, 'Fiber': 3473, 'fiber': 3474, 'fibers': 3475, 'fidelity': 3476, 'fiducial': 3477, 'field': 3478, 'Field': 3479, 'fields': 3480, 'Fields': 3481, 'FIFO': 3482, 'fifty': 3483, 'fighting': 3484, 'figures': 3485, 'filament': 3486, 'file': 3487, 'Filed': 3488, 'Filer': 3489, 'files': 3490, 'fill': 3491, 'filled': 3492, 'filling': 3493, 'film': 3494, 'Film': 3495, 'filter': 3496, 'Filter': 3497, 'filterbank': 3498, 'filtered': 3499, 'Filtering': 3500, 'filtering': 3501, 'filters': 3502, 'Filters': 3503, 'filtration': 3504, 'Final': 3505, 'final': 3506, 'finally': 3507, 'Finally': 3508, 'finance': 3509, 'financial': 3510, 'Financial': 3511, 'financial markets': 3512, 'find': 3513, 'finding': 3514, 'Finding': 3515, 'findings': 3516, 'finds': 3517, 'fine': 3518, 'Fine': 3519, 'fine tuning': 3520, 'Finger': 3521, 'finger': 3522, 'Fingerprint': 3523, 'fingerprint': 3524, 'fingerprinting': 3525, 'Fingerprinting': 3526, 'fingerprints': 3527, 'Fingerprints': 3528, 'fingers': 3529, 'finite': 3530, 'Finite': 3531, 'finite-state machines': 3532, 'finiteness': 3533, 'fire': 3534, 'fires': 3535, 'firewall': 3536, 'firewalls (computing)': 3537, 'firmlp': 3538, 'FIRMLP': 3539, 'First': 3540, 'first': 3541, 'firstly': 3542, 'Firstly': 3543, 'Fisher': 3544, 'fisher vector (fv) feature representation': 3545, 'fit': 3546, 'fitness': 3547, 'fits': 3548, 'fitted': 3549, 'fittest': 3550, 'fitting': 3551, 'Five': 3552, 'five': 3553, 'fixed': 3554, 'flat': 3555, 'flaw': 3556, 'FLC': 3557, 'Fleet': 3558, 'flexibility': 3559, 'flexible': 3560, 'Flexible': 3561, 'flickering': 3562, 'Flipping': 3563, 'floods': 3564, 'flow': 3565, 'Flow': 3566, 'flow forecast': 3567, 'flowing': 3568, 'flows': 3569, 'fluctuating': 3570, 'fluctuations': 3571, 'fluid': 3572, 'fluidic': 3573, 'fluorescence': 3574, 'fly': 3575, 'Fly': 3576, 'fMLR': 3577, 'fMRI': 3578, 'Focus': 3579, 'focus': 3580, 'focused': 3581, 'focuses': 3582, 'focusing': 3583, 'fold': 3584, 'Folded': 3585, 'folding': 3586, 'follow': 3587, 'followed': 3588, 'Following': 3589, 'following': 3590, 'follows': 3591, 'food': 3592, 'foods': 3593, 'foot': 3594, 'footprint': 3595, 'Footprint': 3596, 'for': 3597, 'For': 3598, 'foraging': 3599, 'force': 3600, 'Force': 3601, 'force plate': 3602, 'forces': 3603, 'forcing': 3604, 'forecast': 3605, 'Forecast': 3606, 'forecast combination': 3607, 'Forecaster': 3608, 'forecaster': 3609, 'forecasting': 3610, 'Forecasting': 3611, 'forecasting energy demand': 3612, 'Forecasts': 3613, 'forecasts': 3614, 'foreclosure': 3615, 'Foreclosure': 3616, 'foreclosure-and-real-estate-market': 3617, 'foreground': 3618, 'foreign': 3619, 'Foreign': 3620, 'foremost': 3621, 'forensic': 3622, 'Forensic': 3623, 'forensics': 3624, 'forest': 3625, 'Forest': 3626, 'Forests': 3627, 'forests': 3628, 'forfingerprint': 3629, 'forged': 3630, 'forgery': 3631, 'Forgery': 3632, 'forgetting': 3633, 'forgotten': 3634, 'fork': 3635, 'form': 3636, 'Form': 3637, 'Formal': 3638, 'formal': 3639, 'formal modeling': 3640, 'formalism': 3641, 'formalize': 3642, 'formalized': 3643, 'formance': 3644, 'formed': 3645, 'former': 3646, 'forming': 3647, 'forms': 3648, 'formulate': 3649, 'formulated': 3650, 'formulation': 3651, 'formulations': 3652, 'forth': 3653, 'forum': 3654, 'forums': 3655, 'Forums': 3656, 'Forward': 3657, 'forward': 3658, 'forward looking sonars': 3659, 'forwarded': 3660, 'foster': 3661, 'found': 3662, 'foundation': 3663, 'founded': 3664, 'Four': 3665, 'four': 3666, 'four dimension': 3667, 'Fourier': 3668, 'Fourth': 3669, 'fourth': 3670, 'FPE': 3671, 'FRA': 3672, 'fraction': 3673, 'fragmented': 3674, 'frame': 3675, 'frames': 3676, 'Framework': 3677, 'framework': 3678, 'Frameworks': 3679, 'frameworks': 3680, 'France': 3681, 'Fraud': 3682, 'fraud': 3683, 'fraud detection': 3684, 'fraudulent': 3685, 'free': 3686, 'freelancer': 3687, 'frequencies': 3688, 'frequency': 3689, 'Frequency': 3690, 'frequency response analysis fra': 3691, 'frequent': 3692, 'Frequent': 3693, 'frequent patterns': 3694, 'frequent sequence pattern mining': 3695, 'frequent set mining': 3696, 'Frequently': 3697, 'frequently': 3698, 'freshly': 3699, 'Freund': 3700, 'friendly': 3701, 'from': 3702, 'From': 3703, 'front': 3704, 'FSS': 3705, 'fueled': 3706, 'fulfilling': 3707, 'full': 3708, 'Fuller': 3709, 'fully': 3710, 'function': 3711, 'Function': 3712, 'function approximation': 3713, 'functional': 3714, 'Functional': 3715, 'functional connectivity': 3716, 'functional dependency': 3717, 'functional time series': 3718, 'functionality': 3719, 'functions': 3720, 'Functions': 3721, 'fundamental': 3722, 'fundamentals': 3723, 'Further': 3724, 'further': 3725, 'furthermore': 3726, 'Furthermore': 3727, 'fused': 3728, 'fusing': 3729, 'fusion': 3730, 'Fusion': 3731, 'future': 3732, 'Future': 3733, 'futuristic': 3734, 'fuzzy': 3735, 'Fuzzy': 3736, 'fuzzy clustering': 3737, 'fuzzy discrete event system': 3738, 'fuzzy logic': 3739, 'fuzzy operations': 3740, 'fuzzy rules': 3741, 'fuzzy soft sets': 3742, 'fuzzy systems': 3743, 'fuzzy-logic-controller': 3744, 'fuzzy-neighborhood density-based clustering': 3745, 'FV': 3746, 'FVC2004': 3747, 'g': 3748, 'GA': 3749, 'GAEMN': 3750, 'gain': 3751, 'gain parameter and drop out technique': 3752, 'gained': 3753, 'gaining': 3754, 'gains': 3755, 'gait': 3756, 'gait analysis': 3757, 'Galaxy': 3758, 'Game': 3759, 'game': 3760, 'game theory': 3761, 'game-data': 3762, 'games': 3763, 'gamma': 3764, 'Gamma': 3765, 'gamma distribution': 3766, 'gamma-ray spectra': 3767, 'gap': 3768, 'Gaps': 3769, 'gaps': 3770, 'garden': 3771, 'GAs': 3772, 'Gate': 3773, 'gather': 3774, 'gathered': 3775, 'GATK': 3776, 'Gaussian': 3777, 'gaussian mixture': 3778, 'gaussian mixture model': 3779, 'gaussian mixture model (gmm)': 3780, 'gaussian process': 3781, 'gaussian process regression': 3782, 'gaussian processes': 3783, 'gaussian radial basis function': 3784, 'GBT': 3785, 'GCM': 3786, 'gcm data': 3787, 'GCMs': 3788, 'GCPV': 3789, 'gender': 3790, 'Gender': 3791, 'gender identification': 3792, 'Gene': 3793, 'gene': 3794, 'gene coexpression networks': 3795, 'gene expression data': 3796, 'GENEActiv': 3797, 'geneous': 3798, 'General': 3799, 'general': 3800, 'generalisation': 3801, 'Generalization': 3802, 'generalization': 3803, 'generalize': 3804, 'Generalized': 3805, 'generalized': 3806, 'generalizes': 3807, 'generalizing': 3808, 'Generally': 3809, 'generally': 3810, 'generate': 3811, 'generated': 3812, 'generates': 3813, 'generating': 3814, 'Generation': 3815, 'generation': 3816, 'generations': 3817, 'generative': 3818, 'generative learning': 3819, 'generative models': 3820, 'generator': 3821, 'generators': 3822, 'generic': 3823, 'genes': 3824, 'genetic': 3825, 'Genetic': 3826, 'genetic algorithm': 3827, 'genetic algorithms': 3828, 'genetic optimization and supervision': 3829, 'Genetically': 3830, 'genetically': 3831, 'genetics': 3832, 'genome': 3833, 'Genome': 3834, 'genome analysis toolkit (gatk)': 3835, 'genome wide association studies': 3836, 'genomic': 3837, 'genomic data': 3838, 'genre': 3839, 'geo': 3840, 'geodesic': 3841, 'geodesically': 3842, 'geograph': 3843, 'Geographic': 3844, 'geographical': 3845, 'geometric': 3846, 'Geometric': 3847, 'geometrical': 3848, 'Geometrical': 3849, 'geometrical analysis': 3850, 'geometrically': 3851, 'geometry': 3852, 'geophysical': 3853, 'Geophysical': 3854, 'Georgia': 3855, 'geospa': 3856, 'geospatial': 3857, 'gestational': 3858, 'gestational hypertension': 3859, 'Gestures': 3860, 'gestures': 3861, 'get': 3862, 'gets': 3863, 'getting': 3864, 'Gibbs': 3865, 'Gigabytes': 3866, 'Github': 3867, 'give': 3868, 'Given': 3869, 'given': 3870, 'gives': 3871, 'giving': 3872, 'glass': 3873, 'Glass': 3874, 'GLM': 3875, 'Global': 3876, 'global': 3877, 'global optimization': 3878, 'globally': 3879, 'glucose': 3880, 'glyph': 3881, 'gmm': 3882, 'GMM': 3883, 'GMMs': 3884, 'GNU': 3885, 'go': 3886, 'goal': 3887, 'goals': 3888, 'goes': 3889, 'going': 3890, 'gold': 3891, 'golden': 3892, 'Golf': 3893, 'Good': 3894, 'good': 3895, 'goodness': 3896, 'google': 3897, 'Google': 3898, 'google cloud vision api': 3899, 'got': 3900, 'governing': 3901, 'government': 3902, 'governmental': 3903, 'Gower': 3904, \"gower's measure of similarity\": 3905, 'GPA': 3906, 'gpgpu': 3907, 'gplvm': 3908, 'GPLVM': 3909, 'GPS': 3910, 'gps': 3911, 'GPU': 3912, 'gpu computing': 3913, 'GPUMLib': 3914, 'GPUs': 3915, 'grabcut': 3916, 'GrabCut': 3917, 'gracefully': 3918, 'grade': 3919, 'gradient': 3920, 'Gradient': 3921, 'gradient approximation': 3922, 'Gradients': 3923, 'gradually': 3924, 'graduation': 3925, 'Grain': 3926, 'grain': 3927, 'grained': 3928, 'Grained': 3929, 'grains': 3930, 'gram': 3931, 'grammar': 3932, 'Grammar': 3933, 'grandmasters': 3934, 'Granger': 3935, 'granger-causality': 3936, 'grants': 3937, 'Granular': 3938, 'granular': 3939, 'granular computing': 3940, 'granulation': 3941, 'granules': 3942, 'Graph': 3943, 'graph': 3944, 'graph representation': 3945, 'graph sequence': 3946, 'graph theory': 3947, 'Graphic': 3948, 'graphical': 3949, 'Graphical': 3950, 'graphical model': 3951, 'graphical models': 3952, 'graphically': 3953, 'Graphics': 3954, 'graphics': 3955, 'graphs': 3956, 'Graphs': 3957, 'gray': 3958, 'gray-level co-occurrence matrix (glcm)': 3959, 'great': 3960, 'greater': 3961, 'greatly': 3962, 'greedy': 3963, 'Greedy': 3964, 'gress': 3965, 'gression': 3966, 'grib': 3967, 'Grid': 3968, 'grid': 3969, 'grid-connected-pv-system': 3970, 'grids': 3971, 'GRNs': 3972, 'ground': 3973, 'Group': 3974, 'group': 3975, 'group based labeling': 3976, 'group diversity': 3977, 'grouped': 3978, 'grouping': 3979, 'Grouping': 3980, 'groupings': 3981, 'groups': 3982, 'groups1': 3983, 'grow': 3984, 'Growing': 3985, 'growing': 3986, 'grows': 3987, 'growth': 3988, 'GTIFRS': 3989, 'guarantee': 3990, 'guarantees': 3991, 'GUI': 3992, 'gui': 3993, 'guidance': 3994, 'guide': 3995, 'Guidelines': 3996, 'guidelines': 3997, 'guiding': 3998, 'Gustafson': 3999, 'gyroscope': 4000, 'h': 4001, 'H': 4002, 'habitat': 4003, 'habits': 4004, 'hacker': 4005, 'had': 4006, 'HadCM3': 4007, 'Hadoop': 4008, 'half': 4009, 'Hamming': 4010, 'hamming codes': 4011, 'hand': 4012, 'handcrafted': 4013, 'handle': 4014, 'handled': 4015, 'handling': 4016, 'handoff': 4017, 'handover': 4018, 'Handover': 4019, 'handpicked': 4020, 'handwritten': 4021, 'handwritten digit recognition': 4022, 'Hannan': 4023, 'happen': 4024, 'happens': 4025, 'hard': 4026, 'Hard': 4027, 'harden': 4028, 'harder': 4029, 'hardware': 4030, 'harming': 4031, 'Harmonic': 4032, 'harmonic': 4033, 'harness': 4034, 'Harnessing': 4035, 'has': 4036, 'hashing': 4037, 'Hashing': 4038, 'Hashtags': 4039, 'Hausdorff': 4040, 'have': 4041, 'having': 4042, 'Hawai': 4043, 'hazard': 4044, 'hazy': 4045, 'HC': 4046, 'HCA': 4047, 'HCI': 4048, 'HDLTex': 4049, 'HDP': 4050, 'he': 4051, 'he12': 4052, 'headlines': 4053, 'Health': 4054, 'health': 4055, 'health social networks': 4056, 'Healthcare': 4057, 'healthcare': 4058, 'healthcare fraud': 4059, 'healthcare systems': 4060, 'healthy': 4061, 'Hearing': 4062, 'hearing': 4063, 'heart': 4064, 'Heart': 4065, 'heart disease': 4066, 'heart rate': 4067, 'heartbeat': 4068, 'heater': 4069, 'heating': 4070, 'Heating': 4071, 'heavily': 4072, 'heavy': 4073, 'Hedonic': 4074, 'hedonic': 4075, 'hedonic pricing model': 4076, 'hedonic theory': 4077, 'height': 4078, 'help': 4079, 'helpful': 4080, 'helping': 4081, 'helps': 4082, 'hematocrit': 4083, 'Hematopoietic': 4084, 'Hemiplegic': 4085, 'hemiplegic': 4086, 'hemiplegic gait': 4087, 'hemorrhagic': 4088, 'Hemorrhagic': 4089, 'Hence': 4090, 'hence': 4091, 'Henze': 4092, \"henze-zirkler's multivariate normality test\": 4093, 'her': 4094, 'here': 4095, 'Here': 4096, 'Hereby': 4097, 'hetero': 4098, 'heterogeneity': 4099, 'heterogeneous': 4100, 'Heterogeneous': 4101, 'heterogeneous-data': 4102, 'heuristic': 4103, 'Heuristic': 4104, 'heuristic word alignment': 4105, 'heuristically': 4106, 'heuristics': 4107, 'Hidden': 4108, 'hidden': 4109, 'hidden markov model': 4110, 'hidden markov model (hmm)': 4111, 'hidden markov models': 4112, 'hide': 4113, 'hierachical graph neuron': 4114, 'hierarchical': 4115, 'Hierarchical': 4116, 'hierarchical bayesian model': 4117, 'hierarchical classification': 4118, 'hierarchical clustering': 4119, 'hierarchical dirichlet process': 4120, 'hierarchical learning': 4121, 'hierarchy': 4122, 'high': 4123, 'High': 4124, 'high voltage feeder': 4125, 'high-dimensional data': 4126, 'high-dimensional input': 4127, 'high-order rbms': 4128, 'Higher': 4129, 'higher': 4130, 'highest': 4131, 'highlight': 4132, 'highlights': 4133, 'highly': 4134, 'Highly': 4135, 'highresource': 4136, 'highresources': 4137, 'highway': 4138, 'Highway': 4139, 'Hilbert': 4140, 'him': 4141, 'Himalayan': 4142, 'hindered': 4143, 'hindering': 4144, 'hinge': 4145, 'Hinton': 4146, 'hip': 4147, 'hippocampal': 4148, 'hiring': 4149, 'his': 4150, 'Histogram': 4151, 'histograms': 4152, 'historical': 4153, 'history': 4154, 'hit': 4155, 'HLA': 4156, 'HMM': 4157, 'hmm': 4158, 'HMMs': 4159, 'hoc': 4160, 'HOG': 4161, 'hold': 4162, 'holders': 4163, 'holds': 4164, 'holidays': 4165, 'home': 4166, 'Home': 4167, 'home appliances': 4168, 'homeostasis': 4169, 'homeowners': 4170, 'homes': 4171, 'Homes': 4172, 'homogeneous': 4173, 'homogenous': 4174, 'Homogenous': 4175, 'homomorphic': 4176, 'Honda': 4177, 'hope': 4178, 'Horizon': 4179, 'horizon': 4180, 'horizon line detection': 4181, 'horizons': 4182, 'horizontal': 4183, 'hospital': 4184, 'Hospital': 4185, 'hospitalizations': 4186, 'hospitalized': 4187, 'hospitals': 4188, 'host': 4189, 'hot': 4190, 'Hot': 4191, 'Hotspot': 4192, 'hotspot': 4193, 'hotspot mapping': 4194, 'hotspots': 4195, 'hour': 4196, 'hourly': 4197, 'Hourly': 4198, 'hours': 4199, 'House': 4200, 'house': 4201, 'houses': 4202, 'Housing': 4203, 'housing': 4204, 'housing prices prediction': 4205, 'how': 4206, 'However': 4207, 'however': 4208, 'HQ': 4209, 'HSDPA': 4210, 'html': 4211, 'HTTP': 4212, 'huge': 4213, 'human': 4214, 'Human': 4215, 'human action recognition': 4216, 'human activity recognition': 4217, 'human behavior prediction': 4218, 'human tracking': 4219, 'Human218': 4220, 'Humans': 4221, 'humans': 4222, 'humid': 4223, 'hundreds': 4224, 'HVAC': 4225, 'Hybrid': 4226, 'hybrid': 4227, 'hybrid algorithms': 4228, 'hybrid electric vehicles': 4229, 'hybrid learning algorithms': 4230, 'hybrid-neurone-fuzzy': 4231, 'HybridElectric': 4232, 'Hybridising': 4233, 'hydroelectric': 4234, 'Hydroelectric': 4235, 'hydrologic': 4236, 'hyper': 4237, 'hypercompetitive': 4238, 'hyperparameter': 4239, 'hyperparameter optimization': 4240, 'hyperparameters': 4241, 'hyperplane': 4242, 'hypertension': 4243, 'hypopnea': 4244, 'hypotheses': 4245, 'hypothesis': 4246, 'hypothesize': 4247, 'I': 4248, 'i': 4249, 'IBM': 4250, 'IC': 4251, 'ICA': 4252, 'ical': 4253, 'Ice': 4254, 'ice': 4255, 'iClass': 4256, 'ICMC': 4257, 'ICU': 4258, 'ICUs': 4259, 'ID': 4260, 'idea': 4261, 'ideal': 4262, 'Ideally': 4263, 'ideas': 4264, 'identically': 4265, 'identifiable': 4266, 'identification': 4267, 'Identification': 4268, 'identification-recognition': 4269, 'identified': 4270, 'identifies': 4271, 'identify': 4272, 'identifying': 4273, 'Identifying': 4274, 'identities': 4275, 'identity': 4276, 'Idiopathic': 4277, 'idiopathic': 4278, 'IDP': 4279, 'IDS': 4280, 'IDSs': 4281, 'IEC': 4282, 'IEEE': 4283, 'if': 4284, 'If': 4285, 'IFF': 4286, 'ignore': 4287, 'IHT': 4288, 'ii': 4289, 'iii': 4290, 'ill': 4291, 'Illinois': 4292, 'illumination': 4293, 'Illumine': 4294, 'illustrate': 4295, 'illustrated': 4296, 'illustrates': 4297, 'illustrative': 4298, 'im': 4299, 'IM': 4300, 'image': 4301, 'Image': 4302, 'image classification': 4303, 'image descriptors': 4304, 'image forgery detection': 4305, 'image matching': 4306, 'image noise': 4307, 'image processing': 4308, 'image restoration': 4309, 'image segmentation': 4310, 'image segments': 4311, 'image synthetization': 4312, 'image-based diagnosis': 4313, 'ImageNet': 4314, 'Images': 4315, 'images': 4316, 'imaging': 4317, 'Imbalance': 4318, 'imbalance': 4319, 'imbalanced': 4320, 'imbalanced classes': 4321, 'IMCP': 4322, 'imitate': 4323, 'immediate': 4324, 'immensely': 4325, 'immunity': 4326, 'immunohistochemical': 4327, 'Impact': 4328, 'impact': 4329, 'Impacts': 4330, 'impacts': 4331, 'impaired': 4332, 'impairment': 4333, 'IMPC': 4334, 'impeding': 4335, 'imperative': 4336, 'impetus': 4337, 'implement': 4338, 'implementable': 4339, 'implementation': 4340, 'Implementation': 4341, 'implementations': 4342, 'implemented': 4343, 'implementing': 4344, 'implements': 4345, 'implicated': 4346, 'implications': 4347, 'implicit': 4348, 'implicit feedback': 4349, 'implicitly': 4350, 'implies': 4351, 'imply': 4352, 'implying': 4353, 'importance': 4354, 'Importance': 4355, 'importance sampling': 4356, 'important': 4357, 'imposed': 4358, 'imposing': 4359, 'impossible': 4360, 'impractical': 4361, 'imprecise': 4362, 'imprecision': 4363, 'impressive': 4364, 'improper': 4365, 'improve': 4366, 'Improve': 4367, 'improved': 4368, 'Improved': 4369, 'Improvement': 4370, 'improvement': 4371, 'improvements': 4372, 'improves': 4373, 'improving': 4374, 'Improving': 4375, 'impulse': 4376, 'Impulse': 4377, 'imputation': 4378, 'Impute': 4379, 'In': 4380, 'in': 4381, 'in-hospital length of stay prediction': 4382, 'in-memory distribution': 4383, 'inadequate': 4384, 'inadvertent': 4385, 'inappropriate': 4386, 'incentives': 4387, 'incidence': 4388, 'Incidence': 4389, 'incident': 4390, 'Incident': 4391, 'incident-ranking': 4392, 'incidents': 4393, 'include': 4394, 'included': 4395, 'includes': 4396, 'including': 4397, 'Including': 4398, 'inclusion': 4399, 'Inclusion': 4400, 'incoming': 4401, 'Incomplete': 4402, 'incomplete': 4403, 'inconsistency': 4404, 'inconsistent': 4405, 'Inconsistent': 4406, 'incorporate': 4407, 'incorporated': 4408, 'incorporates': 4409, 'incorporating': 4410, 'incorrect': 4411, 'incorrectly': 4412, 'increase': 4413, 'increased': 4414, 'increases': 4415, 'increasing': 4416, 'increasingly': 4417, 'Increasingly': 4418, 'Incremental': 4419, 'incremental': 4420, 'incur': 4421, 'incurred': 4422, 'incurs': 4423, 'indeed': 4424, 'Indeed': 4425, 'indefinite': 4426, 'InDegree': 4427, 'independence': 4428, 'Independent': 4429, 'independent': 4430, 'independently': 4431, 'Index': 4432, 'index': 4433, 'index and ring finger ratio': 4434, 'indexes': 4435, 'Indexing': 4436, 'indexing': 4437, 'India': 4438, 'indicate': 4439, 'indicated': 4440, 'indicates': 4441, 'indicating': 4442, 'indication': 4443, 'Indicative': 4444, 'Indicator': 4445, 'indicator': 4446, 'indicators': 4447, 'indices': 4448, 'Indira': 4449, 'Individual': 4450, 'individual': 4451, 'individually': 4452, 'individuals': 4453, 'Indoor': 4454, 'indoor': 4455, 'indoor localization': 4456, 'indoor user movement': 4457, 'induce': 4458, 'induced': 4459, 'inducing': 4460, 'Induction': 4461, 'induction': 4462, 'induction motors': 4463, 'inductive': 4464, 'inductive logic programming': 4465, 'Industrial': 4466, 'industrial': 4467, 'industries': 4468, 'industry': 4469, 'ineligible': 4470, 'inertia': 4471, 'inertial': 4472, 'inertial measurement units': 4473, 'inevitable': 4474, 'inevitably': 4475, 'inexpensive': 4476, 'inexperience': 4477, 'infeasible': 4478, 'infection': 4479, 'infections': 4480, 'infer': 4481, 'Inference': 4482, 'inference': 4483, 'Inferences': 4484, 'inferential': 4485, 'Inferential': 4486, 'inferential reasoning': 4487, 'infering': 4488, 'inferred': 4489, 'Inferring': 4490, 'inferring': 4491, 'Infinite': 4492, 'infinite': 4493, 'infinitely': 4494, 'Infinitely': 4495, 'infinity': 4496, 'inflation': 4497, 'inflectional': 4498, 'inflict': 4499, 'influence': 4500, 'Influence': 4501, 'influenced': 4502, 'influences': 4503, 'inform': 4504, 'Information': 4505, 'information': 4506, 'information extraction': 4507, 'information need modeling': 4508, 'information retrieval': 4509, 'information theoretic learning': 4510, 'information theory': 4511, 'informative': 4512, 'informative weight': 4513, 'informed': 4514, 'Informed': 4515, 'informing': 4516, 'informs': 4517, 'Infrared': 4518, 'infrared': 4519, 'infrastructure': 4520, 'ingenious': 4521, 'Inhabitants': 4522, 'inhabitants': 4523, 'inhabiting': 4524, 'inherent': 4525, 'inherently': 4526, 'inheritance': 4527, 'inherits': 4528, 'inhibiting': 4529, 'initial': 4530, 'Initial': 4531, 'initialization': 4532, 'initialize': 4533, 'Initially': 4534, 'initially': 4535, 'initiatives': 4536, 'injecting': 4537, 'injection': 4538, 'Injection': 4539, 'injuries': 4540, 'injury': 4541, 'inking': 4542, 'inner': 4543, 'innovations': 4544, 'innovative': 4545, 'inopportune': 4546, 'Inpainting': 4547, 'inpainting': 4548, 'input': 4549, 'inputs': 4550, 'Inquiry': 4551, 'insecure': 4552, 'inside': 4553, 'insight': 4554, 'Insight': 4555, 'insights': 4556, 'Insolation': 4557, 'insolation': 4558, 'insolation period': 4559, 'inspecting': 4560, 'Inspection': 4561, 'inspection': 4562, 'inspired': 4563, 'Inspired': 4564, 'Instagram': 4565, 'installation': 4566, 'installations': 4567, 'installed': 4568, 'Instance': 4569, 'instance': 4570, 'instance selection': 4571, 'instance weighting': 4572, 'Instances': 4573, 'instances': 4574, 'instant': 4575, 'Instant': 4576, 'instant message': 4577, 'instantaneous': 4578, 'Instantaneous': 4579, 'instants': 4580, 'Instead': 4581, 'instead': 4582, 'institution': 4583, 'institutional': 4584, 'institutions': 4585, 'instructors': 4586, 'instrument': 4587, 'instrumental': 4588, 'instruments': 4589, 'insufficiency': 4590, 'insufficient': 4591, 'insurance': 4592, 'integer': 4593, 'integral': 4594, 'integrate': 4595, 'integrated': 4596, 'Integrated': 4597, 'integrated circuits': 4598, 'integrates': 4599, 'integrating': 4600, 'Integrating': 4601, 'Integration': 4602, 'integration': 4603, 'integration of new classes on-the-fly': 4604, 'Integrative': 4605, 'integrative complexity': 4606, 'integrity': 4607, 'Intel': 4608, 'intellectual': 4609, 'intelligence': 4610, 'Intelligence': 4611, 'intelligent': 4612, 'Intelligent': 4613, 'intelligent agent': 4614, 'intelligent systems': 4615, 'intelligent tutoring systems': 4616, 'intelligibility': 4617, 'intend': 4618, 'intended': 4619, 'intensity': 4620, 'Intensive': 4621, 'intensive': 4622, 'intensive care units': 4623, 'intensively': 4624, 'intention': 4625, 'intentional': 4626, 'inter': 4627, 'interact': 4628, 'interacting': 4629, 'interaction': 4630, 'Interaction': 4631, 'interactions': 4632, 'Interactive': 4633, 'interactive': 4634, 'interactive evolutionary computation': 4635, 'interactive systems': 4636, 'interdisciplinary': 4637, 'interest': 4638, 'interested': 4639, 'interesting': 4640, 'Interestingly': 4641, 'interests': 4642, 'Interface': 4643, 'interface': 4644, 'interfaces': 4645, 'intermediate': 4646, 'intermittent': 4647, 'internal': 4648, 'internally': 4649, 'International': 4650, 'international': 4651, 'Internet': 4652, 'internet of things': 4653, 'interpolates': 4654, 'interpolation': 4655, 'interpret': 4656, 'interpretability': 4657, 'interpretable': 4658, 'Interpretable': 4659, 'interpretable machine learning': 4660, 'interpretable modeling': 4661, 'Interpretation': 4662, 'interpretation': 4663, 'interpreted': 4664, 'interrelation': 4665, 'interrogation': 4666, 'interrupt': 4667, 'interrupted': 4668, 'interruption': 4669, 'intersect': 4670, 'intersection': 4671, 'Intersections': 4672, 'Interval': 4673, 'interval': 4674, 'interval-radial algorithm': 4675, 'intervals': 4676, 'intervention': 4677, 'intervention systems': 4678, 'interventions': 4679, 'into': 4680, 'intra': 4681, 'Intracellular': 4682, 'intractable': 4683, 'intricacies': 4684, 'intriguing': 4685, 'intrinsic': 4686, 'introduce': 4687, 'introduced': 4688, 'introduces': 4689, 'introducing': 4690, 'Introduction': 4691, 'Intrusion': 4692, 'intrusion': 4693, 'intrusion detection': 4694, 'intrusion detection &amp; defence': 4695, 'intrusion detection system': 4696, 'intrusiondetection': 4697, 'Intrusions': 4698, 'intrusions': 4699, 'intrusive': 4700, 'intuition': 4701, 'intuitionistic': 4702, 'Intuitionistic': 4703, 'intuitionistic fuzzy stes': 4704, 'intuitions': 4705, 'intuitive': 4706, 'intuitively': 4707, 'invades': 4708, 'invalid': 4709, 'invariance': 4710, 'Invariant': 4711, 'invariant': 4712, 'invariants': 4713, 'invasive': 4714, 'Invasive': 4715, 'invention': 4716, 'inverse': 4717, 'Inverse': 4718, 'inverse gaussian regression': 4719, 'inverse reinforcement learning': 4720, 'inverse-inference': 4721, 'inversion': 4722, 'Inversion': 4723, 'inverted': 4724, 'Inverted': 4725, 'inverted dirichlet': 4726, 'invested': 4727, 'investigate': 4728, 'Investigate': 4729, 'investigated': 4730, 'investigates': 4731, 'Investigating': 4732, 'investigation': 4733, 'Investigation': 4734, 'investigators': 4735, 'investment': 4736, 'investors': 4737, 'involve': 4738, 'involved': 4739, 'involves': 4740, 'involving': 4741, 'ionosphere': 4742, 'iot': 4743, 'IoT': 4744, 'IP': 4745, 'ip networks': 4746, 'IPC': 4747, 'IR': 4748, 'iris': 4749, 'IRL': 4750, 'IRMA': 4751, 'Iron': 4752, 'iron': 4753, 'irradiance': 4754, 'Irradiance': 4755, 'irradiation': 4756, 'irregular': 4757, 'irregularities': 4758, 'irrelevant': 4759, 'irritation': 4760, 'IRS': 4761, 'is': 4762, 'Is': 4763, 'isbsg': 4764, 'island': 4765, 'isolate': 4766, 'isolates': 4767, 'isolating': 4768, 'isolation': 4769, 'Isolation': 4770, 'issue': 4771, 'issues': 4772, 'Istanbul': 4773, 'It': 4774, 'it': 4775, 'IT': 4776, 'item': 4777, 'item popularity': 4778, 'items': 4779, 'itemset': 4780, 'itemsets': 4781, 'iterated': 4782, 'iteration': 4783, 'iterations': 4784, 'Iterative': 4785, 'iterative': 4786, 'iterative methods': 4787, 'iteratively': 4788, 'Iteratively': 4789, 'its': 4790, 'Its': 4791, 'ITS': 4792, 'itself': 4793, 'iv': 4794, 'J48': 4795, 'Jackknife': 4796, 'Jacobian': 4797, 'January': 4798, 'Japan': 4799, 'Java': 4800, 'Jensen': 4801, 'jensen-shannon divergence': 4802, 'job': 4803, 'job recommendation email system': 4804, 'Joint': 4805, 'joint': 4806, 'joint inference': 4807, 'jointly': 4808, 'joints': 4809, 'jpeg': 4810, 'JPEG': 4811, 'judging': 4812, 'July': 4813, 'jumps': 4814, 'just': 4815, 'justifiable': 4816, 'justification': 4817, 'K': 4818, 'k': 4819, 'k-means': 4820, 'k-means clustering': 4821, 'k-medoids': 4822, 'k-nearest neighbor': 4823, 'k-nearest neighbor classifier (knn)': 4824, 'k-nn': 4825, 'Kaiser': 4826, 'kaiser-meyer-olkin': 4827, 'Kalman': 4828, 'Kantorovich': 4829, 'kappa': 4830, 'KBP': 4831, 'kd': 4832, 'kd-trees': 4833, 'KDDCUP': 4834, 'keep': 4835, 'keeping': 4836, 'KEGG': 4837, 'kegg signalling pathways': 4838, 'Kernel': 4839, 'kernel': 4840, 'kernel function': 4841, 'kernel functions': 4842, 'kernel k-means': 4843, 'kernel method': 4844, 'kernel methods': 4845, 'kernel online learning': 4846, 'kernel ridge regression': 4847, 'Kernels': 4848, 'kernels': 4849, 'Kessel': 4850, 'key': 4851, 'Keystroke': 4852, 'keystroke': 4853, 'keystroke dynamics': 4854, 'keystroke feature': 4855, 'keystrokes': 4856, 'Keyword': 4857, 'keyword': 4858, 'keyword spotting': 4859, 'keywords': 4860, 'KGs': 4861, 'khepera': 4862, 'KheperaIII': 4863, 'kHz': 4864, 'kicks': 4865, 'kidney': 4866, 'Kidney': 4867, 'kidney segmentation': 4868, 'kind': 4869, 'kinds': 4870, 'kinect': 4871, 'kinematic': 4872, 'kingdom': 4873, 'Kmeans': 4874, 'kmeans': 4875, 'kmeans clustering': 4876, 'knn': 4877, 'kNN': 4878, 'KNN': 4879, 'knn classification model': 4880, 'knobs': 4881, 'knocking': 4882, 'know': 4883, 'knowledge': 4884, 'Knowledge': 4885, 'knowledge base': 4886, 'knowledge discovery': 4887, 'knowledge graphs': 4888, 'knowledge topology and acquisition': 4889, 'knowledge-discovery': 4890, 'known': 4891, 'Kohonen': 4892, 'kohonen self organizing network': 4893, 'KPSS': 4894, 'KRR': 4895, 'Kullback': 4896, 'Kwiatkowski': 4897, 'L': 4898, 'L1': 4899, 'l1': 4900, 'l1 norm': 4901, 'L2': 4902, 'l2 norm': 4903, 'L2LR': 4904, 'lab': 4905, 'label': 4906, 'Label': 4907, 'label noise': 4908, 'label propagation': 4909, 'Labeled': 4910, 'labeled': 4911, 'labelers': 4912, 'labeling': 4913, 'Labeling': 4914, 'labelled': 4915, 'Labelled': 4916, 'labellers': 4917, 'Labelling': 4918, 'labelling': 4919, 'Labels': 4920, 'labels': 4921, 'laboratory': 4922, 'Laboratory': 4923, 'laborious': 4924, 'LabVIEW': 4925, 'lack': 4926, 'lacked': 4927, 'lacking': 4928, 'lacks': 4929, 'LaCova': 4930, 'LAD': 4931, 'Lanczos': 4932, 'land': 4933, 'landscapes': 4934, 'language': 4935, 'Language': 4936, 'language modeling': 4937, 'Languages': 4938, 'languages': 4939, 'Laplacian': 4940, 'LapSVM': 4941, 'Large': 4942, 'large': 4943, 'large data': 4944, 'large scale': 4945, 'large scale network flow': 4946, 'largely': 4947, 'larger': 4948, 'largest': 4949, 'Lasso': 4950, 'LASSO': 4951, 'lasso': 4952, 'lasso regression': 4953, 'last': 4954, 'late': 4955, 'Latencies': 4956, 'latency': 4957, 'Latent': 4958, 'latent': 4959, 'latent dirichlet allocation': 4960, 'latent semantic indexing': 4961, 'later': 4962, 'lateral': 4963, 'lateral movement': 4964, 'latest': 4965, 'latter': 4966, 'layer': 4967, 'Layer': 4968, 'layered': 4969, 'Layered': 4970, 'layered learning': 4971, 'layering': 4972, 'layers': 4973, 'lays': 4974, 'LBP': 4975, 'LBPs': 4976, 'lcm': 4977, 'lda': 4978, 'LDA': 4979, 'lead': 4980, 'leader': 4981, 'leading': 4982, 'Leading': 4983, 'leads': 4984, 'Leaf': 4985, 'leaf': 4986, 'Leap': 4987, 'leap': 4988, 'Learn': 4989, 'learn': 4990, 'learned': 4991, 'Learned': 4992, 'learner': 4993, 'Learner': 4994, 'Learners': 4995, 'learners': 4996, 'learning': 4997, 'Learning': 4998, 'learning (artificial intelligence)': 4999, 'learning classifier systems': 5000, 'learning convex function': 5001, 'learning from interpretation transition': 5002, 'learning systems': 5003, 'learns': 5004, 'learnt': 5005, 'Least': 5006, 'least': 5007, 'least absolute shrinkage and selection operator (lasso)': 5008, 'leave': 5009, 'leaving': 5010, 'Lecture': 5011, 'lecture': 5012, 'Lectures': 5013, 'led': 5014, 'LED': 5015, 'ledger': 5016, 'LEDs': 5017, 'left': 5018, 'leg': 5019, 'legged locomotion': 5020, 'Legitimate': 5021, 'legitimate': 5022, 'Leibler': 5023, 'leightweight': 5024, 'lenders': 5025, 'lending': 5026, 'length': 5027, 'Length': 5028, 'lengths': 5029, 'lengthy': 5030, 'lens': 5031, 'Lesion': 5032, 'lesions': 5033, 'less': 5034, 'Less': 5035, 'lessened': 5036, 'let': 5037, 'lets': 5038, 'Levee': 5039, 'Levees': 5040, 'Level': 5041, 'level': 5042, 'level-k thinking': 5043, 'Levels': 5044, 'levels': 5045, 'leverage': 5046, 'leverages': 5047, 'leveraging': 5048, 'Leveraging': 5049, 'lexical': 5050, 'Lexical': 5051, 'lexicon': 5052, 'LFU': 5053, 'Li': 5054, 'library': 5055, 'Library': 5056, 'LibriSpeech': 5057, 'libs': 5058, 'License': 5059, 'license': 5060, 'license plate recognition system': 5061, 'Lie': 5062, 'lie': 5063, 'lies': 5064, 'Life': 5065, 'life': 5066, 'lifelong': 5067, 'lifelong machine learning': 5068, 'lifestyle': 5069, 'lifetime': 5070, 'light': 5071, 'lighting': 5072, 'lightning': 5073, 'lightweight': 5074, 'like': 5075, 'Like': 5076, 'likelihood': 5077, 'likely': 5078, 'limit': 5079, 'limitation': 5080, 'Limitation': 5081, 'limitations': 5082, 'limited': 5083, 'Limited': 5084, 'limiting': 5085, 'limits': 5086, 'Line': 5087, 'line': 5088, 'Linear': 5089, 'linear': 5090, 'linear programming': 5091, 'linear regression': 5092, 'linearly': 5093, 'lines': 5094, 'Lingual': 5095, 'linguistic': 5096, 'Linguistic': 5097, 'linguistic features': 5098, 'link': 5099, 'Link': 5100, 'link prediction': 5101, 'Linkage': 5102, 'linkage': 5103, 'linked': 5104, 'Linking': 5105, 'linking': 5106, 'links': 5107, 'LIP': 5108, 'list': 5109, 'Listing': 5110, 'lists': 5111, 'literature': 5112, 'literatures': 5113, 'little': 5114, 'Little': 5115, 'Live': 5116, 'live': 5117, 'liver': 5118, 'Liver': 5119, 'liver segmentation': 5120, 'Liverpool': 5121, 'lives': 5122, 'Living': 5123, 'living': 5124, 'LIWC': 5125, 'load': 5126, 'Load': 5127, 'loading': 5128, 'loads': 5129, 'Local': 5130, 'local': 5131, 'local binary patterns': 5132, 'locality': 5133, 'Localization': 5134, 'localization': 5135, 'localizations': 5136, 'localize': 5137, 'Localized': 5138, 'localized': 5139, 'Localizing': 5140, 'locally': 5141, 'located': 5142, 'location': 5143, 'locations': 5144, 'locomotion': 5145, 'log': 5146, 'Logic': 5147, 'logic': 5148, 'logical': 5149, 'login': 5150, 'Logistic': 5151, 'logistic': 5152, 'logistic regression': 5153, 'logistics': 5154, 'logits': 5155, 'logs': 5156, 'logsigmoid function': 5157, 'long': 5158, 'Long': 5159, 'long short-term memory': 5160, 'long-short term memory': 5161, 'longer': 5162, 'Longitudinal': 5163, 'longitudinal': 5164, 'longitudinal data': 5165, 'LOOCV': 5166, 'look': 5167, 'looking': 5168, 'Looking': 5169, 'lookup': 5170, 'loop': 5171, 'Loop': 5172, 'loops': 5173, 'loosely': 5174, 'Los': 5175, 'losing': 5176, 'Loss': 5177, 'loss': 5178, 'loss minimization': 5179, 'losses': 5180, 'lost': 5181, 'lot': 5182, 'lots': 5183, 'loudness': 5184, 'Low': 5185, 'low': 5186, 'low-rank approximation': 5187, 'lower': 5188, 'lowered': 5189, 'Lowering': 5190, 'lowest': 5191, 'lows': 5192, 'Lp': 5193, 'LP': 5194, 'lp-norm estimators': 5195, 'LPCA': 5196, 'LPDS': 5197, 'LPRS': 5198, 'LR': 5199, 'LRU': 5200, 'LSB': 5201, 'LSBs': 5202, 'LSH': 5203, 'LSI': 5204, 'LSTM': 5205, 'Luckily': 5206, 'Lung': 5207, 'lung': 5208, 'lung cancer': 5209, 'lying': 5210, 'Lyrics': 5211, 'lyrics': 5212, 'm': 5213, 'M': 5214, 'm3': 5215, 'MA': 5216, 'Machine': 5217, 'machine': 5218, 'machine learning': 5219, 'machine learning algorithm (mla)': 5220, 'machine learning algorithms': 5221, 'machine learning application': 5222, 'machine learning as a service': 5223, 'machine learning techniques': 5224, 'machine-learning': 5225, 'machine-sourced': 5226, 'Machines': 5227, 'machines': 5228, 'Macro': 5229, 'made': 5230, 'Madhya': 5231, 'MAE': 5232, 'magnetic': 5233, 'Magnetic': 5234, 'magnetic field': 5235, 'magnitude': 5236, 'Mahalanobis': 5237, 'mail': 5238, 'main': 5239, 'Main': 5240, 'mainly': 5241, 'mainstream': 5242, 'maintain': 5243, 'maintainability': 5244, 'Maintained': 5245, 'maintained': 5246, 'maintaining': 5247, 'maintenance': 5248, 'Major': 5249, 'major': 5250, 'majority': 5251, 'Majority': 5252, 'majority vote rule': 5253, 'Make': 5254, 'make': 5255, 'maker': 5256, 'makers': 5257, 'makes': 5258, 'Making': 5259, 'making': 5260, 'male': 5261, 'males': 5262, 'Malicious': 5263, 'malicious': 5264, 'Malware': 5265, 'malware': 5266, 'malware classification': 5267, 'malwares': 5268, 'manage': 5269, 'manageable': 5270, 'management': 5271, 'Management': 5272, 'manages': 5273, 'managing': 5274, 'manifest': 5275, 'Manifestations': 5276, 'Manifold': 5277, 'manifold': 5278, 'manifold learning': 5279, 'manifold learning regression': 5280, 'Manifolds': 5281, 'manifolds': 5282, 'manipulated': 5283, 'manipulation': 5284, 'Manipulators': 5285, 'manner': 5286, 'manual': 5287, 'manually': 5288, 'Manually': 5289, 'manufacturers': 5290, 'manufacturing': 5291, 'Manufacturing': 5292, 'Many': 5293, 'many': 5294, 'Map': 5295, 'map': 5296, 'MAP': 5297, 'MAPE': 5298, 'MAPK': 5299, 'Maple': 5300, 'maple': 5301, 'mapped': 5302, 'Mapping': 5303, 'mapping': 5304, 'MapReduce': 5305, 'mapreduce': 5306, 'maps': 5307, 'Maps': 5308, 'MAR': 5309, 'margin': 5310, 'Margin': 5311, 'marginal': 5312, 'margins': 5313, 'mark': 5314, 'marker': 5315, 'markers': 5316, 'Market': 5317, 'market': 5318, 'marketing': 5319, 'Markets': 5320, 'markets': 5321, 'Markov': 5322, 'markov decision process': 5323, 'markov decision processes': 5324, 'markov logic networks': 5325, 'markov network': 5326, 'markov switching model': 5327, 'markov(k)': 5328, 'Markovian': 5329, 'Maryland': 5330, 'MAS': 5331, 'mashup': 5332, 'Mashups': 5333, 'mashups': 5334, 'mask': 5335, 'Mask': 5336, 'Masked': 5337, 'masked conditional neural networks': 5338, 'masking': 5339, 'masks': 5340, 'mass': 5341, 'mass deaths': 5342, 'mass transfer': 5343, 'massive': 5344, 'Master': 5345, 'master': 5346, 'master degree in information technology': 5347, 'match': 5348, 'matched': 5349, 'matches': 5350, 'Matching': 5351, 'matching': 5352, 'Matchingtching': 5353, 'material': 5354, 'Mathematica': 5355, 'mathematica': 5356, 'mathematical': 5357, 'mathematical model': 5358, 'mathematically': 5359, 'MATLAB': 5360, 'matrices': 5361, 'matrix': 5362, 'Matrix': 5363, 'matrix decomposition': 5364, 'matter': 5365, 'Matthews': 5366, 'mattress': 5367, 'Mattress': 5368, 'maturation': 5369, 'matures': 5370, 'max': 5371, 'Max': 5372, 'max-min distance algorithm': 5373, 'maxima': 5374, 'maximal': 5375, 'Maximising': 5376, 'Maximization': 5377, 'maximization': 5378, 'maximize': 5379, 'maximizes': 5380, 'Maximizing': 5381, 'Maximum': 5382, 'maximum': 5383, 'maximum a posteriori': 5384, 'maximum likelihood estimation': 5385, 'maximum-power-point-tracker': 5386, 'may': 5387, 'maze': 5388, 'mc': 5389, 'MClassification': 5390, 'MCLNN': 5391, 'mclnn': 5392, 'MCS': 5393, 'MDLClass': 5394, 'MDP': 5395, 'Mead': 5396, 'meal': 5397, 'mean': 5398, 'Mean': 5399, 'meaning': 5400, 'Meaning': 5401, 'meaningful': 5402, 'meaningfully': 5403, 'meaningless': 5404, 'means': 5405, 'Means': 5406, 'Measure': 5407, 'measure': 5408, 'measured': 5409, 'Measurement': 5410, 'measurement': 5411, 'Measurements': 5412, 'measurements': 5413, 'Measures': 5414, 'measures': 5415, 'measuring': 5416, 'Measuring': 5417, 'mechanism': 5418, 'mechanisms': 5419, 'Media': 5420, 'media': 5421, 'medical': 5422, 'Medical': 5423, 'medical image analysis': 5424, 'medical informatics': 5425, 'Medicare': 5426, 'medicine': 5427, 'medium': 5428, 'Medoids': 5429, 'medoids': 5430, 'MEE': 5431, 'meet': 5432, 'meets': 5433, 'Mel': 5434, 'Mellon': 5435, 'membership': 5436, 'memoRy': 5437, 'memory': 5438, 'Memory': 5439, 'men': 5440, 'mental': 5441, 'mention': 5442, 'mentionpair': 5443, 'mentions': 5444, 'merely': 5445, 'merge': 5446, 'merging': 5447, 'merits': 5448, 'Message': 5449, 'message': 5450, 'messages': 5451, 'Messages': 5452, 'messaging': 5453, 'Meta': 5454, 'meta': 5455, 'meta-algorithms': 5456, 'meta-heuristic prediction algorithm': 5457, 'meta-recommendation system': 5458, 'Metabolic': 5459, 'metabolic': 5460, 'metabolites': 5461, 'metabolomics': 5462, 'metadata': 5463, 'metaheuristic': 5464, 'Metaheuristic': 5465, 'metaheuristics': 5466, 'metal': 5467, 'metasoundex': 5468, 'MetaSoundex': 5469, 'meteorological': 5470, 'meteorology': 5471, 'Meter': 5472, 'metering': 5473, 'meters': 5474, 'Method': 5475, 'method': 5476, 'methodically': 5477, 'Methodological': 5478, 'methodological': 5479, 'methodologies': 5480, 'methodology': 5481, 'Methods': 5482, 'methods': 5483, 'Metric': 5484, 'metric': 5485, 'metric learning': 5486, 'metrics': 5487, 'Metrics': 5488, 'Metro': 5489, 'Meyer': 5490, 'MFCC': 5491, 'MFCCs': 5492, 'mfccs': 5493, 'MH': 5494, 'MHAD': 5495, 'mHealth': 5496, 'mhealth': 5497, 'MI': 5498, 'MIAMI': 5499, 'Michigan': 5500, 'Micro': 5501, 'micro': 5502, 'Microalgae': 5503, 'microalgae': 5504, 'microalgae classification': 5505, 'microblogging': 5506, 'microcytic': 5507, 'Microscope': 5508, 'microscopic': 5509, 'microseconds': 5510, 'Microsoft': 5511, 'microstructure': 5512, 'Microtubule': 5513, 'microtubules': 5514, 'mid': 5515, 'Mid': 5516, 'might': 5517, 'MIL': 5518, 'mild': 5519, 'military': 5520, 'million': 5521, 'Millions': 5522, 'millions': 5523, 'millisecond': 5524, 'milliseconds': 5525, 'mimicked': 5526, 'mimicking': 5527, 'mimics': 5528, 'min': 5529, 'Min': 5530, 'mind': 5531, 'mine': 5532, 'mined': 5533, 'Minimal': 5534, 'minimal': 5535, 'minimally': 5536, 'Minimally': 5537, 'Minimization': 5538, 'minimization': 5539, 'minimize': 5540, 'minimizes': 5541, 'Minimizing': 5542, 'minimizing': 5543, 'minimum': 5544, 'Minimum': 5545, 'minimum description length': 5546, 'mininet': 5547, 'mining': 5548, 'Mining': 5549, 'mining big data': 5550, 'Minneapolis': 5551, 'minor': 5552, 'minority': 5553, 'minute': 5554, 'minutes': 5555, 'minutia code': 5556, 'Minutiae': 5557, 'minutiae': 5558, 'mirrors': 5559, 'MIRS': 5560, 'misclassification': 5561, 'Mises': 5562, 'mislabeled': 5563, 'mislabeled data': 5564, 'misled': 5565, 'mismatch': 5566, 'misses': 5567, 'Missing': 5568, 'missing': 5569, 'missing at random': 5570, 'missing data': 5571, 'mission': 5572, 'mistakes': 5573, 'MIT': 5574, 'mitigate': 5575, 'Mitigate': 5576, 'mitigates': 5577, 'Mitigating': 5578, 'mitigating': 5579, 'Mitigation': 5580, 'mitigation': 5581, 'mixed': 5582, 'Mixed': 5583, 'mixed data': 5584, 'mixing': 5585, 'mixture': 5586, 'Mixture': 5587, 'mixture model': 5588, 'mixture models': 5589, 'mixture of experts': 5590, 'mixtures': 5591, 'Mixtures': 5592, 'MKRL': 5593, 'ML': 5594, 'MLA': 5595, 'MLaaS': 5596, 'mlp': 5597, 'MLP': 5598, 'MLPs': 5599, 'MLR': 5600, 'MLS': 5601, 'mm': 5602, 'MMSE': 5603, 'MN': 5604, 'MNIST': 5605, 'mnist': 5606, 'mnist variations': 5607, 'Mobile': 5608, 'mobile': 5609, 'mobile computing': 5610, 'mobile robot self-localization': 5611, 'mobile robots': 5612, 'mobile security': 5613, 'mobile store security': 5614, 'Mobility': 5615, 'mobility': 5616, 'Mocap': 5617, 'MOCAP': 5618, 'modal': 5619, 'modalities': 5620, 'modality': 5621, 'mode': 5622, 'Model': 5623, 'model': 5624, 'model building': 5625, 'model calibration': 5626, 'model checking': 5627, 'model post processing': 5628, 'model transformatiomn': 5629, 'modeled': 5630, 'Modeling': 5631, 'modeling': 5632, 'modelled': 5633, 'Modelling': 5634, 'modelling': 5635, 'models': 5636, 'Models': 5637, 'moderate': 5638, 'moderation': 5639, 'modern': 5640, 'Modern': 5641, 'modest': 5642, 'modification': 5643, 'Modification': 5644, 'modifications': 5645, 'modified': 5646, 'Modified': 5647, 'modify': 5648, 'modifying': 5649, 'Modular': 5650, 'modular': 5651, 'modulated': 5652, 'modulation': 5653, 'module': 5654, 'MOEAs': 5655, 'molecular': 5656, 'Molecular': 5657, 'molecules': 5658, 'moment': 5659, 'momentary': 5660, 'moments': 5661, 'Monge': 5662, 'monitor': 5663, 'monitored': 5664, 'monitoring': 5665, 'Monitoring': 5666, 'monitors': 5667, 'monolithic': 5668, 'monotonically': 5669, 'Monte': 5670, 'monte carlo': 5671, 'monte carlo methods': 5672, 'month': 5673, 'monthly': 5674, 'Monthly': 5675, 'months': 5676, 'mood': 5677, 'More': 5678, 'more': 5679, 'Moreover': 5680, 'morphological': 5681, 'Morphologically': 5682, 'morphologically': 5683, 'morphology': 5684, 'mortality': 5685, 'Mortality': 5686, 'mortality rate prediction': 5687, 'mortgage': 5688, 'Moscow': 5689, 'Most': 5690, 'most': 5691, 'mostly': 5692, 'motif': 5693, 'Motifs': 5694, 'motifs': 5695, 'Motion': 5696, 'motion': 5697, 'motion capture (mocap)': 5698, 'motion-based multiple object tracking': 5699, 'Motions': 5700, 'motions': 5701, 'Motivated': 5702, 'motivated': 5703, 'motivation': 5704, 'motor': 5705, 'Motor': 5706, 'Motors': 5707, 'motors': 5708, 'mouse': 5709, 'Mouse': 5710, 'move': 5711, 'Movement': 5712, 'movement': 5713, 'movements': 5714, 'moves': 5715, 'movie': 5716, 'Movie': 5717, 'MovieLens': 5718, 'movies': 5719, 'moving': 5720, 'Moving': 5721, 'moving target defense': 5722, 'MR': 5723, 'mr images': 5724, 'mRMR': 5725, 'mrmr': 5726, 'ms': 5727, 'MSA': 5728, 'MSE': 5729, 'MT': 5730, 'MTs': 5731, 'Much': 5732, 'much': 5733, 'MUE': 5734, 'multi': 5735, 'Multi': 5736, 'multi agent systems': 5737, 'multi instance classification': 5738, 'multi-armed bandit': 5739, 'multi-armed bandits': 5740, 'multi-corpora': 5741, 'multi-density clustering': 5742, 'multi-label classification': 5743, 'multi-label classifiers': 5744, 'multi-label learning': 5745, 'multi-linear regression model': 5746, 'multi-objective evolutionary algorithm': 5747, 'multi-objective particle swarm optimization': 5748, 'multi-objective reinforcement learning': 5749, 'multi-objectivization': 5750, 'multi-period prediction': 5751, 'multi-scale': 5752, 'multi-strategy learning': 5753, 'multi-task learning': 5754, 'multi-valued models': 5755, 'multiclass': 5756, 'Multiclass': 5757, 'multiclass classification': 5758, 'multidimensional': 5759, 'Multidimensional': 5760, 'multidisciplinary': 5761, 'Multifaceted': 5762, 'multifaceted': 5763, 'Multilabel': 5764, 'multilayer': 5765, 'multilayer feedforward neural network': 5766, 'multilayer network': 5767, 'multilingual': 5768, 'Multimedia': 5769, 'multimedia': 5770, 'multimedia signal processing': 5771, 'multimedia structure analysis': 5772, 'Multimodal': 5773, 'multimodal': 5774, 'multinomial': 5775, 'Multinomial': 5776, 'multiobjectivization': 5777, 'Multipath': 5778, 'Multiplayer': 5779, 'Multiple': 5780, 'multiple': 5781, 'multiple classifier systems': 5782, 'multiple instance learning': 5783, 'multiple kernel learning': 5784, 'multiple object tracking': 5785, 'Multipliers': 5786, 'Multistep': 5787, 'multistep': 5788, 'multitude': 5789, 'multivariate': 5790, 'Multivariate': 5791, 'multivariate analyses': 5792, 'multiview': 5793, 'Multiview': 5794, 'multiview data': 5795, 'muscle': 5796, 'music': 5797, 'Music': 5798, 'music event': 5799, 'musical': 5800, 'Musical': 5801, 'Musicologists': 5802, 'must': 5803, 'mutation': 5804, 'Mutual': 5805, 'mutual': 5806, 'mutual information': 5807, 'my': 5808, 'myriad': 5809, 'n': 5810, 'N': 5811, 'na': 5812, 'Na': 5813, 'NAB': 5814, 'Nai': 5815, 'Naive': 5816, 'naive': 5817, 'naive bayes': 5818, 'naive bayes classifier': 5819, 'name': 5820, 'named': 5821, 'Named': 5822, 'named entity recognition': 5823, 'namely': 5824, 'names': 5825, 'nanoseconds': 5826, 'Nari': 5827, 'narrative': 5828, 'narrowed': 5829, 'narx': 5830, 'NARX': 5831, 'narx neural network': 5832, 'NASA': 5833, 'NASDAQ': 5834, 'National': 5835, 'national': 5836, 'natural': 5837, 'Natural': 5838, 'natural language processing': 5839, 'Nature': 5840, 'nature': 5841, 'navigate': 5842, 'navigation': 5843, 'Nazarbayev': 5844, 'NB': 5845, 'NCEP': 5846, 'NDK': 5847, 'NDmin': 5848, 'ndt': 5849, 'near': 5850, 'near infrared': 5851, 'nearby': 5852, 'Nearest': 5853, 'nearest': 5854, 'nearest neighbor': 5855, 'nearest neighbor search': 5856, 'nearly': 5857, 'necessarily': 5858, 'Necessary': 5859, 'necessary': 5860, 'necessitates': 5861, 'necessitating': 5862, 'necessity': 5863, 'need': 5864, 'needed': 5865, 'needing': 5866, 'needs': 5867, 'negate': 5868, 'negative': 5869, 'Negative': 5870, 'negative images': 5871, 'negativity': 5872, 'neglect': 5873, 'neglected': 5874, 'Neighbor': 5875, 'neighbor': 5876, 'Neighborhood': 5877, 'neighborhood': 5878, 'neighborhoods': 5879, 'Neighbors': 5880, 'neighbors': 5881, 'Neighbour': 5882, 'neither': 5883, 'Nelder': 5884, 'nelder-mead algorithm (nma)': 5885, 'neoadjuvant': 5886, 'NER': 5887, 'nested': 5888, 'Nested': 5889, 'net': 5890, 'Netflow': 5891, 'Netflows': 5892, 'Nets': 5893, 'Network': 5894, 'network': 5895, 'network attacks': 5896, 'network communities': 5897, 'network data': 5898, 'network inference': 5899, 'network intrusion detection system (nids)': 5900, 'network layer': 5901, 'network representation learning': 5902, 'network topology': 5903, 'Networked': 5904, 'networked control system': 5905, 'networking': 5906, 'Networking': 5907, 'Networks': 5908, 'networks': 5909, 'Neural': 5910, 'neural': 5911, 'neural network': 5912, 'neural network based machine learning': 5913, 'neural network classifier': 5914, 'neural networks': 5915, 'Neuro': 5916, 'neuro': 5917, 'neurobiology': 5918, 'neurocrfs': 5919, 'neuroevolution': 5920, 'neurofuzzy': 5921, 'Neurofuzzy': 5922, 'neurofuzzy system': 5923, 'Neuroimaging': 5924, 'neurologic': 5925, 'neurological': 5926, 'neurology': 5927, 'neuron': 5928, 'neuronal': 5929, 'neurons': 5930, 'neurophysiological': 5931, 'neuroscience': 5932, 'neutralizes': 5933, 'never': 5934, 'Nevertheless': 5935, 'new': 5936, 'New': 5937, 'new event types': 5938, 'newly': 5939, 'news': 5940, 'News': 5941, 'newsagents': 5942, 'NewsCubeSum': 5943, 'newsgroup': 5944, 'newswire': 5945, 'newsworthy': 5946, 'Newtons': 5947, 'next': 5948, 'Next': 5949, 'next generation sequence (ngs)': 5950, 'next generation wireless networks': 5951, 'NGS': 5952, 'nice': 5953, 'nicely': 5954, 'NIDS': 5955, 'night': 5956, 'NiN': 5957, 'nir': 5958, 'NIR': 5959, 'NK': 5960, 'NlogN': 5961, 'nlp': 5962, 'NLP': 5963, 'NMA': 5964, 'NMAE': 5965, 'NMF': 5966, 'NMR': 5967, 'NN': 5968, 'nn-based fault detection algorith': 5969, 'NNBHMS': 5970, 'no': 5971, 'NOAA': 5972, 'node': 5973, 'Node': 5974, 'node similarities': 5975, 'nodes': 5976, 'nodules': 5977, 'Nodules': 5978, 'noise': 5979, 'Noise': 5980, 'noise estimation': 5981, 'noise reduction': 5982, 'noised': 5983, 'noises': 5984, 'Noisy': 5985, 'noisy': 5986, 'noisy data': 5987, 'noisy training data': 5988, 'Non': 5989, 'non': 5990, 'non intrusive load monitoring': 5991, 'non negative matrix factorization': 5992, 'non stationary time-series': 5993, 'non-linearity': 5994, 'non-personalized single heuristic strategies': 5995, 'non-stationary': 5996, 'Noncooperative': 5997, 'noncustodial': 5998, 'none': 5999, 'Nonetheless': 6000, 'nonholonomic': 6001, 'nonintrusive': 6002, 'nonlinear': 6003, 'Nonlinear': 6004, 'nonlinear dynamics': 6005, 'nonlinearity': 6006, 'nonnegative': 6007, 'Nonnegative': 6008, 'nonnegative matrix factorization': 6009, 'Nonparametric': 6010, 'nonparametric': 6011, 'nonparametric bayesian': 6012, 'Nonstationarity': 6013, 'nonstationarity': 6014, 'nonstationary processes': 6015, 'nonsurgical': 6016, 'Nontechnical': 6017, 'nontechnical': 6018, 'nontechnical loss': 6019, 'nonword': 6020, 'Nonword': 6021, 'nonword stimuli repetition': 6022, 'nonwords': 6023, 'nor': 6024, 'Norm': 6025, 'norm': 6026, 'normal': 6027, 'Normal': 6028, 'normality': 6029, 'Normality': 6030, 'normalization': 6031, 'normalized': 6032, 'normally': 6033, 'North': 6034, 'not': 6035, 'Not': 6036, 'notably': 6037, 'Notably': 6038, 'note': 6039, 'noted': 6040, 'noticeably': 6041, 'notification': 6042, 'notifications': 6043, 'notion': 6044, 'notions': 6045, 'Nottingham': 6046, 'Novel': 6047, 'novel': 6048, 'Novelty': 6049, 'novelty': 6050, 'novelty search': 6051, 'Now': 6052, 'now': 6053, 'Nowadays': 6054, 'nowadays': 6055, 'NP': 6056, 'NPI': 6057, 'NTL': 6058, 'Nuclear': 6059, 'nuclear': 6060, 'nuclear magnetic resonance': 6061, 'Number': 6062, 'number': 6063, 'number of clusters in a dataset': 6064, 'numbers': 6065, 'Numenta': 6066, 'numerical': 6067, 'numerical models': 6068, 'numerical simulation': 6069, 'numerically': 6070, 'Numerous': 6071, 'numerous': 6072, 'Nutrition': 6073, 'nutrition': 6074, 'NVIDIA': 6075, 'NWR': 6076, 'nyi': 6077, 'o': 6078, 'O': 6079, 'Oahu': 6080, 'obesity': 6081, 'object': 6082, 'Object': 6083, 'object oriented software': 6084, 'object recognition': 6085, 'object tracking': 6086, 'objective': 6087, 'Objective': 6088, 'objective selection': 6089, 'objectively': 6090, 'Objectives': 6091, 'objectives': 6092, 'objects': 6093, 'Objects': 6094, 'oblivion': 6095, 'oblivion criterion': 6096, 'Oblivious': 6097, 'oblivious': 6098, 'oblivious routing scheme': 6099, 'obscurities': 6100, 'observation': 6101, 'observational': 6102, 'Observations': 6103, 'observations': 6104, 'observe': 6105, 'observed': 6106, 'observer': 6107, 'observing': 6108, 'obstacle': 6109, 'obstructive': 6110, 'obstructive apnea': 6111, 'obtain': 6112, 'obtained': 6113, 'Obtained': 6114, 'obtaining': 6115, 'obtains': 6116, 'obvious': 6117, 'occidental': 6118, 'occluded': 6119, 'Occluded': 6120, 'occlusion': 6121, 'occlusions': 6122, 'occupancy': 6123, 'occupants': 6124, 'occupies': 6125, 'occur': 6126, 'Occurance': 6127, 'occuring': 6128, 'occurred': 6129, 'occurrence': 6130, 'occurrences': 6131, 'occurring': 6132, 'occurs': 6133, 'Oceanic': 6134, 'oceanography': 6135, 'OCNN': 6136, 'odds': 6137, 'Of': 6138, 'of': 6139, 'off': 6140, 'offchain': 6141, 'offer': 6142, 'offered': 6143, 'offering': 6144, 'offers': 6145, 'Office': 6146, 'offline': 6147, 'Offline': 6148, 'offs': 6149, 'offset': 6150, 'often': 6151, 'Oil': 6152, 'oil': 6153, 'OK': 6154, 'OLAP': 6155, 'older': 6156, 'Olkin': 6157, 'OLP': 6158, 'OLS': 6159, 'Olympics': 6160, 'ompt': 6161, 'On': 6162, 'on': 6163, 'on-line learning': 6164, 'Once': 6165, 'once': 6166, 'One': 6167, 'one': 6168, 'one-way anova': 6169, 'OneMax': 6170, 'ones': 6171, 'Ones': 6172, 'ongoing': 6173, 'Online': 6174, 'online': 6175, 'online clustering': 6176, 'online k-means clustering': 6177, 'online learning': 6178, 'online process monitoring': 6179, 'online selection': 6180, 'ONLINESEARCHSPN': 6181, 'only': 6182, 'Only': 6183, 'onset': 6184, 'onshore': 6185, 'ontological': 6186, 'ontologies': 6187, 'ontology': 6188, 'Ontology': 6189, 'ontology learning': 6190, 'OOP': 6191, 'OP': 6192, 'Open': 6193, 'open': 6194, 'opened': 6195, 'opening': 6196, 'OpenMP': 6197, 'openmp tasks': 6198, 'opens': 6199, 'OpenSimulator': 6200, 'opensource': 6201, 'Operated': 6202, 'operates': 6203, 'operating': 6204, 'operation': 6205, 'Operational': 6206, 'operational': 6207, 'operations': 6208, 'Operator': 6209, 'operator': 6210, 'operators': 6211, 'Opinion': 6212, 'opinion': 6213, 'opinion extraction': 6214, 'opinions': 6215, 'OPP': 6216, 'opportunities': 6217, 'opportunity': 6218, 'opposed': 6219, 'opposite': 6220, 'OPS': 6221, 'Optical': 6222, 'optima': 6223, 'optimal': 6224, 'Optimal': 6225, 'optimal control': 6226, 'Optimality': 6227, 'optimality': 6228, 'optimally': 6229, 'Optimally': 6230, 'Optimisation': 6231, 'optimisation': 6232, 'optimised': 6233, 'optimizatioin': 6234, 'Optimization': 6235, 'optimization': 6236, 'optimizations': 6237, 'Optimize': 6238, 'optimize': 6239, 'Optimized': 6240, 'optimized': 6241, 'optimizer': 6242, 'optimizes': 6243, 'optimizing': 6244, 'Optimizing': 6245, 'optimum': 6246, 'Optimum': 6247, 'optimum path forest': 6248, 'optimum-path forest': 6249, 'option': 6250, 'options': 6251, 'or': 6252, 'OR': 6253, 'oracle': 6254, 'order': 6255, 'orders': 6256, 'Organ': 6257, 'organ': 6258, 'organ segmentation': 6259, 'organic computing': 6260, 'organism': 6261, 'organisms': 6262, 'organization': 6263, 'organizations': 6264, 'organized': 6265, 'Organizing': 6266, 'organizing': 6267, 'organs': 6268, 'orientation': 6269, 'Oriented': 6270, 'oriented': 6271, 'origin': 6272, 'original': 6273, 'originally': 6274, 'ORL': 6275, 'orphan': 6276, 'orphan node prediction': 6277, 'orthogonal': 6278, 'Orthogonal': 6279, 'orthogonal matching pursuit': 6280, 'orthosis': 6281, 'OSA': 6282, 'other': 6283, 'others': 6284, 'Otsu': 6285, 'OUPS': 6286, 'our': 6287, 'Our': 6288, 'Out': 6289, 'out': 6290, 'outage': 6291, 'outcome': 6292, 'Outcome': 6293, 'outcomes': 6294, 'Outcomes': 6295, 'outlets': 6296, 'Outlier': 6297, 'outlier': 6298, 'outlier detection': 6299, 'Outliers': 6300, 'outliers': 6301, 'outline': 6302, 'outpeformed': 6303, 'outperform': 6304, 'outperformed': 6305, 'outperforming': 6306, 'outperforms': 6307, 'output': 6308, 'outputs': 6309, 'outside': 6310, 'outsource': 6311, 'outsourcing': 6312, 'outstanding': 6313, 'OVCLDA': 6314, 'over': 6315, 'Over': 6316, 'over dispersion': 6317, 'overall': 6318, 'overarching': 6319, 'overcome': 6320, 'overcomes': 6321, 'overcoming': 6322, 'Overfeat': 6323, 'overfit': 6324, 'overfitting': 6325, 'Overflow': 6326, 'overhead': 6327, 'overlap': 6328, 'overlapping': 6329, 'Oversampling': 6330, 'oversampling': 6331, 'overtakes': 6332, 'overview': 6333, 'owing': 6334, 'own': 6335, 'owner': 6336, 'owners': 6337, 'ownership': 6338, 'owning': 6339, 'OY': 6340, 'p': 6341, 'P': 6342, 'PA': 6343, 'pace': 6344, 'PACF': 6345, 'packages': 6346, 'packet': 6347, 'Packet': 6348, 'paediatric': 6349, 'page': 6350, 'Page': 6351, 'pages': 6352, 'paid': 6353, 'pair': 6354, 'paired': 6355, 'pairs': 6356, 'pairwise': 6357, 'palm': 6358, 'Palynologists': 6359, 'palynology': 6360, 'panel': 6361, 'PANNET': 6362, 'paper': 6363, 'par': 6364, 'paradigm': 6365, 'paradigms': 6366, 'Parallel': 6367, 'parallel': 6368, 'parallel processing': 6369, 'parallelism': 6370, 'parallelize': 6371, 'parallelized': 6372, 'parallelized sgd': 6373, 'parallelizing': 6374, 'Parallelizing': 6375, 'parameter': 6376, 'Parameter': 6377, 'parameter control': 6378, 'parameterization': 6379, 'parameters': 6380, 'Parameters': 6381, 'parametric': 6382, 'Parametric': 6383, 'paramount': 6384, 'parent': 6385, 'parents': 6386, 'Pareto': 6387, 'Paris': 6388, 'parking': 6389, 'Parkinson': 6390, \"parkinson's disease\": 6391, 'parsimonious': 6392, 'part': 6393, 'partial': 6394, 'Partial': 6395, 'partial-autocorrelation-function-(pacf)': 6396, 'Partially': 6397, 'partially': 6398, 'participant': 6399, 'Participants': 6400, 'participants': 6401, 'participate': 6402, 'Particle': 6403, 'particle': 6404, 'particle swarm optimization': 6405, 'particular': 6406, 'Particularly': 6407, 'particularly': 6408, 'partition': 6409, 'Partition': 6410, 'partitional': 6411, 'partitional clustering': 6412, 'Partitioning': 6413, 'partitioning': 6414, 'partitioning algorithms': 6415, 'partitioning clustering': 6416, 'partitions': 6417, 'parts': 6418, 'Parts': 6419, 'parts based decompositions': 6420, 'party': 6421, 'pass': 6422, 'passed': 6423, 'passenger': 6424, 'passing': 6425, 'passive': 6426, 'Passive': 6427, 'passive seismic': 6428, 'password': 6429, 'past': 6430, 'Past': 6431, 'Pasto': 6432, 'patch': 6433, 'patched': 6434, 'Patent': 6435, 'patent': 6436, 'patents': 6437, 'path': 6438, 'Path': 6439, 'pathogens': 6440, 'pathologists': 6441, 'pathology': 6442, 'paths': 6443, 'pathway': 6444, 'Pathways': 6445, 'pathways': 6446, 'Patient': 6447, 'patient': 6448, 'Patients': 6449, 'patients': 6450, 'pattern': 6451, 'Pattern': 6452, 'pattern matching': 6453, 'pattern recognition': 6454, 'Patterns': 6455, 'patterns': 6456, 'paucity': 6457, 'pave': 6458, 'paves': 6459, 'payload': 6460, 'payments': 6461, 'PCA': 6462, 'pca': 6463, 'PCC': 6464, 'pcr': 6465, 'PCR': 6466, 'PCs': 6467, 'PDEs': 6468, 'peak': 6469, 'Pearson': 6470, 'pedagogically': 6471, 'Pedagogically': 6472, 'pedestrian': 6473, 'peer': 6474, 'PELU': 6475, 'pen': 6476, 'penalization': 6477, 'penalize': 6478, 'penalizing': 6479, 'penalty': 6480, 'pencil': 6481, 'penetration': 6482, 'people': 6483, 'per': 6484, 'Per': 6485, 'perceive': 6486, 'perceived': 6487, 'percent': 6488, 'percentage': 6489, 'Percentage': 6490, 'Perception': 6491, 'perception': 6492, 'perceptron': 6493, 'Perceptron': 6494, 'perceptrons': 6495, 'Perceptual': 6496, 'perceptual': 6497, 'perfect': 6498, 'perfection': 6499, 'perform': 6500, 'Perform': 6501, 'Performance': 6502, 'performance': 6503, 'performance evaluation': 6504, 'performances': 6505, 'Performances': 6506, 'performed': 6507, 'performing': 6508, 'performs': 6509, 'Perfusion': 6510, 'perhaps': 6511, 'perinatal': 6512, 'Period': 6513, 'period': 6514, 'periodic': 6515, 'Periodic': 6516, 'periods': 6517, 'permissions': 6518, 'permittivity': 6519, 'permutations': 6520, 'persecution': 6521, 'persistence': 6522, 'persistent': 6523, 'person': 6524, 'personal': 6525, 'personalization': 6526, 'personalize': 6527, 'Personalized': 6528, 'personalized': 6529, 'personalized item': 6530, 'personalized treatment': 6531, 'personalizes': 6532, 'personnel': 6533, 'Perspective': 6534, 'perspective': 6535, 'perspectives': 6536, 'pertaining': 6537, 'pertinent': 6538, 'perturbation': 6539, 'perturbations': 6540, 'pervasive': 6541, 'Pervasive': 6542, 'pervasively': 6543, 'Petri': 6544, 'PFA': 6545, 'PFP': 6546, 'PGI': 6547, 'PHA': 6548, 'Phase': 6549, 'phase': 6550, 'phase identification': 6551, 'phases': 6552, 'phenomena': 6553, 'phenomenal': 6554, 'phenomenon': 6555, 'Phenotype': 6556, 'phenotype prediction': 6557, 'Phenotypes': 6558, 'phenotypes': 6559, 'Philips': 6560, 'phishing': 6561, 'phone': 6562, 'phoneme': 6563, 'Phoneme': 6564, 'phoneme classification': 6565, 'phoneme prediction': 6566, 'phones': 6567, 'phonetic': 6568, 'photo': 6569, 'photovoltaic': 6570, 'Photovoltaic': 6571, 'physical': 6572, 'Physical': 6573, 'physicians': 6574, 'Physics': 6575, 'physics': 6576, 'physiological': 6577, 'Physiology': 6578, 'physiology': 6579, 'PhysioNet': 6580, 'picking': 6581, 'picks': 6582, 'PID': 6583, 'pid control': 6584, 'piece': 6585, 'pieces': 6586, 'piecewise': 6587, 'Piecewise': 6588, 'piecewise linear': 6589, 'Pilot': 6590, 'pilot': 6591, 'pink': 6592, 'pinpointing': 6593, 'pipeline': 6594, 'Pipeline': 6595, 'Pipelines': 6596, 'Pitch': 6597, 'pitch': 6598, 'pitch system': 6599, 'Pitches': 6600, 'pitfalls': 6601, 'pixel': 6602, 'pixels': 6603, 'PK': 6604, 'place': 6605, 'places': 6606, 'plain': 6607, 'plan': 6608, 'plane': 6609, 'planes': 6610, 'planktonic': 6611, 'planners': 6612, 'Planning': 6613, 'planning': 6614, 'Plant': 6615, 'plant': 6616, 'plants': 6617, 'Plasticity': 6618, 'plasticity': 6619, 'plastics': 6620, 'Plate': 6621, 'plate': 6622, 'plates': 6623, 'Platform': 6624, 'platform': 6625, 'platform as a service': 6626, 'platforms': 6627, 'platoon': 6628, 'plausibility': 6629, 'plausible': 6630, 'play': 6631, 'Play': 6632, 'played': 6633, 'player': 6634, 'players': 6635, 'playing': 6636, 'plays': 6637, 'plenty': 6638, 'plot': 6639, 'plots': 6640, 'PLSA': 6641, 'plsa': 6642, 'plug': 6643, 'pluggable': 6644, 'plugin': 6645, 'plurality': 6646, 'plus': 6647, 'Plus': 6648, 'PN': 6649, 'POA': 6650, 'Point': 6651, 'point': 6652, 'points': 6653, 'Points': 6654, 'policies': 6655, 'Policies': 6656, 'Policing': 6657, 'policing': 6658, 'policy': 6659, 'Policy': 6660, 'Political': 6661, 'political': 6662, 'polled': 6663, 'pollen': 6664, 'Pollen': 6665, 'pollen classification': 6666, 'PolyKernel': 6667, 'polymorphic': 6668, 'polynomial': 6669, 'polynomials': 6670, 'polysomnograph': 6671, 'Pong': 6672, 'pong': 6673, 'pool': 6674, 'pooling': 6675, 'poor': 6676, 'poorer': 6677, 'poorly': 6678, 'pop': 6679, 'Poppelreuter': 6680, \"poppelreuter's test\": 6681, 'Popular': 6682, 'popular': 6683, 'popularity': 6684, 'popularization': 6685, 'popularly': 6686, 'population': 6687, 'Population': 6688, 'populations': 6689, 'port': 6690, 'portability': 6691, 'portable': 6692, 'Portmanteau': 6693, 'ports (computers)': 6694, 'POS': 6695, 'pose': 6696, 'posed': 6697, 'poses': 6698, 'posing': 6699, 'position': 6700, 'Positioning': 6701, 'positioning': 6702, 'positions': 6703, 'positive': 6704, 'Positive': 6705, 'positive unlabeled learning': 6706, 'positives': 6707, 'possess': 6708, 'possibility': 6709, 'possible': 6710, 'possibly': 6711, 'post': 6712, 'Post': 6713, 'post-processing': 6714, 'posted': 6715, 'posterior': 6716, 'Posterior': 6717, 'posting': 6718, 'Posts': 6719, 'posts': 6720, 'Potential': 6721, 'potential': 6722, 'potentiality': 6723, 'potentially': 6724, 'Potentials': 6725, 'potentials': 6726, 'Power': 6727, 'power': 6728, 'power density': 6729, 'power grid analysis': 6730, 'power spectral density analysis': 6731, 'power systems': 6732, 'powered': 6733, 'powerful': 6734, 'powering': 6735, 'Powerset': 6736, 'PPDM': 6737, 'PPDP': 6738, 'PPRL': 6739, 'practical': 6740, 'practicality': 6741, 'practically': 6742, 'practice': 6743, 'practising': 6744, 'practitioner': 6745, 'practitioners': 6746, 'Pradesh': 6747, 'pRBC': 6748, 'pre': 6749, 'Pre': 6750, 'pre school': 6751, 'precious': 6752, 'precipitated': 6753, 'precipitation': 6754, 'precipitations': 6755, 'Precise': 6756, 'precise': 6757, 'precisely': 6758, 'Precision': 6759, 'precision': 6760, 'predefined': 6761, 'Predicate': 6762, 'Predicative': 6763, 'Predict': 6764, 'predict': 6765, 'predictability': 6766, 'predictable': 6767, 'Predictable': 6768, 'predictands': 6769, 'predicted': 6770, 'predicting': 6771, 'Predicting': 6772, 'predicting psychosis': 6773, 'prediction': 6774, 'Prediction': 6775, 'prediction algorithms': 6776, 'predictions': 6777, 'Predictions': 6778, 'Predictive': 6779, 'predictive': 6780, 'predictive analysis': 6781, 'predictive data analytics': 6782, 'predictive model': 6783, 'predictive modelling': 6784, 'predictive models': 6785, 'predictive scoring systems': 6786, 'predictivity': 6787, 'predictor': 6788, 'predictors': 6789, 'predicts': 6790, 'predominant': 6791, 'preeclampsia': 6792, 'preference': 6793, 'preference prediction technique': 6794, 'preferences': 6795, 'Preferences': 6796, 'preferred': 6797, 'preformed': 6798, 'pregnancy': 6799, 'pregnant': 6800, 'Pregnant': 6801, 'preliminaries': 6802, 'preliminary': 6803, 'Preliminary': 6804, 'prenatal': 6805, 'preparation': 6806, 'preprocessed': 6807, 'preprocesses': 6808, 'preprocessing': 6809, 'preprocessor': 6810, 'prerequisite': 6811, 'prescribe': 6812, 'presence': 6813, 'Presence': 6814, 'present': 6815, 'presentation': 6816, 'presented': 6817, 'presenting': 6818, 'presents': 6819, 'preservation': 6820, 'Preservation': 6821, 'preserve': 6822, 'preserving': 6823, 'Preserving': 6824, 'pressing': 6825, 'Pressure': 6826, 'pressure': 6827, 'prestige': 6828, 'pretraining': 6829, 'prevalent': 6830, 'prevent': 6831, 'prevented': 6832, 'preventing': 6833, 'prevention': 6834, 'previews': 6835, 'Previous': 6836, 'previous': 6837, 'Previously': 6838, 'previously': 6839, 'price': 6840, 'Price': 6841, 'prices': 6842, 'pricing': 6843, 'primal': 6844, 'Primal': 6845, 'primal dual algorithm': 6846, 'primary': 6847, 'prime': 6848, 'principal': 6849, 'Principal': 6850, 'principal component analysis': 6851, 'principal components analysis': 6852, 'principal-component analysis': 6853, 'Principle': 6854, 'principle': 6855, 'principle component analysis': 6856, 'principled': 6857, 'principles': 6858, 'printed': 6859, 'prints': 6860, 'Prior': 6861, 'prior': 6862, 'priori': 6863, 'prioritization': 6864, 'Prioritization': 6865, 'prioritize': 6866, 'prioritized': 6867, 'priors': 6868, 'privacy': 6869, 'Privacy': 6870, 'privacy policy': 6871, 'privacy preserving': 6872, 'privacy-preserving': 6873, 'pro': 6874, 'proactively': 6875, 'probabilistic': 6876, 'Probabilistic': 6877, 'probabilistic atlas': 6878, 'probabilistic logic': 6879, 'probabilistic matrix factorization': 6880, 'probabilistic programming': 6881, 'probabilities': 6882, 'Probabilities': 6883, 'Probability': 6884, 'probability': 6885, 'probability of classification error': 6886, 'Probit': 6887, 'probit regression': 6888, 'problem': 6889, 'Problem': 6890, 'problematic': 6891, 'Problems': 6892, 'problems': 6893, 'procedure': 6894, 'procedures': 6895, 'Process': 6896, 'process': 6897, 'process control': 6898, 'processed': 6899, 'Processes': 6900, 'processes': 6901, 'processing': 6902, 'Processing': 6903, 'processor': 6904, 'produce': 6905, 'produced': 6906, 'produces': 6907, 'producing': 6908, 'Product': 6909, 'product': 6910, 'production': 6911, 'Production': 6912, 'productive': 6913, 'productivity': 6914, 'Products': 6915, 'products': 6916, 'professional': 6917, 'professionals': 6918, 'proficiency': 6919, 'proficient': 6920, 'profile': 6921, 'profiles': 6922, 'Profiles': 6923, 'profiling': 6924, 'Profiling': 6925, 'Profit': 6926, 'Profitability': 6927, 'profitability': 6928, 'profitable': 6929, 'profoundly': 6930, 'prognoses': 6931, 'Prognostic': 6932, 'Program': 6933, 'program': 6934, 'Programmable': 6935, 'programmable': 6936, 'Programme': 6937, 'Programmers': 6938, 'programmers': 6939, 'programmes': 6940, 'Programming': 6941, 'programming': 6942, 'programs': 6943, 'progress': 6944, 'progresses': 6945, 'progression': 6946, 'progressive': 6947, 'prohibitive': 6948, 'project': 6949, 'projected': 6950, 'projecting': 6951, 'projection': 6952, 'Projection': 6953, 'projections': 6954, 'Projects': 6955, 'projects': 6956, 'proliferated': 6957, 'proliferation': 6958, 'prolific': 6959, 'Prominent': 6960, 'prominent': 6961, 'promise': 6962, 'promising': 6963, 'Promontory': 6964, 'promote': 6965, 'promoted': 6966, 'promoting': 6967, 'prompt': 6968, 'Prompt': 6969, 'prompting': 6970, 'promptly': 6971, 'prompts': 6972, 'prone': 6973, 'pronounceable': 6974, 'proof': 6975, 'proofof': 6976, 'propagate': 6977, 'propagates': 6978, 'propagating': 6979, 'Propagation': 6980, 'propagation': 6981, 'Propensity': 6982, 'propensity': 6983, 'proper': 6984, 'properly': 6985, 'Properties': 6986, 'properties': 6987, 'property': 6988, 'proportion': 6989, 'proportional': 6990, 'proportions': 6991, 'Proposal': 6992, 'proposal': 6993, 'proposals': 6994, 'propose': 6995, 'proposed': 6996, 'Proposed': 6997, 'proposes': 6998, 'proposing': 6999, 'proprietary': 7000, 'prospective': 7001, 'prospects': 7002, 'Prostate': 7003, 'prostate': 7004, 'protect': 7005, 'protection': 7006, 'protein': 7007, 'Protein': 7008, 'protein conformation': 7009, 'protocol': 7010, 'protocols': 7011, 'proton': 7012, 'prototype': 7013, 'prototyped': 7014, 'prove': 7015, 'proved': 7016, 'proven': 7017, 'provide': 7018, 'provided': 7019, 'provider': 7020, 'providers': 7021, 'provides': 7022, 'providing': 7023, 'provinces': 7024, 'provision': 7025, 'proxy': 7026, 'Pruning': 7027, 'pruning': 7028, 'PS': 7029, 'PSDA': 7030, 'pseudo': 7031, 'PSG': 7032, 'PSM': 7033, 'PSO': 7034, 'psychiatric': 7035, 'psychiatry': 7036, 'psychological': 7037, 'psychology': 7038, 'Psychosis': 7039, 'psychosis': 7040, 'psychotherapy': 7041, 'Psychotherapy': 7042, 'PU': 7043, 'public': 7044, 'publicly': 7045, 'published': 7046, 'publishers': 7047, 'Publishing': 7048, 'publishing': 7049, 'pull': 7050, 'Pull': 7051, 'pull request': 7052, 'pulled': 7053, 'pulling': 7054, 'Pulmonary': 7055, 'purchasing': 7056, 'purpose': 7057, 'purposes': 7058, 'pursue': 7059, 'Pursuit': 7060, 'pursuit': 7061, 'push': 7062, 'put': 7063, 'puts': 7064, 'putting': 7065, 'PV': 7066, 'pv system': 7067, 'pyramid': 7068, 'q': 7069, 'Q': 7070, 'q learning': 7071, 'q-learning': 7072, 'Q10': 7073, 'QoS': 7074, 'qos over heterogeneous networks': 7075, 'QP': 7076, 'qPCR': 7077, 'qpcr': 7078, 'QQ': 7079, 'quadratic': 7080, 'quadratic programming': 7081, 'qualitative': 7082, 'qualities': 7083, 'quality': 7084, 'Quality': 7085, 'quality assessment': 7086, 'quantifiable': 7087, 'quantification': 7088, 'quantified': 7089, 'Quantified': 7090, 'Quantifier': 7091, 'quantify': 7092, 'quantifying': 7093, 'Quantile': 7094, 'quantitative': 7095, 'quantitatively': 7096, 'quantities': 7097, 'quantity': 7098, 'quantization': 7099, 'quantum': 7100, 'quasi': 7101, 'Quasi': 7102, 'queries': 7103, 'Queries': 7104, 'Query': 7105, 'query': 7106, 'query relaxation': 7107, 'question': 7108, 'questionable': 7109, 'questions': 7110, 'quick': 7111, 'quickest': 7112, 'quickly': 7113, 'Quinn': 7114, 'quite': 7115, 'R': 7116, 'R2': 7117, 'race': 7118, 'races': 7119, 'radar': 7120, 'Radar': 7121, 'Radial': 7122, 'radial': 7123, 'radial basis functions': 7124, 'radiality': 7125, 'Radiation': 7126, 'radiation': 7127, 'radiation hybrid mapping': 7128, 'Radio': 7129, 'radio frequency': 7130, 'Radioactive': 7131, 'radiologist': 7132, 'radiologists': 7133, 'radius': 7134, 'railway': 7135, 'Railway': 7136, 'railway crossing region': 7137, 'railway-incidents': 7138, 'rainfall': 7139, 'Rainfall': 7140, 'raise': 7141, 'random': 7142, 'Random': 7143, 'random forest': 7144, 'random forests': 7145, 'random forests ': 7146, 'random projection': 7147, 'Randomized': 7148, 'randomized': 7149, 'randomly': 7150, 'range': 7151, 'Range': 7152, 'ranges': 7153, 'rank': 7154, 'Rank': 7155, 'ranked': 7156, 'rankers': 7157, 'Ranking': 7158, 'ranking': 7159, 'rankings': 7160, 'ranks': 7161, 'rankX': 7162, 'ransom': 7163, 'ransomware': 7164, 'Ransomware': 7165, 'rapid': 7166, 'rapidly': 7167, 'rare': 7168, 'rarely': 7169, 'rate': 7170, 'rated': 7171, 'rates': 7172, 'Rates': 7173, 'Rather': 7174, 'rather': 7175, 'rating': 7176, 'ratings': 7177, 'Ratio': 7178, 'ratio': 7179, 'rationale': 7180, 'ratios': 7181, 'Raw': 7182, 'raw': 7183, 'ray': 7184, 'RBF': 7185, 'RBFNN': 7186, 'RBFs': 7187, 'RBM': 7188, 'rbm': 7189, 'RBMs': 7190, 'RBSO': 7191, 'Rc': 7192, 'RDI': 7193, 'RDIL': 7194, 'RDM': 7195, 'Re': 7196, 're': 7197, 'reach': 7198, 'reaches': 7199, 'reaching': 7200, 'react': 7201, 'reaction': 7202, 'reactive': 7203, 'reactor': 7204, 'read': 7205, 'reader': 7206, 'readers': 7207, 'readily': 7208, 'reading': 7209, 'readings': 7210, 'reads': 7211, 'Real': 7212, 'real': 7213, 'real estate prediction': 7214, 'real-time recurrent learning (rtrl)': 7215, 'real-time systems': 7216, 'realistic': 7217, 'Realistic': 7218, 'realize': 7219, 'realized': 7220, 'really': 7221, 'realm': 7222, 'realworld': 7223, 'reanalysis': 7224, 'reason': 7225, 'reasonable': 7226, 'reasonably': 7227, 'Reasoning': 7228, 'reasoning': 7229, 'reasons': 7230, 'recall': 7231, 'recall of data': 7232, 'receive': 7233, 'Received': 7234, 'received': 7235, 'receiver': 7236, 'recent': 7237, 'Recent': 7238, 'recently': 7239, 'Recently': 7240, 'Recognition': 7241, 'recognition': 7242, 'recognize': 7243, 'recognized': 7244, 'recognizer': 7245, 'recognizing': 7246, 'Recognizing': 7247, 'recommend': 7248, 'recommendation': 7249, 'Recommendation': 7250, 'recommendation emails': 7251, 'recommendations': 7252, 'recommended': 7253, 'Recommender': 7254, 'recommender': 7255, 'recommender systems': 7256, 'recommender systems survey': 7257, 'recommenders': 7258, 'Recommenders': 7259, 'Recommending': 7260, 'recommending': 7261, 'recommends': 7262, 'recompression': 7263, 'Recompression': 7264, 'reconfigured': 7265, 'reconstruct': 7266, 'reconstructed': 7267, 'reconstructing': 7268, 'reconstruction': 7269, 'Reconstruction': 7270, 'reconstruction error': 7271, 'reconstructions': 7272, 'Record': 7273, 'record': 7274, 'record linkage': 7275, 'recorded': 7276, 'recording': 7277, 'recordings': 7278, 'records': 7279, 'recover': 7280, 'recovering': 7281, 'recovery': 7282, 'recruit': 7283, 'recruitment': 7284, 'rectangular': 7285, 'Recurrent': 7286, 'recurrent': 7287, 'recurrent neural network': 7288, 'recurrent processing': 7289, 'recursive': 7290, 'Recursive': 7291, 'recursive feature addition': 7292, 'REDD': 7293, 'rediscovering': 7294, 'redness': 7295, 'reduce': 7296, 'Reduce': 7297, 'reduced': 7298, 'Reduced': 7299, 'reduces': 7300, 'reducible': 7301, 'reducing': 7302, 'Reducing': 7303, 'reduction': 7304, 'Reduction': 7305, 'redundant': 7306, 'refactored': 7307, 'refactoring': 7308, 'Refactoring': 7309, 'reference': 7310, 'Reference': 7311, 'references': 7312, 'referred': 7313, 'referring': 7314, 'refers': 7315, 'refined': 7316, 'refining': 7317, 'reflect': 7318, 'reflects': 7319, 'reformulating': 7320, 'refresh': 7321, 'regard': 7322, 'regarding': 7323, 'Regarding': 7324, 'regardless': 7325, 'regards': 7326, 'Regime': 7327, 'regime': 7328, 'regime classification': 7329, 'regimes': 7330, 'region': 7331, 'Region': 7332, 'region of interest': 7333, 'regional': 7334, 'Regions': 7335, 'regions': 7336, 'registration': 7337, 'Regression': 7338, 'regression': 7339, 'regression trees': 7340, 'regressor': 7341, 'regressors': 7342, 'regret': 7343, 'regular': 7344, 'regularisation': 7345, 'regularization': 7346, 'Regularization': 7347, 'regularize': 7348, 'regularized': 7349, 'regularly': 7350, 'regulate': 7351, 'regulators': 7352, 'regulatory': 7353, 'Regulatory': 7354, 'rehabilitation': 7355, 'reinforced': 7356, 'reinforcement': 7357, 'Reinforcement': 7358, 'reinforcement learning': 7359, 'reinstatement': 7360, 'rejected': 7361, 'rejecting': 7362, 'Rejection': 7363, 'rejection': 7364, 'relabeling': 7365, 'relate': 7366, 'related': 7367, 'Related': 7368, 'relatedness': 7369, 'relates': 7370, 'Relation': 7371, 'relation': 7372, 'relational': 7373, 'relations': 7374, 'relationship': 7375, 'relationships': 7376, 'relative': 7377, 'relatively': 7378, 'relaxing': 7379, 'released': 7380, 'releases': 7381, 'relevance': 7382, 'Relevance': 7383, 'relevant': 7384, 'reliability': 7385, 'reliable': 7386, 'Reliable': 7387, 'reliably': 7388, 'reliance': 7389, 'relied': 7390, 'ReliefF': 7391, 'relies': 7392, 'religious': 7393, 'rely': 7394, 'relying': 7395, 'remain': 7396, 'remaining': 7397, 'remains': 7398, 'remarkable': 7399, 'remedial': 7400, 'Remedial': 7401, 'remember': 7402, 'remote': 7403, 'remote health care': 7404, 'Remotely': 7405, 'removal': 7406, 'Removal': 7407, 'remove': 7408, 'removed': 7409, 'removing': 7410, 'rendered': 7411, 'renewable': 7412, 'Renewable': 7413, 'renewable energy': 7414, 'repair': 7415, 'repeatable': 7416, 'repeatedly': 7417, 'repeating': 7418, 'repetition': 7419, 'Repetition': 7420, 'repetitive': 7421, 'replaced': 7422, 'replacement': 7423, 'Replacement': 7424, 'Replacing': 7425, 'replications': 7426, 'report': 7427, 'reported': 7428, 'reporting': 7429, 'Reporting': 7430, 'reports': 7431, 'repositories': 7432, 'Repository': 7433, 'repository': 7434, 'represent': 7435, 'Representation': 7436, 'representation': 7437, 'representation learning': 7438, 'representations': 7439, 'Representations': 7440, 'representative': 7441, 'represented': 7442, 'representing': 7443, 'represents': 7444, 'reproduce': 7445, 'reproduced': 7446, 'reproducing': 7447, 'Request': 7448, 'request': 7449, 'Requests': 7450, 'requests': 7451, 'require': 7452, 'required': 7453, 'requirement': 7454, 'requirements': 7455, 'requires': 7456, 'requiring': 7457, 'resample': 7458, 'resampled': 7459, 'resamples': 7460, 'Resampling': 7461, 'resampling': 7462, 'research': 7463, 'researched': 7464, 'researcher': 7465, 'researchers': 7466, 'researches': 7467, 'researching': 7468, 'Resembling': 7469, 'reserves': 7470, 'reservoir': 7471, 'Reservoir': 7472, 'reservoir level': 7473, 'residential': 7474, 'Residential': 7475, 'residents': 7476, 'Residual': 7477, 'resistance': 7478, 'ResNet': 7479, 'Resolution': 7480, 'resolution': 7481, 'resolutions': 7482, 'resolve': 7483, 'resolving': 7484, 'Resonance': 7485, 'resonance': 7486, 'resonance frequency': 7487, 'resorting': 7488, 'Resource': 7489, 'resource': 7490, 'resource exhausting': 7491, 'resource management': 7492, 'resources': 7493, 'respect': 7494, 'respectively': 7495, 'respond': 7496, 'respondents': 7497, 'Respondents': 7498, 'response': 7499, 'Response': 7500, 'response likelihood model': 7501, 'responses': 7502, 'responsibility': 7503, 'responsible': 7504, 'responsiveness': 7505, 'rest': 7506, 'Restart': 7507, 'restarted': 7508, 'restarts': 7509, 'restoration': 7510, 'Restoration': 7511, 'restore': 7512, 'restored': 7513, 'restricted': 7514, 'Restricted': 7515, 'restricted boltzmann machine': 7516, 'restrictions': 7517, 'restructuring': 7518, 'result': 7519, 'resultant': 7520, 'resulted': 7521, 'resulting': 7522, 'Results': 7523, 'results': 7524, 'retail': 7525, 'Retail': 7526, 'retained': 7527, 'retaining': 7528, 'retargeting': 7529, 'retention': 7530, 'Retention': 7531, 'retesting': 7532, 'rethink': 7533, 'retinal': 7534, 'Retinal': 7535, 'retinal image': 7536, 'retinas': 7537, 'retrained': 7538, 'retraining': 7539, 'retrieval': 7540, 'Retrieval': 7541, 'retrieve': 7542, 'retrieved': 7543, 'retrieves': 7544, 'Retrieving': 7545, 'retrieving': 7546, 'return': 7547, 'returned': 7548, 'returning': 7549, 'reuse': 7550, 'Reusing': 7551, 'reusing': 7552, 'reveal': 7553, 'revealed': 7554, 'revealing': 7555, 'reveals': 7556, 'revenue': 7557, 'reverse': 7558, 'Review': 7559, 'review': 7560, 'reviewed': 7561, 'Reviews': 7562, 'reviews': 7563, 'revise': 7564, 'revision': 7565, 'revolve': 7566, 'reward': 7567, 'Rewarding': 7568, 'rewards': 7569, 'Reweighting': 7570, 'reweighting': 7571, 'rewrite': 7572, 'RF': 7573, 'rfe': 7574, 'RGB': 7575, 'RH': 7576, 'rho': 7577, 'Rhythm': 7578, 'Ribeiro': 7579, 'Rice': 7580, 'rice': 7581, 'rich': 7582, 'Rich': 7583, 'richer': 7584, 'ridge': 7585, 'Ridge': 7586, 'ridge regression': 7587, 'RIDL': 7588, 'Riemannian': 7589, 'rife': 7590, 'right': 7591, 'RIMARC': 7592, 'ring': 7593, 'rise': 7594, 'rising': 7595, 'risk': 7596, 'Risk': 7597, 'RITM': 7598, 'rival': 7599, 'RKHS': 7600, 'RL': 7601, 'RLS': 7602, 'RME': 7603, 'RMSE': 7604, 'RNNs': 7605, 'Road': 7606, 'road': 7607, 'road accident': 7608, 'road transportation': 7609, 'roads': 7610, 'Robot': 7611, 'robot': 7612, 'robot control': 7613, 'robot sensing systems': 7614, 'robotic': 7615, 'Robots': 7616, 'robots': 7617, 'Robust': 7618, 'robust': 7619, 'robust learning': 7620, 'robustly': 7621, 'Robustness': 7622, 'robustness': 7623, 'RobustSPAM': 7624, 'ROC': 7625, 'roc analysis': 7626, 'Rocchio': 7627, 'ROI': 7628, 'role': 7629, 'Rolling': 7630, 'room': 7631, 'root': 7632, 'Roper': 7633, 'rotated': 7634, 'rotating': 7635, 'rotation': 7636, 'Rotation': 7637, 'rotations': 7638, 'rough': 7639, 'Rough': 7640, 'rough sets': 7641, 'rounds': 7642, 'routers': 7643, 'routes': 7644, 'routine behaviours': 7645, 'routing': 7646, 'Routing': 7647, 'routing and mobility management': 7648, 'ROV': 7649, 'row': 7650, 'rp trees': 7651, 'RRKOL': 7652, 'RRT': 7653, 'RSS': 7654, 'RSSI': 7655, 'RT': 7656, 'RTRL': 7657, 'rubrics': 7658, 'rule': 7659, 'Rule': 7660, 'rule extraction': 7661, 'rule-based classification': 7662, 'Rules': 7663, 'rules': 7664, 'run': 7665, 'running': 7666, 'runs': 7667, 'runtime': 7668, 'Runtime': 7669, 'runtime analysis': 7670, 'S': 7671, 's': 7672, 'sacked sparse autoencoders': 7673, 'sacrificing': 7674, 'Safe': 7675, 'safe': 7676, 'safety': 7677, 'Sagar': 7678, 'said': 7679, 'saidi forecast': 7680, 'sake': 7681, 'Salama': 7682, 'Sale': 7683, 'sales': 7684, 'Saliency': 7685, 'saliency': 7686, 'salient': 7687, 'same': 7688, 'Same': 7689, 'sample': 7690, 'Sample': 7691, 'sample reconstruction': 7692, 'sampled': 7693, 'sampler': 7694, 'Samples': 7695, 'samples': 7696, 'sampling': 7697, 'Sampling': 7698, 'Samsung': 7699, 'Sandbox': 7700, 'sanitizer': 7701, 'SAPS': 7702, 'satellites': 7703, 'satisfaction': 7704, 'Satisfaction': 7705, 'satisfactory': 7706, 'Satisficing': 7707, 'satisficing': 7708, 'satisfies': 7709, 'satisfy': 7710, 'satisfying': 7711, 'Save': 7712, 'save': 7713, 'saves': 7714, 'savings': 7715, 'saw': 7716, 'SAX': 7717, 'SB': 7718, 'SBC': 7719, 'SBME': 7720, 'Sc': 7721, 'SC': 7722, 'SCADA': 7723, 'scada data': 7724, 'scalability': 7725, 'Scalable': 7726, 'scalable': 7727, 'Scale': 7728, 'scale': 7729, 'Scaled': 7730, 'scaled': 7731, 'scales': 7732, 'Scaling': 7733, 'scaling': 7734, 'Scalp': 7735, 'scanned': 7736, 'scanner': 7737, 'scanners': 7738, 'scanning': 7739, 'scarcity': 7740, 'scatter': 7741, 'SCEFIS': 7742, 'scenario': 7743, 'scenario generation': 7744, 'Scenarios': 7745, 'scenarios': 7746, 'scene': 7747, 'Scene': 7748, 'scene matching': 7749, 'scenes': 7750, 'SCHDP': 7751, 'schedule': 7752, 'schedules': 7753, 'Scheduling': 7754, 'scheduling': 7755, 'Schema': 7756, 'schema': 7757, 'scheme': 7758, 'Scheme': 7759, 'schemes': 7760, 'Schmidt': 7761, 'school': 7762, 'schoolers': 7763, 'Schwarz': 7764, 'Science': 7765, 'science': 7766, 'scientific': 7767, 'Scientific': 7768, 'scientists': 7769, 'SCLDA': 7770, 'sclera': 7771, 'sclera segmentation': 7772, 'Scoliosis': 7773, 'scoliosis': 7774, 'scope': 7775, 'score': 7776, 'Score': 7777, 'score systems': 7778, 'scored': 7779, 'scores': 7780, 'Scoring': 7781, 'scoring': 7782, 'Scraper': 7783, 'scraping': 7784, 'scratch': 7785, 'screen': 7786, 'screening': 7787, 'Screening': 7788, 'SDA': 7789, 'sda': 7790, 'SDAM': 7791, 'SDN': 7792, 'sdncontroller': 7793, 'sdsm': 7794, 'SDSM': 7795, 'SE': 7796, 'sea': 7797, 'Sea': 7798, 'seam': 7799, 'seamless': 7800, 'seamlessly': 7801, 'search': 7802, 'Search': 7803, 'search by multiple examples': 7804, 'searches': 7805, 'Searching': 7806, 'searching': 7807, 'SEARCHSPN': 7808, 'season': 7809, 'seasonal': 7810, 'seasons': 7811, 'Second': 7812, 'second': 7813, 'secondary': 7814, 'seconds': 7815, 'secret': 7816, 'section': 7817, 'Sectional': 7818, 'sectional': 7819, 'sections': 7820, 'sector': 7821, 'sectors': 7822, 'secure': 7823, 'Secure': 7824, 'secure data aggregation model (sdam)': 7825, 'secured': 7826, 'Security': 7827, 'security': 7828, 'security strength': 7829, 'see': 7830, 'seed': 7831, 'seek': 7832, 'seeks': 7833, 'seem': 7834, 'seems': 7835, 'seen': 7836, 'segment': 7837, 'Segment': 7838, 'Segmentation': 7839, 'segmentation': 7840, 'Segmentations': 7841, 'segmentations': 7842, 'segmented': 7843, 'segmenting': 7844, 'segments': 7845, 'seismic': 7846, 'Seismic': 7847, 'seizure': 7848, 'Seizure': 7849, 'seizure detection': 7850, 'seizures': 7851, 'select': 7852, 'selected': 7853, 'Selecting': 7854, 'selecting': 7855, 'selection': 7856, 'Selection': 7857, 'Selections': 7858, 'selects': 7859, 'Self': 7860, 'self': 7861, 'self organization': 7862, 'self-organization parallelization': 7863, 'self-organizing map': 7864, 'self-organizing maps': 7865, 'self-supervised': 7866, 'seller': 7867, 'sellers': 7868, 'selling': 7869, 'semantic': 7870, 'Semantic': 7871, 'semantic slot labelling': 7872, 'semantic web': 7873, 'semantically': 7874, 'semantics': 7875, 'semester': 7876, 'semesters': 7877, 'Semi': 7878, 'semi': 7879, 'semi-arid climate': 7880, 'semi-supervised clustering': 7881, 'semi-supervised learning': 7882, 'Semiconductor': 7883, 'semiconductor': 7884, 'semiconductor manufacturing': 7885, 'semisupervised': 7886, 'send': 7887, 'sends': 7888, 'senior': 7889, 'sense': 7890, 'sensibly': 7891, 'sensing': 7892, 'Sensitive': 7893, 'sensitive': 7894, 'sensitivity': 7895, 'Sensor': 7896, 'sensor': 7897, 'sensor node (sn)': 7898, 'Sensors': 7899, 'sensors': 7900, 'sensory': 7901, 'sent': 7902, 'sentence': 7903, 'Sentence': 7904, 'sentences': 7905, 'Sentiment': 7906, 'sentiment': 7907, 'sentiment analysis': 7908, 'Sentimental': 7909, 'sep': 7910, 'separable': 7911, 'separate': 7912, 'separated': 7913, 'separately': 7914, 'separating': 7915, 'separation': 7916, 'Separation': 7917, 'sequence': 7918, 'Sequence': 7919, 'sequence classification': 7920, 'Sequences': 7921, 'sequences': 7922, 'sequencing': 7923, 'sequential': 7924, 'Sequential': 7925, 'sequential optimization': 7926, 'sequential pattern': 7927, 'sequentially': 7928, 'serendipitous discovery': 7929, 'Series': 7930, 'series': 7931, 'serious': 7932, 'serve': 7933, 'server': 7934, 'servers': 7935, 'serves': 7936, 'Service': 7937, 'service': 7938, 'service component architecture': 7939, 'service oriented architecture': 7940, 'services': 7941, 'Services': 7942, 'serving': 7943, 'SESDMK': 7944, 'session': 7945, 'sessions': 7946, 'Set': 7947, 'set': 7948, 'Sets': 7949, 'sets': 7950, 'setting': 7951, 'settings': 7952, 'setup': 7953, 'seven': 7954, 'Several': 7955, 'several': 7956, 'severe': 7957, 'severely': 7958, 'Severity': 7959, 'severity': 7960, 'sex': 7961, 'sexes': 7962, 'SFA': 7963, 'SG': 7964, 'SGD': 7965, 'shallow': 7966, 'Shannon': 7967, 'shape': 7968, 'shape recognition': 7969, 'shaped': 7970, 'shapes': 7971, 'shaping': 7972, 'Shapire': 7973, 'sharable': 7974, 'share': 7975, 'shared': 7976, 'shares': 7977, 'sharing': 7978, 'sharp': 7979, 'she': 7980, 'sheer': 7981, 'shelf': 7982, 'shift': 7983, 'shifts': 7984, 'Shin': 7985, 'shockingly': 7986, 'short': 7987, 'Short': 7988, 'short time series': 7989, 'shortcomings': 7990, 'shorten': 7991, 'shortening': 7992, 'shorter': 7993, 'shortest': 7994, 'Shot': 7995, 'shot': 7996, 'shot classification': 7997, 'shots': 7998, 'should': 7999, 'show': 8000, 'showcase': 8001, 'showed': 8002, 'showing': 8003, 'shown': 8004, 'shows': 8005, 'shrinking': 8006, 'shrinks': 8007, 'shutting': 8008, 'ShuttleTraq': 8009, 'siblings': 8010, 'side': 8011, 'Sided': 8012, 'sided': 8013, 'sides': 8014, 'SIEM': 8015, 'sigmoid': 8016, 'Sign': 8017, 'signal': 8018, 'Signal': 8019, 'signal analysis': 8020, 'signal processing': 8021, 'Signalling': 8022, 'signalling': 8023, 'signals': 8024, 'Signals': 8025, 'signature': 8026, 'Signature': 8027, 'Signatures': 8028, 'signatures': 8029, 'significance': 8030, 'significant': 8031, 'significantly': 8032, 'signifies': 8033, 'signs': 8034, 'silhouette': 8035, 'silicon': 8036, 'SIM': 8037, 'similar': 8038, 'Similar': 8039, 'similarities': 8040, 'similarity': 8041, 'Similarity': 8042, 'similarity analysis': 8043, 'similarity-based methods': 8044, 'similarly': 8045, 'simple': 8046, 'Simple': 8047, 'simpler': 8048, 'simplicity': 8049, 'Simplicity': 8050, 'Simplified': 8051, 'simplifying': 8052, 'simulate': 8053, 'simulated': 8054, 'simulating': 8055, 'simulation': 8056, 'Simulation': 8057, 'simulation-based training': 8058, 'simulations': 8059, 'Simulations': 8060, 'Simulator': 8061, 'simulator': 8062, 'simulators': 8063, 'Simultaneous': 8064, 'simultaneous eeg & fmri': 8065, 'simultaneously': 8066, 'Simultaneously': 8067, 'since': 8068, 'Since': 8069, 'singers': 8070, 'Singing': 8071, 'singing': 8072, 'singing style': 8073, 'singings': 8074, 'Single': 8075, 'single': 8076, 'singular': 8077, 'Singular': 8078, 'singular value decomposition': 8079, 'singular-value decomposition': 8080, 'Sinus': 8081, 'sinusoidal': 8082, 'Site': 8083, 'site': 8084, 'sites': 8085, 'situation': 8086, 'situations': 8087, 'six': 8088, 'sixty': 8089, 'Size': 8090, 'size': 8091, 'SizeConnectivity': 8092, 'sizes': 8093, 'skewed': 8094, 'skill': 8095, 'skip-gram': 8096, 'skyline extraction': 8097, 'slangs': 8098, 'Sleep': 8099, 'sleep': 8100, 'slept': 8101, 'SLGMM': 8102, 'SLI': 8103, 'slice': 8104, 'slices': 8105, 'slide': 8106, 'sliding': 8107, 'slight': 8108, 'slightly': 8109, 'Slot': 8110, 'slot': 8111, 'slots': 8112, 'slow': 8113, 'Slow': 8114, 'slowly': 8115, 'SLPCA': 8116, 'SM': 8117, 'Small': 8118, 'small': 8119, 'small footprint': 8120, 'small sample size problem': 8121, 'small world': 8122, 'smaller': 8123, 'smart': 8124, 'Smart': 8125, 'smart cities': 8126, 'smart city': 8127, 'smart energy': 8128, 'smart environment': 8129, 'smart grids': 8130, 'smart homes': 8131, 'smart housing': 8132, 'smart meter': 8133, 'smart meters': 8134, 'smartphone': 8135, 'Smartphone': 8136, 'sMDP': 8137, 'SMNet': 8138, 'SMO': 8139, 'Smooth': 8140, 'smooth': 8141, 'smoother': 8142, 'SMOTE': 8143, 'SMS': 8144, 'sms spam': 8145, 'sms text': 8146, 'snack': 8147, 'snacking': 8148, 'snacks': 8149, 'snakes': 8150, 'Snakes': 8151, 'snapshots': 8152, 'SNB': 8153, 'SNP': 8154, 'snp selection': 8155, 'SNPs': 8156, 'SNR': 8157, 'So': 8158, 'SO': 8159, 'so': 8160, 'social': 8161, 'Social': 8162, 'social media': 8163, 'social network analysis': 8164, 'social networks': 8165, 'SocialEQ': 8166, 'Socialized': 8167, 'socioeconomic': 8168, 'Socioeconomic': 8169, 'sociological': 8170, 'sociology': 8171, 'SOFM': 8172, 'SOFMs': 8173, 'soft': 8174, 'Soft': 8175, 'soft clustering': 8176, 'soft sets': 8177, 'software': 8178, 'Software': 8179, 'software architecture': 8180, 'software defect prediction': 8181, 'software defined networks': 8182, 'software effort estimation': 8183, 'software engineering': 8184, 'software enhancement duration prediction': 8185, 'software maintenance duration prediction': 8186, 'software-defined networking (sdn)': 8187, 'Solar': 8188, 'solar': 8189, 'solar energy': 8190, 'solar radiation': 8191, 'solely': 8192, 'solo': 8193, 'solution': 8194, 'Solution': 8195, 'Solutions': 8196, 'solutions': 8197, 'solve': 8198, 'solved': 8199, 'Solver': 8200, 'solver': 8201, 'solvers': 8202, 'solves': 8203, 'solving': 8204, 'SOM': 8205, 'Some': 8206, 'some': 8207, 'sometimes': 8208, 'Somewhat': 8209, 'somewhat': 8210, 'Sonar': 8211, 'songs': 8212, 'soon': 8213, 'sophisticated': 8214, 'Sound': 8215, 'sound': 8216, 'Soundex': 8217, 'soundex': 8218, 'Source': 8219, 'source': 8220, 'source code attributes': 8221, 'source-aware': 8222, 'sourced': 8223, 'Sourced': 8224, 'sources': 8225, 'Southern': 8226, 'SP': 8227, 'space': 8228, 'Space': 8229, 'space exploration': 8230, 'spaces': 8231, 'spam': 8232, 'SPAM': 8233, 'Spam': 8234, 'spam review': 8235, 'spamdexing': 8236, 'spammers': 8237, 'span': 8238, 'spanning': 8239, 'Sparse': 8240, 'sparse': 8241, 'sparse autoencoders': 8242, 'sparse methods': 8243, 'sparseness': 8244, 'sparsification': 8245, 'Sparsity': 8246, 'sparsity': 8247, 'Spatial': 8248, 'spatial': 8249, 'spatially': 8250, 'Spatio': 8251, 'spatio': 8252, 'spatio-temporal data': 8253, 'spatiotemporal': 8254, 'speaker': 8255, 'Speaker': 8256, 'speaker adaptation': 8257, 'speaker identification': 8258, 'spearman': 8259, 'SPEC2000': 8260, 'special': 8261, 'specialists': 8262, 'specialized': 8263, 'specially': 8264, 'specialties': 8265, 'Species': 8266, 'species': 8267, 'Specific': 8268, 'specific': 8269, 'specifically': 8270, 'Specifically': 8271, 'specification': 8272, 'specifications': 8273, 'specificity': 8274, 'specified': 8275, 'specify': 8276, 'Spectra': 8277, 'spectra': 8278, 'spectral': 8279, 'Spectral': 8280, 'spectral clustering': 8281, 'spectral learning': 8282, 'spectrogram': 8283, 'spectrograms': 8284, 'spectroscopy': 8285, 'Spectrum': 8286, 'spectrum': 8287, 'speech': 8288, 'Speech': 8289, 'speech enhancement': 8290, 'speech intelligibility': 8291, 'speech quality': 8292, 'speech recognition': 8293, 'speech separation': 8294, 'speed': 8295, 'Speed': 8296, 'Speeding': 8297, 'speeding': 8298, 'speedup': 8299, 'SPEI': 8300, 'spending': 8301, 'spent': 8302, 'sphere': 8303, 'spheres': 8304, 'Spike': 8305, 'spike': 8306, 'spike train': 8307, 'spike-event': 8308, 'Spiking': 8309, 'spiking': 8310, 'spiking neural network (snn)': 8311, 'spine': 8312, 'split': 8313, 'splitting': 8314, 'Splitting': 8315, 'splitting criteria': 8316, 'SPNs': 8317, 'spoken': 8318, 'spontaneous': 8319, 'spores': 8320, 'sport': 8321, 'Sport': 8322, 'Sports': 8323, 'sports': 8324, 'spotting': 8325, 'Spotting': 8326, 'spread': 8327, 'Spread': 8328, 'spreading': 8329, 'SQL': 8330, 'sql injection attack': 8331, 'sqli': 8332, 'square': 8333, 'Square': 8334, 'Squared': 8335, 'squared': 8336, 'Squares': 8337, 'SSH': 8338, 'SSL': 8339, 'SSVEP': 8340, 'Stability': 8341, 'stability': 8342, 'stability analysis': 8343, 'stability-plasticity dilemma': 8344, 'stable': 8345, 'stack': 8346, 'Stack': 8347, 'Stacked': 8348, 'stacked': 8349, 'stacked denoising autoencoders': 8350, 'Stacking': 8351, 'stacking': 8352, 'stacks': 8353, 'staff': 8354, 'staffing': 8355, 'stage': 8356, 'Stage': 8357, 'stages': 8358, 'stakeholders': 8359, 'stance': 8360, 'standard': 8361, 'Standard': 8362, 'standardized': 8363, 'standardized precipitation index': 8364, 'Standards': 8365, 'standards': 8366, 'standing': 8367, 'star': 8368, 'star glyph plot': 8369, 'start': 8370, 'starting': 8371, 'starts': 8372, 'stat': 8373, 'state': 8374, 'State': 8375, 'state abstraction': 8376, 'state-space model': 8377, 'stated': 8378, 'statements': 8379, 'stateof': 8380, 'states': 8381, 'static': 8382, 'Station': 8383, 'station': 8384, 'Stationarity': 8385, 'stationary': 8386, 'stations': 8387, 'Stations': 8388, 'statistic': 8389, 'Statistical': 8390, 'statistical': 8391, 'statistical analysis': 8392, 'statistical downscaling': 8393, 'statistical image clutter metrics': 8394, 'statistical learning': 8395, 'statistical methods': 8396, 'statistical process control': 8397, 'statistical regression': 8398, 'statistical word alignment': 8399, 'statistically': 8400, 'statistics': 8401, 'status': 8402, 'Status': 8403, 'Stay': 8404, 'stay': 8405, 'steady': 8406, 'steady state visual evoked potential': 8407, 'steganography': 8408, 'Steganography': 8409, 'stem': 8410, 'Stem': 8411, 'stem cell transplant': 8412, 'stems': 8413, 'step': 8414, 'steps': 8415, 'Stick': 8416, 'sticky': 8417, 'still': 8418, 'stimuli': 8419, 'stimulus': 8420, 'stochastic': 8421, 'Stochastic': 8422, 'stochastic gradient descent': 8423, 'stochastic local search': 8424, 'stochastic processes': 8425, 'stochastically': 8426, 'Stock': 8427, 'stock': 8428, 'stock trading points': 8429, 'stoke': 8430, 'stone': 8431, 'Stop': 8432, 'stops': 8433, 'storage': 8434, 'storage system': 8435, 'store': 8436, 'stored': 8437, 'stores': 8438, 'Stores': 8439, 'stories': 8440, 'storing': 8441, 'Storm': 8442, 'storm': 8443, 'storylines': 8444, 'straggler': 8445, 'Stragglers': 8446, 'stragglers': 8447, 'straight': 8448, 'strategic': 8449, 'strategies': 8450, 'Strategies': 8451, 'Strategy': 8452, 'strategy': 8453, 'stream': 8454, 'Streamflow': 8455, 'streamflow': 8456, 'Streaming': 8457, 'streaming': 8458, 'streaming data': 8459, 'streamline': 8460, 'Streams': 8461, 'streams': 8462, 'strength': 8463, 'Strength': 8464, 'strengths': 8465, 'stress': 8466, 'stresses': 8467, 'strict': 8468, 'stride': 8469, 'strike': 8470, 'striking': 8471, 'string': 8472, 'stringent': 8473, 'strings': 8474, 'striving': 8475, 'stroke': 8476, 'Stroke': 8477, 'Strong': 8478, 'strong': 8479, 'strongly': 8480, 'structural': 8481, 'Structure': 8482, 'structure': 8483, 'structure learning': 8484, 'structured': 8485, 'structures': 8486, 'Structures': 8487, 'structuring': 8488, 'struggling': 8489, 'stuck': 8490, 'Student': 8491, 'student': 8492, 'student dropout': 8493, 'student retention': 8494, 'student success': 8495, 'students': 8496, 'studied': 8497, 'studies': 8498, 'Studies': 8499, 'Studio': 8500, 'study': 8501, 'Study': 8502, 'studying': 8503, 'style': 8504, 'Style': 8505, 'styles': 8506, 'stylistic': 8507, 'stylometric': 8508, 'Stylometry': 8509, 'stylometry': 8510, 'stylus': 8511, 'sub': 8512, 'subatomic': 8513, 'subbands': 8514, 'subclass': 8515, 'subgroup': 8516, 'subgroups': 8517, 'subject': 8518, 'Subject': 8519, 'subjective': 8520, 'subjects': 8521, 'submarket': 8522, 'submarkets': 8523, 'submetering': 8524, 'submitted': 8525, 'suboptimal': 8526, 'subpopulations': 8527, 'subregions': 8528, 'subsampling': 8529, 'subsequences': 8530, 'subsequent': 8531, 'Subsequently': 8532, 'subsequently': 8533, 'subset': 8534, 'Subset': 8535, 'subsethood': 8536, 'subsets': 8537, 'subsetting': 8538, 'subsignals': 8539, 'subspace learning': 8540, 'subspaces': 8541, 'substantial': 8542, 'substantially': 8543, 'substi': 8544, 'substitutability': 8545, 'substitute': 8546, 'substitutions': 8547, 'subsystems': 8548, 'subtask': 8549, 'subtle': 8550, 'subtly': 8551, 'Subtraction': 8552, 'subtraction': 8553, 'subtypes': 8554, 'suburb': 8555, 'Success': 8556, 'success': 8557, 'successes': 8558, 'Successes': 8559, 'successful': 8560, 'successfully': 8561, 'successively': 8562, 'such': 8563, 'Such': 8564, 'sudden': 8565, 'suffer': 8566, 'suffers': 8567, 'sufficiency': 8568, 'sufficient': 8569, 'sufficiently': 8570, 'suggest': 8571, 'suggested': 8572, 'suggests': 8573, 'suitability': 8574, 'suitable': 8575, 'suite': 8576, 'suited': 8577, 'sum': 8578, 'Sum': 8579, 'sum product networks': 8580, 'summaries': 8581, 'Summarization': 8582, 'summarization': 8583, 'summarize': 8584, 'summarizes': 8585, 'summarizing': 8586, 'summary': 8587, 'Summary': 8588, 'summer': 8589, 'sundown': 8590, 'sunshine': 8591, 'Sunspot': 8592, 'sunspot': 8593, 'superfunction': 8594, 'superfunctions': 8595, 'superior': 8596, 'superiority': 8597, 'Superposed': 8598, 'superposed': 8599, 'supervised': 8600, 'Supervised': 8601, 'supervised classification': 8602, 'supervised learning': 8603, 'supervised machine learning': 8604, 'Supervision': 8605, 'Supervisory': 8606, 'supplemented': 8607, 'supplied': 8608, 'suppliers': 8609, 'supply': 8610, 'support': 8611, 'Support': 8612, 'support vector egression': 8613, 'support vector machine': 8614, 'support vector machine learning': 8615, 'support vector machines': 8616, 'support vector machines (svm)': 8617, 'support vector machines plus': 8618, 'support vector regression': 8619, 'supported': 8620, 'Supporting': 8621, 'supporting': 8622, 'Supportive': 8623, 'supports': 8624, 'surely': 8625, 'Surface': 8626, 'surface': 8627, 'surface images': 8628, 'surfaces': 8629, 'surpass': 8630, 'surpasses': 8631, 'surrogate': 8632, 'surrogates': 8633, 'surrounding': 8634, 'Surveillance': 8635, 'surveillance': 8636, 'survey': 8637, 'Survey': 8638, 'survey datasets': 8639, 'surveys': 8640, 'survive': 8641, 'susceptible': 8642, 'suspiciousness': 8643, 'sustainability': 8644, 'SVD': 8645, 'SVHN': 8646, 'SVM': 8647, 'svm': 8648, 'svm classification': 8649, 'SVMs': 8650, 'svr': 8651, 'SVR': 8652, 'SVRs': 8653, 'swap': 8654, 'swarm': 8655, 'Swarm': 8656, 'swiftly': 8657, 'Swing': 8658, 'swing': 8659, 'swing detection': 8660, 'swing sports': 8661, 'Switch': 8662, 'Switched': 8663, 'switched': 8664, 'switching': 8665, 'Sybil': 8666, 'sybil account': 8667, 'Sybils': 8668, 'syllable': 8669, 'syllable segmentation': 8670, 'Symbolic': 8671, 'symbolically': 8672, 'symbolized': 8673, 'symbols': 8674, 'symptoms': 8675, 'synapses': 8676, 'Synchronization': 8677, 'synchronization': 8678, 'synchronized': 8679, 'synchronous': 8680, 'Synchronous': 8681, 'synergistic': 8682, 'synergy': 8683, 'syntactics': 8684, 'syntax': 8685, 'Syntax': 8686, 'synthesisers': 8687, 'Synthetic': 8688, 'synthetic': 8689, 'synthetic oversampling': 8690, 'synthetization': 8691, 'Synthetizing': 8692, 'system': 8693, 'System': 8694, 'system-level testing': 8695, 'systematic': 8696, 'systematically': 8697, 'Systems': 8698, 'systems': 8699, 'systems biology': 8700, 't': 8701, 'T': 8702, 'tables': 8703, 'tablet': 8704, 'tackle': 8705, 'tackled': 8706, 'tag': 8707, 'tagging': 8708, 'tags': 8709, 'tail': 8710, 'tailored': 8711, 'take': 8712, 'taken': 8713, 'takes': 8714, 'taking': 8715, 'talker': 8716, 'talking': 8717, 'taller': 8718, 'tampering': 8719, 'tan': 8720, 'tangent bundle manifold learning': 8721, 'tapes': 8722, 'target': 8723, 'target detection': 8724, 'target tracking': 8725, 'targeted': 8726, 'targeting': 8727, 'tariff': 8728, 'Tariff': 8729, 'task': 8730, 'Task': 8731, 'tasking': 8732, 'Tasks': 8733, 'tasks': 8734, 'taxonomic': 8735, 'taxonomical': 8736, 'taxonomy': 8737, 'TCGA': 8738, 'TCP': 8739, 'tcp/ip model': 8740, 'TD': 8741, 'teach': 8742, 'teachers': 8743, 'teaches': 8744, 'teaching': 8745, 'team': 8746, 'Team': 8747, 'teams': 8748, 'tear': 8749, 'tech': 8750, 'technical': 8751, 'technicians': 8752, 'Technique': 8753, 'technique': 8754, 'Techniques': 8755, 'techniques': 8756, 'technological': 8757, 'technologies': 8758, 'technology': 8759, 'Technology': 8760, 'tecture': 8761, 'tedious': 8762, 'teeth': 8763, 'telecommunication': 8764, 'tells': 8765, 'Temperature': 8766, 'temperature': 8767, 'temperature measurement': 8768, 'temperatures': 8769, 'template': 8770, 'template matching': 8771, 'template-security': 8772, 'Temporal': 8773, 'temporal': 8774, 'temporal pattern': 8775, 'temporal segmentation': 8776, 'temporally': 8777, 'Temporally': 8778, 'temporary': 8779, 'ten': 8780, 'tend': 8781, 'tended': 8782, 'tendencies': 8783, 'tends': 8784, 'tenfold': 8785, 'Tennis': 8786, 'tennis': 8787, 'TennisTraq': 8788, 'term': 8789, 'Term': 8790, 'termed': 8791, 'terminal': 8792, 'terminology': 8793, 'terms': 8794, 'territory': 8795, 'tertiary': 8796, 'TEs': 8797, 'test': 8798, 'TEST': 8799, 'Test': 8800, 'test case prioritization': 8801, 'test code size': 8802, 'testability': 8803, 'testbed': 8804, 'tested': 8805, 'testing': 8806, 'Tests': 8807, 'tests': 8808, 'text': 8809, 'Text': 8810, 'text analysis': 8811, 'text categorization': 8812, 'text mining': 8813, 'text similarity': 8814, 'text summarization': 8815, 'texts': 8816, 'textual': 8817, 'TFBS': 8818, 'th': 8819, 'thalassemia': 8820, 'than': 8821, 'thanks': 8822, 'That': 8823, 'that': 8824, 'The': 8825, 'the': 8826, 'the lasso estimate': 8827, 'theft': 8828, 'their': 8829, 'Their': 8830, 'them': 8831, 'theme': 8832, 'themselves': 8833, 'then': 8834, 'Then': 8835, 'theorem': 8836, 'theoretic': 8837, 'theoretical': 8838, 'Theoretical': 8839, 'theoretically': 8840, 'theories': 8841, 'theory': 8842, 'Theory': 8843, 'therapeutic': 8844, 'therapy': 8845, 'there': 8846, 'There': 8847, 'thereby': 8848, 'Therefore': 8849, 'therefore': 8850, 'thereof': 8851, 'thermal': 8852, 'These': 8853, 'these': 8854, 'thesis': 8855, 'they': 8856, 'They': 8857, 'thin': 8858, 'Thin': 8859, 'thin film flow equation': 8860, 'Things': 8861, 'things': 8862, 'thinking': 8863, 'Third': 8864, 'third': 8865, 'This': 8866, 'this': 8867, 'Thompson': 8868, 'Thoracolumbosacral': 8869, 'thorough': 8870, 'thoroughly': 8871, 'those': 8872, 'Though': 8873, 'though': 8874, 'thought': 8875, 'thousands': 8876, 'thread': 8877, 'threat': 8878, 'Threat': 8879, 'threaten': 8880, 'threatened': 8881, 'threatening': 8882, 'threats': 8883, 'Three': 8884, 'three': 8885, 'threefold': 8886, 'threshold': 8887, 'Threshold': 8888, 'thresholding': 8889, 'Thresholding': 8890, 'thresholds': 8891, 'thriving': 8892, 'Through': 8893, 'through': 8894, 'throughout': 8895, 'throw': 8896, 'thus': 8897, 'Thus': 8898, 'Thyme': 8899, 'tial': 8900, 'tightness': 8901, 'time': 8902, 'Time': 8903, 'time series': 8904, 'time series analysis': 8905, 'time series classification': 8906, 'time series clustering': 8907, 'time series forecasting': 8908, 'time series prediction': 8909, 'time series representation': 8910, 'time-frequency analysis': 8911, 'time-series analysis': 8912, 'time-series data': 8913, 'time-varying impact': 8914, 'timed': 8915, 'timeframes': 8916, 'Timeline': 8917, 'timeline': 8918, 'timely': 8919, 'times': 8920, 'timescales': 8921, 'timeseries': 8922, 'timestamped': 8923, 'timestamping': 8924, 'timestamps': 8925, 'timetabling': 8926, 'timing': 8927, 'Timing': 8928, 'TIMIT': 8929, 'Tissue': 8930, 'tissue': 8931, 'TLSO': 8932, 'To': 8933, 'to': 8934, 'today': 8935, 'Together': 8936, 'together': 8937, 'toll': 8938, 'Tomography': 8939, 'tomography': 8940, 'tomorrow': 8941, 'too': 8942, 'took': 8943, 'Tool': 8944, 'tool': 8945, 'Tools': 8946, 'tools': 8947, 'top': 8948, 'Top': 8949, 'topic': 8950, 'Topic': 8951, 'topic detection': 8952, 'topic model': 8953, 'topic model labeling': 8954, 'topic modeling': 8955, 'topic models': 8956, 'topic novelty detection': 8957, 'topic-semantic indexing (tsi)': 8958, 'topical': 8959, 'topical ontology': 8960, 'topics': 8961, 'topmost': 8962, 'topological': 8963, 'Topologically': 8964, 'topologies': 8965, 'Topology': 8966, 'topology': 8967, 'topology mamagement': 8968, 'Toponogov': 8969, 'total': 8970, 'Touchless': 8971, 'TourMiner': 8972, 'tours': 8973, 'toward': 8974, 'Toward': 8975, 'towards': 8976, 'Towards': 8977, 'TPU': 8978, 'trace': 8979, 'traces': 8980, 'Track': 8981, 'track': 8982, 'tracked': 8983, 'Tracker': 8984, 'tracker': 8985, 'trackers': 8986, 'tracking': 8987, 'trackIng': 8988, 'Tracking': 8989, 'tracks': 8990, 'TRACLUS': 8991, 'traclus clustering': 8992, 'tractable': 8993, 'TRACULUS': 8994, 'trade': 8995, 'tradeoff': 8996, 'trading': 8997, 'Trading': 8998, 'Traditional': 8999, 'traditional': 9000, 'traditional machine learning': 9001, 'Traditionally': 9002, 'traditionally': 9003, 'Traffic': 9004, 'traffic': 9005, 'traffic flow prediciton': 9006, 'traffic flow prediction': 9007, 'traffic prediction': 9008, 'Train': 9009, 'train': 9010, 'trained': 9011, 'training': 9012, 'Training': 9013, 'training data': 9014, 'training simulations': 9015, 'training speed': 9016, 'training with noisy data': 9017, 'trains': 9018, 'trait': 9019, 'traits': 9020, 'trajectories': 9021, 'Trajectories': 9022, 'Trajectory': 9023, 'trajectory': 9024, 'trajectory analysis': 9025, 'trajectory planning in road traffic': 9026, 'transaction': 9027, 'transactional': 9028, 'transactions': 9029, 'transcribe': 9030, 'Transcription': 9031, 'transcription': 9032, 'Transductive': 9033, 'transductive': 9034, 'transductive learning': 9035, 'Transfer': 9036, 'transfer': 9037, 'transfer learning': 9038, 'transferable': 9039, 'transferred': 9040, 'transferring': 9041, 'Transform': 9042, 'transform': 9043, 'transformation': 9044, 'transformations': 9045, 'transformed': 9046, 'transformer': 9047, 'Transformer': 9048, 'transforming': 9049, 'transforms': 9050, 'transfusion': 9051, 'transient': 9052, 'Transient': 9053, 'transit': 9054, 'transition': 9055, 'transitions': 9056, 'translate': 9057, 'translated': 9058, 'translating': 9059, 'translation': 9060, 'Transmission': 9061, 'transmission': 9062, 'transmit': 9063, 'transmitted': 9064, 'transmitters': 9065, 'transparency': 9066, 'transparent': 9067, 'Transplant': 9068, 'transport': 9069, 'transportation': 9070, 'Transposable': 9071, 'travel': 9072, 'TRCM': 9073, 'treasure': 9074, 'treat': 9075, 'treated': 9076, 'Treating': 9077, 'treating': 9078, 'Treatment': 9079, 'treatment': 9080, 'treats': 9081, 'tree': 9082, 'Tree': 9083, 'trees': 9084, 'Trees': 9085, 'Trend': 9086, 'trend': 9087, 'trend prediction': 9088, 'Trends': 9089, 'trends': 9090, 'trial': 9091, 'trials': 9092, 'triangles': 9093, 'triaxial': 9094, 'trick': 9095, 'tried': 9096, 'tries': 9097, 'trigger': 9098, 'triggers': 9099, 'trimmed': 9100, 'trips': 9101, 'trivial': 9102, 'troublesome': 9103, 'true': 9104, 'Trunk': 9105, 'trusted': 9106, 'truth': 9107, 'truthful': 9108, 'truthfulness': 9109, 'truths': 9110, 'try': 9111, 'trying': 9112, 'TSD': 9113, 'TSI': 9114, 'tsvm': 9115, 'TubeSpam': 9116, 'tumour': 9117, 'tuned': 9118, 'Tuning': 9119, 'tuning': 9120, 'tuning curve': 9121, 'turbidity': 9122, 'turbine': 9123, 'Turbine': 9124, 'Turbines': 9125, 'turbines': 9126, 'turbulence': 9127, 'Turbulence': 9128, 'turbulence modeling': 9129, 'turbulent': 9130, 'Turing': 9131, 'Turkey': 9132, 'Turkish': 9133, 'turkish ner': 9134, 'turkish universities': 9135, 'turn': 9136, 'turning': 9137, 'turns': 9138, 'tutability': 9139, 'tutorials': 9140, 'Tutoring': 9141, 'TV': 9142, 'tweet': 9143, 'Tweet': 9144, 'tweet mining': 9145, 'Tweets': 9146, 'tweets': 9147, 'twenty': 9148, 'Twin': 9149, 'twin': 9150, 'twitter': 9151, 'Twitter': 9152, 'Two': 9153, 'two': 9154, 'two-sided markets': 9155, 'twovalued': 9156, 'Type': 9157, 'type': 9158, 'types': 9159, 'Types': 9160, 'typical': 9161, 'Typical': 9162, 'typically': 9163, 'Typically': 9164, 'U': 9165, 'ubiquitous': 9166, 'ubiquitous monitoring': 9167, 'UCB1': 9168, 'UCF50': 9169, 'UCI': 9170, 'UCP': 9171, 'UCR': 9172, 'UK': 9173, 'UK2006': 9174, 'UK2007': 9175, 'Ukraine': 9176, 'ultimate': 9177, 'ultimately': 9178, 'Ultra': 9179, 'ultra': 9180, 'ultra-wide band radar': 9181, 'UMTS': 9182, 'un': 9183, 'unable': 9184, 'unaffected': 9185, 'unavailability': 9186, 'unavailable': 9187, 'unavoidable': 9188, 'unaware': 9189, 'Unbalanced': 9190, 'unbalanced': 9191, 'unbalanced data': 9192, 'unbiased': 9193, 'uncertain': 9194, 'uncertain labels': 9195, 'uncertainties': 9196, 'uncertainty': 9197, 'Uncertainty': 9198, 'uncertainty quantification': 9199, 'unclear': 9200, 'unconventional': 9201, 'uncoupled': 9202, 'uncover': 9203, 'under': 9204, 'Under': 9205, 'undergoes': 9206, 'undergraduate': 9207, 'underlying': 9208, 'underpinning': 9209, 'Understading': 9210, 'understand': 9211, 'Understand': 9212, 'Understanding': 9213, 'understanding': 9214, 'understood': 9215, 'undertaken': 9216, 'underused': 9217, 'underwater': 9218, 'undesirable': 9219, 'unequal': 9220, 'unexpected': 9221, 'Unexpected': 9222, 'unexpectedly': 9223, 'unfamiliar': 9224, 'unfavorable': 9225, 'Unfortunately': 9226, 'uni': 9227, 'unicellular': 9228, 'Unification': 9229, 'unifies': 9230, 'uniformly': 9231, 'unifying': 9232, 'uninterrupted': 9233, 'Union': 9234, 'union of intersections': 9235, 'Unique': 9236, 'unique': 9237, 'uniqueness': 9238, 'Unit': 9239, 'unit': 9240, 'units': 9241, 'Units': 9242, 'univariate': 9243, 'Univariate': 9244, 'universal': 9245, 'universality': 9246, 'Universities': 9247, 'universities': 9248, 'university': 9249, 'University': 9250, 'unknown': 9251, 'Unlabeled': 9252, 'unlabeled': 9253, 'unlabelled': 9254, 'unlike': 9255, 'Unlike': 9256, 'unordered': 9257, 'unpleasant': 9258, 'unpractical': 9259, 'unprecedented': 9260, 'unrealistic': 9261, 'unregistered': 9262, 'unreliable': 9263, 'unscheduled': 9264, 'unseen': 9265, 'unsolicited electronic mail': 9266, 'unsolved': 9267, 'unstructured': 9268, 'unsubscribe': 9269, 'Unsupervised': 9270, 'unsupervised': 9271, 'unsupervised clustering': 9272, 'unsupervised feature learning': 9273, 'unsupervised learning': 9274, 'unsupervised machine learning': 9275, 'unsupervised-learning': 9276, 'until': 9277, 'Until': 9278, 'untruthful': 9279, 'unvetted': 9280, 'unwanted': 9281, 'unwavering': 9282, 'UoI': 9283, 'up': 9284, 'Up': 9285, 'update': 9286, 'Update': 9287, 'updated': 9288, 'updates': 9289, 'updating': 9290, 'uploaded': 9291, 'uploading': 9292, 'upon': 9293, 'upper': 9294, 'upper bound': 9295, 'upright': 9296, 'upstairs': 9297, 'URAP': 9298, 'urap rankings': 9299, 'urban': 9300, 'Urbansound8k': 9301, 'urgent': 9302, 'UrSGP': 9303, 'us': 9304, 'US': 9305, 'USA': 9306, 'usability': 9307, 'usable': 9308, 'Usage': 9309, 'usage': 9310, 'usages': 9311, 'Use': 9312, 'use': 9313, 'Used': 9314, 'used': 9315, 'Useful': 9316, 'useful': 9317, 'usefulness': 9318, 'useless': 9319, 'Useless': 9320, 'useless words': 9321, 'User': 9322, 'user': 9323, 'user modeling': 9324, 'user profiles': 9325, 'users': 9326, 'Users': 9327, 'uses': 9328, 'Using': 9329, 'using': 9330, 'USP': 9331, 'Usual': 9332, 'usual': 9333, 'usually': 9334, 'Usually': 9335, 'utilise': 9336, 'utilities': 9337, 'utility': 9338, 'utilization': 9339, 'utilize': 9340, 'utilized': 9341, 'utilizes': 9342, 'utilizing': 9343, 'Utilizing': 9344, 'utmost': 9345, 'UWB': 9346, 'v': 9347, 'valid': 9348, 'validate': 9349, 'validated': 9350, 'validating': 9351, 'Validation': 9352, 'validation': 9353, 'validity': 9354, 'valuable': 9355, 'value': 9356, 'Value': 9357, 'valued': 9358, 'Valued': 9359, 'values': 9360, 'valves': 9361, 'Vancouver': 9362, 'variability': 9363, 'Variable': 9364, 'variable': 9365, 'variable selection': 9366, 'variables': 9367, 'Variance': 9368, 'variance': 9369, 'variance inflation factor': 9370, 'variance of query response': 9371, 'variant': 9372, 'variants': 9373, 'variation': 9374, 'variational': 9375, 'Variational': 9376, 'variational bayes': 9377, 'variational em': 9378, 'variational inference': 9379, 'variations': 9380, 'Variations': 9381, 'varied': 9382, 'varies': 9383, 'variety': 9384, 'Various': 9385, 'various': 9386, 'variously': 9387, 'vary': 9388, 'varying': 9389, 'Varying': 9390, 'varying coefficient model': 9391, 'vascularization': 9392, 'vast': 9393, 'VC': 9394, 'VCPSs': 9395, 'Vdeo': 9396, 've': 9397, 'Vector': 9398, 'vector': 9399, 'vectors': 9400, 'Vectors': 9401, 'vegetation': 9402, 'vehicle': 9403, 'Vehicle': 9404, 'vehicles': 9405, 'Vehicular': 9406, 'vehicular': 9407, 'vehicular cyber-physical systems': 9408, 'velocity': 9409, 'vendor': 9410, 'Ventilation': 9411, 'ventilation': 9412, 'veracity': 9413, 'verbal': 9414, 'Verification': 9415, 'verified': 9416, 'verifies': 9417, 'verify': 9418, 'version': 9419, 'versions': 9420, 'Versus': 9421, 'versus': 9422, 'Vertical': 9423, 'vertical': 9424, 'vertical handoff (vho)': 9425, 'vertical scaling': 9426, 'vertices': 9427, 'very': 9428, 'Very': 9429, 'vetting': 9430, 'Vgg': 9431, 'VGG': 9432, 'VHO': 9433, 'via': 9434, 'victim': 9435, 'victims': 9436, 'Victoria': 9437, 'Video': 9438, 'video': 9439, 'video event': 9440, 'video indexing': 9441, 'video steganography': 9442, 'video understanding': 9443, 'videos': 9444, 'view': 9445, 'viewed': 9446, 'viewing': 9447, 'viewpoint': 9448, 'views': 9449, 'VIF': 9450, 'violated': 9451, 'violating': 9452, 'violations': 9453, 'violent': 9454, 'VIRAT': 9455, 'virtual': 9456, 'Virtual': 9457, 'virtual world': 9458, 'virtually': 9459, 'virus': 9460, 'viruses': 9461, 'viscous': 9462, 'viscous reconstruction': 9463, 'visibility': 9464, 'visible': 9465, 'visibly': 9466, 'vision': 9467, 'Vision': 9468, 'visitors': 9469, 'visual': 9470, 'Visual': 9471, 'visual classification': 9472, 'visual inspection': 9473, 'visualise': 9474, 'Visualising': 9475, 'visualising': 9476, 'visualization': 9477, 'visually': 9478, 'vital': 9479, 'viz': 9480, 'VLP': 9481, 'VOC': 9482, 'vocal': 9483, 'vocalist': 9484, 'vocalists': 9485, 'vocalizations': 9486, 'Voice': 9487, 'voice': 9488, 'voiceprint': 9489, 'Voiceprint': 9490, 'volatile': 9491, 'volatility': 9492, 'voltage': 9493, 'Voltage': 9494, 'volume': 9495, 'volumes': 9496, 'voluminous': 9497, 'volunteers': 9498, 'von': 9499, 'von mises distribution': 9500, 'VOR': 9501, 'Vote': 9502, 'vote': 9503, 'votes': 9504, 'voting': 9505, 'vs': 9506, 'vulnerabilities': 9507, 'vulnerability': 9508, 'vulnerable': 9509, 'Vulnerable': 9510, 'W': 9511, 'waikato environment for knowledge analysis (weka)': 9512, 'walk': 9513, 'walking': 9514, 'WannaCry': 9515, 'want': 9516, 'war': 9517, 'warehouse': 9518, 'warm': 9519, 'warming': 9520, 'Warning': 9521, 'warning': 9522, 'warns': 9523, 'warping': 9524, 'Warping': 9525, 'was': 9526, 'Washington': 9527, 'waste': 9528, 'wasting': 9529, 'water': 9530, 'Water': 9531, 'Watershed': 9532, 'Watson': 9533, 'wave': 9534, 'wavelengths': 9535, 'Wavelet': 9536, 'wavelet': 9537, 'wavelet analysis': 9538, 'wavelet coefficients': 9539, 'Wavelets': 9540, 'waves': 9541, 'way': 9542, 'ways': 9543, 'wban security': 9544, 'WBANs': 9545, 'WCDN': 9546, 'WCDNs': 9547, 'WE': 9548, 'we': 9549, 'We': 9550, 'weak': 9551, 'weakly supervised learning': 9552, 'weaknesses': 9553, 'weapon': 9554, 'wear': 9555, 'wearable': 9556, 'Wearable': 9557, 'wearable sensors': 9558, 'wearables': 9559, 'Weather': 9560, 'weather': 9561, 'weather forecasting': 9562, 'web': 9563, 'Web': 9564, 'web application': 9565, 'web based games': 9566, 'web based information sources': 9567, 'web caching': 9568, 'web robots': 9569, 'web scraping': 9570, 'web servers': 9571, 'web spam': 9572, 'website': 9573, 'websites': 9574, 'WEBSPAM': 9575, 'weed': 9576, 'weekly': 9577, 'weeks': 9578, 'weighed': 9579, 'weight': 9580, 'Weight': 9581, 'weight convergence and robust stability': 9582, 'weighted': 9583, 'Weighted': 9584, 'weighting': 9585, 'weights': 9586, 'WEKA': 9587, 'weka': 9588, 'Welch': 9589, 'well': 9590, 'wellknown': 9591, 'were': 9592, 'wet': 9593, 'WH': 9594, 'what': 9595, 'What': 9596, 'whatever': 9597, 'wheel': 9598, 'Wheel': 9599, 'wheel alignment': 9600, 'wheeze': 9601, 'Wheezing': 9602, 'when': 9603, 'When': 9604, 'whenever': 9605, 'where': 9606, 'whereas': 9607, 'whereby': 9608, 'whether': 9609, 'Whether': 9610, 'Which': 9611, 'which': 9612, 'While': 9613, 'while': 9614, 'Whilst': 9615, 'white': 9616, 'who': 9617, 'whole': 9618, 'whose': 9619, 'why': 9620, 'wide': 9621, 'Wide': 9622, 'widely': 9623, 'widespread': 9624, 'width': 9625, 'widths': 9626, 'wifi': 9627, 'WiFi': 9628, 'wifi csi data mining': 9629, 'wifi slam': 9630, 'Wilcoxon': 9631, 'wild': 9632, 'wildlife': 9633, 'will': 9634, 'Wilsons': 9635, 'wind': 9636, 'Wind': 9637, 'wind power forecasting': 9638, 'wind power plant': 9639, 'wind speed': 9640, 'wind turbine': 9641, 'winding': 9642, 'Windings': 9643, 'window': 9644, 'windows': 9645, 'winner': 9646, 'winning': 9647, 'winter': 9648, 'wire': 9649, 'Wireless': 9650, 'wireless': 9651, 'wireless communication': 9652, 'wireless sensor network (wsn)': 9653, 'wireless sensor networks (wsns)': 9654, 'With': 9655, 'with': 9656, 'Within': 9657, 'within': 9658, 'Without': 9659, 'without': 9660, 'witnessed': 9661, 'WMA': 9662, 'Women': 9663, 'women': 9664, 'Word': 9665, 'word': 9666, 'word embedding': 9667, 'word embeddings': 9668, 'word vectors': 9669, 'words': 9670, 'Words': 9671, 'Work': 9672, 'work': 9673, 'worked': 9674, 'workers': 9675, 'working': 9676, 'workload': 9677, 'workload characterization': 9678, 'workloads': 9679, 'Workloads': 9680, 'works': 9681, 'World': 9682, 'world': 9683, 'worlds': 9684, 'worldwide': 9685, 'worn': 9686, 'worse': 9687, 'worst': 9688, 'worth': 9689, 'worthwhile': 9690, 'would': 9691, 'Wrapped': 9692, 'wrapper': 9693, 'Wrapper': 9694, 'wrist': 9695, 'writing': 9696, 'written': 9697, 'wrong': 9698, 'wrote': 9699, 'WSN': 9700, 'WSNs': 9701, 'www': 9702, 'Wyoming': 9703, 'x': 9704, 'X': 9705, 'XGBoost': 9706, 'xgboost': 9707, 'XOR': 9708, 'xray': 9709, 'Yale': 9710, 'year': 9711, 'yearly': 9712, 'years': 9713, 'yet': 9714, 'Yet': 9715, 'yield': 9716, 'yielded': 9717, 'yielding': 9718, 'yields': 9719, 'YorNoise': 9720, 'your': 9721, 'YouTube': 9722, 'Youtube': 9723, 'youtube': 9724, 'zero': 9725, 'Zero': 9726, 'zero-shot learning': 9727, 'Zirkler': 9728}\n",
      "9729\n"
     ]
    }
   ],
   "source": [
    "# * FASE 1.1 Creamos el diccionario\n",
    "diccionarioLengua = dict()\n",
    "'''\n",
    "word_index = {word: (index + 3) for word, index in word_index.items()} \n",
    "word_index['<PAD>'] = 0  # Para padding\n",
    "word_index['<SOS>'] = 1  # Para comienzo de sentencia\n",
    "word_index['<UNK>'] = 2  # Para valores desconocidos\n",
    "word_index['<UNU>'] = 3  # Para valores que no se usan\n",
    "'''\n",
    "\n",
    "diccionarioLengua[\"<UNU>\"] = 0 # Establecemos el primero como valor vacio\n",
    "diccionarioLengua[\"EsteValorEstaMuyDesconocido\"] = 1 # Establecemos el segundo como valor desconocido\n",
    "for i in range(0, len(res)):\n",
    "    diccionarioLengua[res[i]] = i+2\n",
    "\n",
    "print(diccionarioLengua)\n",
    "print(len(diccionarioLengua))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6ad3aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EsteValorEstaMuyDesconocido': 0, '2-dim distance measure': 1, '2d:4d': 2, '3d shapes': 3, '3d-convnets': 4, 'abnormal event detection': 5, 'academic success': 6, 'accelerometer': 7, 'accelerometer data': 8, 'accelerometers': 9, 'accreditation and assesments': 10, 'accuracy': 11, 'achievements information': 12, 'acoustic feature learning': 13, 'action bank features': 14, 'activation function': 15, 'active contour method': 16, 'active learning': 17, 'active set shrinking': 18, 'activity detection': 19, 'activity forecasting': 20, 'activity recognition': 21, 'adaptation method': 22, 'adaptation models': 23, 'adaptive approaches': 24, 'adaptive learning': 25, 'adaptive scheduling': 26, 'adaptive threshold': 27, 'adenoviral conjunctivitis (pink eye)': 28, 'adversarial machine learning': 29, 'afis': 30, 'age': 31, 'aggregated netflows': 32, 'aggression': 33, 'agriculture': 34, 'air combat': 35, 'algorithm': 36, 'algorithm design and analysis': 37, 'algorithm recognition': 38, 'algorithm selection': 39, \"alzheimer's disease\": 40, \"alzheimer's disease stage detection\": 41, 'american sign language': 42, 'anaemia': 43, 'anchored synchronization': 44, 'android': 45, 'anns': 46, 'anomaly': 47, 'anomaly detection': 48, 'anomaly prediction': 49, 'anonymity': 50, 'anonymization': 51, 'ant colony optimization': 52, 'anytime algorithm': 53, 'ap imashups': 54, 'appearance-based learning': 55, 'application': 56, 'application essay': 57, 'application layer ddos': 58, 'applications': 59, 'approximate computing': 60, 'approximate inference': 61, 'approximation algorithms': 62, 'approximation methods': 63, 'arctic sea ice': 64, 'arima': 65, 'arma': 66, 'artifial neural network model': 67, 'artificial defects': 68, 'artificial intelligence': 69, 'artificial neural network': 70, 'artificial neural network (ann)': 71, 'artificial neural networks': 72, 'artificial-neural-network': 73, 'association map': 74, 'association rules': 75, 'associative classification': 76, 'associative memory': 77, 'attack': 78, 'attacks': 79, 'audio': 80, 'audio captcha': 81, 'audio equalizer': 82, 'audio signal': 83, 'audiogram': 84, 'authentication': 85, 'authentication graphs': 86, 'author classification': 87, 'autism spectrum disorder': 88, 'autocorrelation-function-(acf)': 89, 'autoencoder': 90, 'autoencoders': 91, 'automated classification': 92, 'automatic': 93, 'automatic diagnosis': 94, 'automatic gender estimation': 95, 'automatic scoring': 96, 'automatic speech recognition': 97, 'automation': 98, 'automobiles': 99, 'automotive security': 100, 'autoregressive processes': 101, 'auxiliary objectives': 102, 'availability': 103, 'back-propagation-algorithm': 104, 'backpropagation': 105, 'badminton': 106, 'bag-of-concepts': 107, 'bag-of-pattern': 108, 'bagging': 109, 'balanced k-means': 110, 'ballistocardiogram artifact': 111, 'bandwidth': 112, 'bartlett tests': 113, 'base station (bs)': 114, 'basis selection': 115, 'batteries': 116, 'bayes classifier': 117, 'bayes methods': 118, 'bayesian': 119, 'bayesian analysis': 120, 'bayesian classification': 121, 'bayesian inference': 122, 'bayesian network': 123, 'bayesian networks': 124, 'bayesian nonparametrics': 125, 'bayesian-networks': 126, 'bearing defects': 127, 'benchmarks': 128, 'best subset linear regression': 129, 'bifurcation': 130, 'big data': 131, 'big data analytics': 132, 'big data clustering': 133, 'big healthcare data': 134, 'big mobile social data': 135, 'big-data': 136, 'bilateral filter': 137, 'binary classification': 138, 'binary codes': 139, 'bio-acoustics': 140, 'bio-detection': 141, 'bioinformatics': 142, 'biological neural networks': 143, 'biological system modeling': 144, 'biomarker': 145, 'biomedical informatics': 146, 'biometric': 147, 'biometric recognition': 148, 'biometrics': 149, 'bipartite graphs': 150, 'bipartite ranking problem': 151, 'bird call identification': 152, 'bitcoin': 153, 'black-box testing': 154, 'blind source seperation': 155, 'blockchain': 156, 'blog spam': 157, 'blogs': 158, 'blunder': 159, 'boolean networks': 160, 'boosting': 161, 'bootstrap': 162, 'bootstrap approaches': 163, 'boundary value problems': 164, 'box office': 165, 'brace treatment': 166, 'brain': 167, 'brain computer interface': 168, 'brand perception': 169, 'breaking news': 170, 'breast cancer': 171, 'brute force': 172, 'budgeted learning': 173, 'buildings': 174, 'bus transportation': 175, 'business': 176, 'c++ languages': 177, 'cameras': 178, 'can bus': 179, 'canal command': 180, 'cancer': 181, 'cancer detection': 182, 'canonical correlation analysis': 183, 'canopy algorithm': 184, 'car following model': 185, 'careerbuilder': 186, 'cascaded sparse autoencoders': 187, 'cascading style sheets': 188, 'case management': 189, 'case-based reasoning': 190, 'causal discovery': 191, 'cell images': 192, 'cepstral coefficients': 193, 'cfrp': 194, 'cgp': 195, 'cgpann': 196, 'challenging behaviors': 197, 'chess': 198, 'child support': 199, 'choice': 200, 'chord': 201, 'churn prediction': 202, 'class decomposition': 203, 'class imbalance': 204, 'classification': 205, 'classification algorithms': 206, 'classification techniques': 207, 'classifier ensemble': 208, 'climate': 209, 'climate science': 210, 'clnn': 211, 'clo': 212, 'clone refactoring': 213, 'cloud computing': 214, 'cloud data security': 215, 'cloud-oriented architecture': 216, 'cluster analysis': 217, 'cluster data': 218, 'cluster forest': 219, 'cluster head (ch)': 220, 'cluster size distribution': 221, 'cluster validation': 222, 'cluster validity': 223, 'clustering': 224, 'clustering algorithms': 225, 'cm-knn': 226, 'cma-es': 227, 'cnn': 228, 'cold-start problem': 229, 'collaboration': 230, 'collaboration network': 231, 'collaborative filtering': 232, 'collaborative learning': 233, 'collaborative recommendation': 234, 'collector apis': 235, 'colorization': 236, 'coloured petri nets': 237, 'combination forgery': 238, 'combinatorial optimization': 239, 'combinatorial reverse auctions': 240, 'comment features': 241, 'comment spam detection': 242, 'common metric learning': 243, 'compactness measure of clusters': 244, 'companies': 245, 'comparative market analysis': 246, 'comparative study': 247, 'completeness': 248, 'complex event programming': 249, 'complexity reduction': 250, 'component based design petri nets': 251, 'compounds': 252, 'compression algorithms': 253, 'computational modeling': 254, 'computer crime': 255, 'computer generated forces': 256, 'computer science': 257, 'computer vision': 258, 'computer-aided detection (cad)': 259, 'computer-aided diagnosis': 260, 'computers': 261, 'conditional neural networks': 262, 'conditional restricted boltzmann machine': 263, 'conferences': 264, 'confidence region': 265, 'conformal prediction': 266, 'conformation motion': 267, 'confusion matrix': 268, 'connected vehicles': 269, 'constraint programming': 270, 'constraint satisfaction problem': 271, 'content caching': 272, 'content spam': 273, 'context': 274, 'context aware': 275, 'contextual similarity': 276, 'contour recognition': 277, 'contour representations': 278, 'control': 279, 'control period computational burden': 280, 'control system': 281, 'control systems': 282, 'convergence': 283, 'convolution filtering': 284, 'convolutional neural nets': 285, 'convolutional neural network': 286, 'convolutional neural networks': 287, 'convolutional neural networks (cnn)': 288, 'convolutional neural networks (cnns)': 289, 'cooperative adaptive cruise control': 290, 'cooperative systems': 291, 'coordinate descent': 292, 'coreference': 293, 'correlation': 294, 'cost sensitive classification': 295, 'cost-sensitive learning': 296, 'counters': 297, 'covariance matrix': 298, 'cpd': 299, 'crbm': 300, 'credit default swap': 301, 'credit scoring': 302, 'crime prediction': 303, 'cross lingual': 304, 'cross-validation': 305, 'crowd-sourcing': 306, 'crowdsourcing': 307, 'crude oil price forecasting': 308, 'cruise control': 309, 'ct images': 310, 'ct prediction': 311, 'curve simplification': 312, 'cwt': 313, 'cyber forensic': 314, 'cyber security': 315, 'cyber-security vulnerabilities': 316, 'cyberattack': 317, 'cybersecurity': 318, 'cybersecurity applications': 319, 'cyclic contrastive divergence learning': 320, 'cytoskeleton': 321, 'czech ner': 322, 'data analysis': 323, 'data analytics': 324, 'data augmentation': 325, 'data clustering': 326, 'data contamination': 327, 'data diversity': 328, 'data integration': 329, 'data mining': 330, 'data models': 331, 'data modification intrusion detection': 332, 'data privacy': 333, 'data stream': 334, 'data stream with concept drift': 335, 'data warehouse': 336, 'data-acquisition': 337, 'data-driven': 338, 'databases': 339, 'dbn': 340, 'dbpedia ontology': 341, 'dc-dc converter': 342, 'dc/dc-boost-converter': 343, 'dct': 344, 'decision making': 345, 'decision support': 346, 'decision support system': 347, 'decision tree': 348, 'decision trees': 349, 'declarative learning': 350, 'decomposition-based reinforcement learning': 351, 'deconvolutional networks (deconvnet)': 352, 'decorrelation': 353, 'deep convolutional network': 354, 'deep learning': 355, 'deep neural network': 356, 'deep neural networks': 357, 'deep regression model': 358, 'deep reinforcement learning': 359, 'dehazing': 360, 'delay': 361, 'delayed labels': 362, 'demand forecast': 363, 'demographic group prediction': 364, 'denial-of-service (dos)': 365, 'depressive disorders': 366, 'dh-hemts': 367, 'diabetes': 368, 'diagnosabiliy': 369, 'dimensional reduction': 370, 'dimensionality reduction': 371, 'dirichlet process': 372, 'disaggregation': 373, 'discourse': 374, 'discrete cosine transforms': 375, 'discrete event systems': 376, 'discrete fourier': 377, 'discrete-event systems': 378, 'discretization': 379, 'discretize': 380, 'diseases': 381, 'distinctness measure of clusters': 382, 'distributed computing': 383, 'distributed data clustering': 384, 'distributed sgd': 385, 'distributed simulation': 386, 'divisive analysis': 387, 'dnn': 388, 'document classification': 389, 'documentation': 390, 'domain class imbalance': 391, 'domain knowledge': 392, 'domestic hot water': 393, 'donor selection': 394, 'dos attack': 395, 'driver behavior': 396, 'drives': 397, 'drop out technique': 398, 'drought modelling': 399, 'drug-design': 400, 'dwt': 401, 'dynamic clustering': 402, 'dynamic factor analysis': 403, 'dynamic kernels': 404, 'dynamic programming': 405, 'dynamic system': 406, 'dynamic web domain': 407, 'dynamical systems': 408, 'e-commerce': 409, 'ea+rl': 410, 'earth levee': 411, 'ecg': 412, 'education': 413, 'educational analytics': 414, 'educational data mining': 415, 'educational data mining (edm)': 416, 'educational institutions': 417, 'eeg signals': 418, 'eembedding payload': 419, 'effective sample size': 420, 'efficiency': 421, 'effort prediction': 422, 'eigenfaces': 423, 'eigenvalues': 424, 'eigenvector': 425, 'electrical engineering': 426, 'electricity market': 427, 'electricity retail markets': 428, 'electrocardiography': 429, 'electroencephalogram': 430, 'electronic mail': 431, 'embedded methods': 432, 'embedding efficiency': 433, 'empirical mode decomposition': 434, 'encryption': 435, 'energy end-use model': 436, 'energy management': 437, 'energy saving': 438, 'engagement detection': 439, 'ensemble': 440, 'ensemble clustering': 441, 'ensemble learning': 442, 'ensemble method': 443, 'ensemble methods': 444, 'ensembles': 445, 'entity extraction': 446, 'environmental sound recognition': 447, 'epilepsy': 448, 'epileptogenesis': 449, 'equal loudness contour': 450, 'equations': 451, 'equipment condition diagnosis (ecd)': 452, 'error analysis': 453, 'error entropy': 454, 'esm': 455, 'esr': 456, 'estimation': 457, 'estimation of students successes': 458, 'evaporation': 459, 'event coreference': 460, 'event detection': 461, 'event related potentials': 462, 'evidential database': 463, 'evolutionary algorithms': 464, 'evolutionary based learning': 465, 'evolutionary computing': 466, 'evolving (fuzzy) classifiers': 467, 'evolving fuzzy systems': 468, 'evolving graph': 469, 'evolving networks': 470, 'exact inference': 471, 'expectation maximization': 472, \"expected change in classifier's accuracy\": 473, 'expert knowledge': 474, 'expert systems': 475, 'exponential regression': 476, 'extraction patterns': 477, 'extreme verification latency': 478, 'face': 479, 'face recognition': 480, 'facial expression recognition': 481, 'fake user accounts': 482, 'fans': 483, 'fault data injection': 484, 'fault detection': 485, 'fault detection and classification (fdc)': 486, 'fault diagnosis': 487, 'fault fingerprint extraction': 488, 'fault localization': 489, 'faults localization': 490, 'fdd': 491, 'feature': 492, 'feature aware': 493, 'feature discovery': 494, 'feature extraction': 495, 'feature fusion': 496, 'feature learning': 497, 'feature recognition': 498, 'feature selection': 499, 'feature vector': 500, 'features selection': 501, 'feed-forward networks': 502, 'filtering': 503, 'financial markets': 504, 'fine tuning': 505, 'fingerprint': 506, 'fingerprinting': 507, 'finite-state machines': 508, 'firewalls (computing)': 509, 'firmlp': 510, 'fisher vector (fv) feature representation': 511, 'flexibility': 512, 'floods': 513, 'flow forecast': 514, 'folding': 515, 'force plate': 516, 'forecast combination': 517, 'forecasting': 518, 'forecasting energy demand': 519, 'foreclosure-and-real-estate-market': 520, 'formal modeling': 521, 'forums': 522, 'forward looking sonars': 523, 'four dimension': 524, 'fraud detection': 525, 'frequency response analysis fra': 526, 'frequent patterns': 527, 'frequent sequence pattern mining': 528, 'frequent set mining': 529, 'function approximation': 530, 'functional connectivity': 531, 'functional dependency': 532, 'functional time series': 533, 'fusion': 534, 'fuzzy': 535, 'fuzzy clustering': 536, 'fuzzy discrete event system': 537, 'fuzzy logic': 538, 'fuzzy operations': 539, 'fuzzy rules': 540, 'fuzzy soft sets': 541, 'fuzzy systems': 542, 'fuzzy-logic-controller': 543, 'fuzzy-neighborhood density-based clustering': 544, 'gain parameter and drop out technique': 545, 'gait analysis': 546, 'game theory': 547, 'game-data': 548, 'games': 549, 'gamma distribution': 550, 'gamma-ray spectra': 551, 'gaussian mixture': 552, 'gaussian mixture model': 553, 'gaussian mixture model (gmm)': 554, 'gaussian process': 555, 'gaussian process regression': 556, 'gaussian processes': 557, 'gaussian radial basis function': 558, 'gcm data': 559, 'gender identification': 560, 'gene coexpression networks': 561, 'gene expression data': 562, 'generative learning': 563, 'generative models': 564, 'genetic algorithm': 565, 'genetic algorithms': 566, 'genetic optimization and supervision': 567, 'genetics': 568, 'genome analysis toolkit (gatk)': 569, 'genome wide association studies': 570, 'genomic data': 571, 'geometrical analysis': 572, 'geophysical': 573, 'gestational hypertension': 574, 'glass': 575, 'global optimization': 576, 'gmm': 577, 'google': 578, 'google cloud vision api': 579, 'government': 580, \"gower's measure of similarity\": 581, 'gpgpu': 582, 'gplvm': 583, 'gps': 584, 'gpu computing': 585, 'grabcut': 586, 'gradient approximation': 587, 'grammar': 588, 'granger-causality': 589, 'granular computing': 590, 'graph representation': 591, 'graph sequence': 592, 'graph theory': 593, 'graphical model': 594, 'graphical models': 595, 'gray-level co-occurrence matrix (glcm)': 596, 'grib': 597, 'grid-connected-pv-system': 598, 'group based labeling': 599, 'group diversity': 600, 'gui': 601, 'hamming codes': 602, 'handwritten digit recognition': 603, 'health social networks': 604, 'healthcare fraud': 605, 'healthcare systems': 606, 'heart disease': 607, 'heart rate': 608, 'hedonic pricing model': 609, 'hedonic theory': 610, 'hemiplegic gait': 611, \"henze-zirkler's multivariate normality test\": 612, 'heterogeneous-data': 613, 'heuristic word alignment': 614, 'hidden markov model': 615, 'hidden markov model (hmm)': 616, 'hidden markov models': 617, 'hierachical graph neuron': 618, 'hierarchical bayesian model': 619, 'hierarchical classification': 620, 'hierarchical clustering': 621, 'hierarchical dirichlet process': 622, 'hierarchical learning': 623, 'high voltage feeder': 624, 'high-dimensional data': 625, 'high-dimensional input': 626, 'high-order rbms': 627, 'histograms': 628, 'history': 629, 'hmm': 630, 'home appliances': 631, 'horizon line detection': 632, 'hotspot mapping': 633, 'housing prices prediction': 634, 'html': 635, 'human action recognition': 636, 'human activity recognition': 637, 'human behavior prediction': 638, 'human tracking': 639, 'hybrid': 640, 'hybrid algorithms': 641, 'hybrid electric vehicles': 642, 'hybrid learning algorithms': 643, 'hybrid-neurone-fuzzy': 644, 'hydroelectric': 645, 'hyperparameter optimization': 646, 'hypopnea': 647, 'identification-recognition': 648, 'image classification': 649, 'image descriptors': 650, 'image forgery detection': 651, 'image matching': 652, 'image noise': 653, 'image processing': 654, 'image restoration': 655, 'image segmentation': 656, 'image segments': 657, 'image synthetization': 658, 'image-based diagnosis': 659, 'imbalance': 660, 'imbalanced classes': 661, 'implicit feedback': 662, 'importance sampling': 663, 'improvement': 664, 'imputation': 665, 'in-hospital length of stay prediction': 666, 'in-memory distribution': 667, 'incident-ranking': 668, 'inconsistency': 669, 'index and ring finger ratio': 670, 'indexes': 671, 'indoor localization': 672, 'indoor user movement': 673, 'induction motors': 674, 'inductive logic programming': 675, 'inertial measurement units': 676, 'inferential reasoning': 677, 'information extraction': 678, 'information need modeling': 679, 'information retrieval': 680, 'information theoretic learning': 681, 'information theory': 682, 'informative weight': 683, 'inpainting': 684, 'insolation period': 685, 'inspection': 686, 'instance selection': 687, 'instance weighting': 688, 'instant message': 689, 'integrated circuits': 690, 'integration of new classes on-the-fly': 691, 'integrative complexity': 692, 'intelligent agent': 693, 'intelligent systems': 694, 'intelligent tutoring systems': 695, 'intensive care units': 696, 'interactive evolutionary computation': 697, 'interactive systems': 698, 'internet of things': 699, 'interpretability': 700, 'interpretable machine learning': 701, 'interpretable modeling': 702, 'interpretation': 703, 'interval-radial algorithm': 704, 'intervention systems': 705, 'intrusion detection': 706, 'intrusion detection &amp; defence': 707, 'intrusion detection system': 708, 'intrusiondetection': 709, 'intuitionistic fuzzy stes': 710, 'inverse gaussian regression': 711, 'inverse reinforcement learning': 712, 'inverse-inference': 713, 'inverted dirichlet': 714, 'iot': 715, 'ip networks': 716, 'iris': 717, 'irradiance': 718, 'isbsg': 719, 'item popularity': 720, 'iterative methods': 721, 'jensen-shannon divergence': 722, 'job recommendation email system': 723, 'joint inference': 724, 'jpeg': 725, 'k-means': 726, 'k-means clustering': 727, 'k-medoids': 728, 'k-nearest neighbor': 729, 'k-nearest neighbor classifier (knn)': 730, 'k-nn': 731, 'kaiser-meyer-olkin': 732, 'kd-trees': 733, 'kegg signalling pathways': 734, 'kernel': 735, 'kernel function': 736, 'kernel functions': 737, 'kernel k-means': 738, 'kernel method': 739, 'kernel methods': 740, 'kernel online learning': 741, 'kernel ridge regression': 742, 'keystroke dynamics': 743, 'keystroke feature': 744, 'keyword spotting': 745, 'khepera': 746, 'kidney segmentation': 747, 'kmeans clustering': 748, 'knn': 749, 'knn classification model': 750, 'knowledge base': 751, 'knowledge discovery': 752, 'knowledge graphs': 753, 'knowledge topology and acquisition': 754, 'knowledge-discovery': 755, 'kohonen self organizing network': 756, 'l1 norm': 757, 'l2 norm': 758, 'label noise': 759, 'label propagation': 760, 'labeling': 761, 'language modeling': 762, 'large data': 763, 'large scale': 764, 'large scale network flow': 765, 'lasso regression': 766, 'latent dirichlet allocation': 767, 'latent semantic indexing': 768, 'lateral movement': 769, 'layered learning': 770, 'lcm': 771, 'lda': 772, 'learning (artificial intelligence)': 773, 'learning classifier systems': 774, 'learning convex function': 775, 'learning from interpretation transition': 776, 'learning systems': 777, 'least absolute shrinkage and selection operator (lasso)': 778, 'legged locomotion': 779, 'lesions': 780, 'level-k thinking': 781, 'libs': 782, 'license plate recognition system': 783, 'lifelong machine learning': 784, 'linear programming': 785, 'linear regression': 786, 'linguistic features': 787, 'link prediction': 788, 'liver segmentation': 789, 'local binary patterns': 790, 'logistic regression': 791, 'logistics': 792, 'logsigmoid function': 793, 'long short-term memory': 794, 'long-short term memory': 795, 'longitudinal data': 796, 'loss minimization': 797, 'low-rank approximation': 798, 'lp-norm estimators': 799, 'lung cancer': 800, 'machine learning': 801, 'machine learning algorithm (mla)': 802, 'machine learning algorithms': 803, 'machine learning application': 804, 'machine learning as a service': 805, 'machine learning techniques': 806, 'machine-learning': 807, 'machine-sourced': 808, 'magnetic field': 809, 'majority vote rule': 810, 'malware': 811, 'malware classification': 812, 'manifold learning': 813, 'manifold learning regression': 814, 'manufacturing': 815, 'maple': 816, 'mapreduce': 817, 'margin': 818, 'markov decision process': 819, 'markov decision processes': 820, 'markov logic networks': 821, 'markov network': 822, 'markov switching model': 823, 'markov(k)': 824, 'masked conditional neural networks': 825, 'mass deaths': 826, 'mass transfer': 827, 'master degree in information technology': 828, 'mathematica': 829, 'mathematical model': 830, 'matrix decomposition': 831, 'max-min distance algorithm': 832, 'maximum a posteriori': 833, 'maximum likelihood estimation': 834, 'maximum-power-point-tracker': 835, 'mclnn': 836, 'measurement': 837, 'medical image analysis': 838, 'medical informatics': 839, 'meta-algorithms': 840, 'meta-heuristic prediction algorithm': 841, 'meta-recommendation system': 842, 'metabolomics': 843, 'metadata': 844, 'metasoundex': 845, 'meteorology': 846, 'metric learning': 847, 'metrics': 848, 'mfccs': 849, 'mhealth': 850, 'microalgae classification': 851, 'microtubules': 852, 'mimics': 853, 'minimum description length': 854, 'mininet': 855, 'mining big data': 856, 'minutia code': 857, 'minutiae': 858, 'mislabeled data': 859, 'missing at random': 860, 'missing data': 861, 'mixed data': 862, 'mixture model': 863, 'mixture models': 864, 'mixture of experts': 865, 'mlp': 866, 'mnist': 867, 'mnist variations': 868, 'mobile computing': 869, 'mobile robot self-localization': 870, 'mobile robots': 871, 'mobile security': 872, 'mobile store security': 873, 'model building': 874, 'model calibration': 875, 'model checking': 876, 'model post processing': 877, 'model transformatiomn': 878, 'modeling': 879, 'monitoring': 880, 'monte carlo': 881, 'monte carlo methods': 882, 'mortality rate prediction': 883, 'motion capture (mocap)': 884, 'motion-based multiple object tracking': 885, 'movie': 886, 'moving target defense': 887, 'mr images': 888, 'mrmr': 889, 'multi agent systems': 890, 'multi instance classification': 891, 'multi-armed bandit': 892, 'multi-armed bandits': 893, 'multi-corpora': 894, 'multi-density clustering': 895, 'multi-label classification': 896, 'multi-label classifiers': 897, 'multi-label learning': 898, 'multi-linear regression model': 899, 'multi-objective evolutionary algorithm': 900, 'multi-objective particle swarm optimization': 901, 'multi-objective reinforcement learning': 902, 'multi-objectivization': 903, 'multi-period prediction': 904, 'multi-scale': 905, 'multi-strategy learning': 906, 'multi-task learning': 907, 'multi-valued models': 908, 'multiclass classification': 909, 'multilayer feedforward neural network': 910, 'multilayer network': 911, 'multilingual': 912, 'multimedia signal processing': 913, 'multimedia structure analysis': 914, 'multimodal': 915, 'multiobjectivization': 916, 'multiple classifier systems': 917, 'multiple instance learning': 918, 'multiple kernel learning': 919, 'multiple object tracking': 920, 'multivariate analyses': 921, 'multiview data': 922, 'music': 923, 'music event': 924, 'mutual information': 925, 'naive bayes': 926, 'naive bayes classifier': 927, 'named entity recognition': 928, 'narx': 929, 'narx neural network': 930, 'natural language processing': 931, 'ndt': 932, 'near infrared': 933, 'nearest neighbor': 934, 'nearest neighbor search': 935, 'negative images': 936, 'nelder-mead algorithm (nma)': 937, 'network attacks': 938, 'network communities': 939, 'network data': 940, 'network inference': 941, 'network intrusion detection system (nids)': 942, 'network layer': 943, 'network representation learning': 944, 'network topology': 945, 'networked control system': 946, 'networks': 947, 'neural network': 948, 'neural network based machine learning': 949, 'neural network classifier': 950, 'neural networks': 951, 'neurocrfs': 952, 'neuroevolution': 953, 'neurofuzzy system': 954, 'neurons': 955, 'neuroscience': 956, 'new event types': 957, 'next generation sequence (ngs)': 958, 'next generation wireless networks': 959, 'nir': 960, 'nlp': 961, 'nn-based fault detection algorith': 962, 'node similarities': 963, 'noise': 964, 'noise estimation': 965, 'noise reduction': 966, 'noisy data': 967, 'noisy training data': 968, 'non intrusive load monitoring': 969, 'non negative matrix factorization': 970, 'non stationary time-series': 971, 'non-linearity': 972, 'non-personalized single heuristic strategies': 973, 'non-stationary': 974, 'nonlinear dynamics': 975, 'nonnegative matrix factorization': 976, 'nonparametric bayesian': 977, 'nonstationary processes': 978, 'nontechnical loss': 979, 'nonword stimuli repetition': 980, 'normalization': 981, 'notifications': 982, 'novelty search': 983, 'nuclear magnetic resonance': 984, 'number of clusters in a dataset': 985, 'numerical models': 986, 'numerical simulation': 987, 'nutrition': 988, 'object oriented software': 989, 'object recognition': 990, 'object tracking': 991, 'objective selection': 992, 'oblivion criterion': 993, 'oblivious routing scheme': 994, 'obstructive apnea': 995, 'occlusion': 996, 'oceanography': 997, 'ompt': 998, 'on-line learning': 999, 'one-way anova': 1000, 'online clustering': 1001, 'online k-means clustering': 1002, 'online learning': 1003, 'online process monitoring': 1004, 'online selection': 1005, 'ontology learning': 1006, 'openmp tasks': 1007, 'opinion extraction': 1008, 'optimal control': 1009, 'optimization': 1010, 'optimum path forest': 1011, 'optimum-path forest': 1012, 'organ segmentation': 1013, 'organic computing': 1014, 'orphan node prediction': 1015, 'orthogonal matching pursuit': 1016, 'outlier': 1017, 'outlier detection': 1018, 'outliers': 1019, 'outsourcing': 1020, 'over dispersion': 1021, 'palynology': 1022, 'parallel processing': 1023, 'parallelized sgd': 1024, 'parameter control': 1025, \"parkinson's disease\": 1026, 'partial-autocorrelation-function-(pacf)': 1027, 'particle swarm optimization': 1028, 'partitional clustering': 1029, 'partitioning': 1030, 'partitioning algorithms': 1031, 'partitioning clustering': 1032, 'parts based decompositions': 1033, 'passive seismic': 1034, 'patent': 1035, 'pattern matching': 1036, 'pattern recognition': 1037, 'pca': 1038, 'pcr': 1039, 'penalization': 1040, 'performance': 1041, 'performance evaluation': 1042, 'personalized item': 1043, 'personalized treatment': 1044, 'phase identification': 1045, 'phenotype prediction': 1046, 'phoneme': 1047, 'phoneme classification': 1048, 'phoneme prediction': 1049, 'pid control': 1050, 'piecewise linear': 1051, 'pipeline': 1052, 'pitch system': 1053, 'platform': 1054, 'platform as a service': 1055, 'plsa': 1056, 'pollen classification': 1057, \"poppelreuter's test\": 1058, 'ports (computers)': 1059, 'positive unlabeled learning': 1060, 'post-processing': 1061, 'potentials': 1062, 'power density': 1063, 'power grid analysis': 1064, 'power spectral density analysis': 1065, 'power systems': 1066, 'pre school': 1067, 'predict': 1068, 'predictability': 1069, 'predicting psychosis': 1070, 'prediction': 1071, 'prediction algorithms': 1072, 'predictive analysis': 1073, 'predictive data analytics': 1074, 'predictive model': 1075, 'predictive modelling': 1076, 'predictive models': 1077, 'predictive scoring systems': 1078, 'preference prediction technique': 1079, 'preprocessing': 1080, 'primal dual algorithm': 1081, 'principal component analysis': 1082, 'principal components analysis': 1083, 'principal-component analysis': 1084, 'principle component analysis': 1085, 'privacy': 1086, 'privacy policy': 1087, 'privacy preserving': 1088, 'privacy-preserving': 1089, 'probabilistic atlas': 1090, 'probabilistic logic': 1091, 'probabilistic matrix factorization': 1092, 'probabilistic programming': 1093, 'probability': 1094, 'probability of classification error': 1095, 'probit regression': 1096, 'process control': 1097, 'profitability': 1098, 'programmers': 1099, 'programming': 1100, 'protein conformation': 1101, 'protocols': 1102, 'pruning': 1103, 'pull request': 1104, 'pv system': 1105, 'q learning': 1106, 'q-learning': 1107, 'qos over heterogeneous networks': 1108, 'qpcr': 1109, 'quadratic programming': 1110, 'quality assessment': 1111, 'query relaxation': 1112, 'radial basis functions': 1113, 'radiality': 1114, 'radiation hybrid mapping': 1115, 'radio frequency': 1116, 'railway crossing region': 1117, 'railway-incidents': 1118, 'random forest': 1119, 'random forests': 1120, 'random forests ': 1121, 'random projection': 1122, 'rbm': 1123, 'real estate prediction': 1124, 'real-time recurrent learning (rtrl)': 1125, 'real-time systems': 1126, 'recall of data': 1127, 'recognition': 1128, 'recommendation emails': 1129, 'recommender systems': 1130, 'recommender systems survey': 1131, 'recompression': 1132, 'reconstruction': 1133, 'reconstruction error': 1134, 'record linkage': 1135, 'recurrent neural network': 1136, 'recurrent processing': 1137, 'recursive feature addition': 1138, 'regime classification': 1139, 'region of interest': 1140, 'regression': 1141, 'regression trees': 1142, 'regularization': 1143, 'reinforcement learning': 1144, 'rejection': 1145, 'reliability': 1146, 'remote health care': 1147, 'renewable energy': 1148, 'repair': 1149, 'representation': 1150, 'representation learning': 1151, 'resampling': 1152, 'reservoir level': 1153, 'resonance frequency': 1154, 'resource exhausting': 1155, 'resource management': 1156, 'response likelihood model': 1157, 'restricted boltzmann machine': 1158, 'resultant': 1159, 'retinal image': 1160, 'rfe': 1161, 'ridge': 1162, 'ridge regression': 1163, 'road accident': 1164, 'road transportation': 1165, 'roads': 1166, 'robot control': 1167, 'robot sensing systems': 1168, 'robots': 1169, 'robust': 1170, 'robust learning': 1171, 'robustness': 1172, 'roc analysis': 1173, 'rough sets': 1174, 'routine behaviours': 1175, 'routing and mobility management': 1176, 'rp trees': 1177, 'rubrics': 1178, 'rule extraction': 1179, 'rule-based classification': 1180, 'runtime': 1181, 'runtime analysis': 1182, 'sacked sparse autoencoders': 1183, 'saidi forecast': 1184, 'saliency': 1185, 'sample reconstruction': 1186, 'sanitizer': 1187, 'satisficing': 1188, 'scada data': 1189, 'scalability': 1190, 'scenario generation': 1191, 'scene matching': 1192, 'sclera segmentation': 1193, 'scoliosis': 1194, 'score systems': 1195, 'sda': 1196, 'sdncontroller': 1197, 'sdsm': 1198, 'search by multiple examples': 1199, 'secure data aggregation model (sdam)': 1200, 'security': 1201, 'security strength': 1202, 'segmentation': 1203, 'seizure detection': 1204, 'selection': 1205, 'self organization': 1206, 'self-organization parallelization': 1207, 'self-organizing map': 1208, 'self-organizing maps': 1209, 'self-supervised': 1210, 'semantic slot labelling': 1211, 'semantic web': 1212, 'semantics': 1213, 'semi-arid climate': 1214, 'semi-supervised clustering': 1215, 'semi-supervised learning': 1216, 'semiconductor manufacturing': 1217, 'sensitivity': 1218, 'sensor node (sn)': 1219, 'sensors': 1220, 'sentiment analysis': 1221, 'sequence classification': 1222, 'sequential optimization': 1223, 'sequential pattern': 1224, 'serendipitous discovery': 1225, 'servers': 1226, 'service component architecture': 1227, 'service oriented architecture': 1228, 'shape recognition': 1229, 'short time series': 1230, 'shot classification': 1231, 'sigmoid': 1232, 'signal analysis': 1233, 'signal processing': 1234, 'signature': 1235, 'silicon': 1236, 'similarity analysis': 1237, 'similarity-based methods': 1238, 'simulation': 1239, 'simulation-based training': 1240, 'simultaneous eeg & fmri': 1241, 'singing style': 1242, 'singular value decomposition': 1243, 'singular-value decomposition': 1244, 'skip-gram': 1245, 'skyline extraction': 1246, 'small footprint': 1247, 'small sample size problem': 1248, 'small world': 1249, 'smart cities': 1250, 'smart city': 1251, 'smart energy': 1252, 'smart environment': 1253, 'smart grids': 1254, 'smart homes': 1255, 'smart housing': 1256, 'smart meter': 1257, 'smart meters': 1258, 'smartphone': 1259, 'sms spam': 1260, 'sms text': 1261, 'snacks': 1262, 'snakes': 1263, 'snp selection': 1264, 'social media': 1265, 'social network analysis': 1266, 'social networks': 1267, 'sociology': 1268, 'soft clustering': 1269, 'soft sets': 1270, 'software': 1271, 'software architecture': 1272, 'software defect prediction': 1273, 'software defined networks': 1274, 'software effort estimation': 1275, 'software engineering': 1276, 'software enhancement duration prediction': 1277, 'software maintenance duration prediction': 1278, 'software-defined networking (sdn)': 1279, 'solar energy': 1280, 'solar radiation': 1281, 'soundex': 1282, 'source code attributes': 1283, 'source-aware': 1284, 'space exploration': 1285, 'spam': 1286, 'spam review': 1287, 'spamdexing': 1288, 'sparse autoencoders': 1289, 'sparse methods': 1290, 'sparsification': 1291, 'spatio-temporal data': 1292, 'speaker adaptation': 1293, 'speaker identification': 1294, 'spectral clustering': 1295, 'spectral learning': 1296, 'speech enhancement': 1297, 'speech intelligibility': 1298, 'speech quality': 1299, 'speech recognition': 1300, 'speech separation': 1301, 'spike train': 1302, 'spike-event': 1303, 'spiking neural network (snn)': 1304, 'splitting criteria': 1305, 'sql injection attack': 1306, 'sqli': 1307, 'stability': 1308, 'stability analysis': 1309, 'stability-plasticity dilemma': 1310, 'stacked denoising autoencoders': 1311, 'stacking': 1312, 'standard': 1313, 'standardized precipitation index': 1314, 'standards': 1315, 'star glyph plot': 1316, 'state abstraction': 1317, 'state-space model': 1318, 'statistical analysis': 1319, 'statistical downscaling': 1320, 'statistical image clutter metrics': 1321, 'statistical learning': 1322, 'statistical methods': 1323, 'statistical process control': 1324, 'statistical regression': 1325, 'statistical word alignment': 1326, 'statistics': 1327, 'steady state visual evoked potential': 1328, 'stem cell transplant': 1329, 'stochastic gradient descent': 1330, 'stochastic local search': 1331, 'stochastic processes': 1332, 'stock trading points': 1333, 'storage system': 1334, 'straggler': 1335, 'streamflow': 1336, 'streaming': 1337, 'streaming data': 1338, 'structure learning': 1339, 'student dropout': 1340, 'student retention': 1341, 'student success': 1342, 'stylometry': 1343, 'subspace learning': 1344, 'sum product networks': 1345, 'summarization': 1346, 'superfunctions': 1347, 'supervised classification': 1348, 'supervised learning': 1349, 'supervised machine learning': 1350, 'support vector egression': 1351, 'support vector machine': 1352, 'support vector machine learning': 1353, 'support vector machines': 1354, 'support vector machines (svm)': 1355, 'support vector machines plus': 1356, 'support vector regression': 1357, 'surface images': 1358, 'survey datasets': 1359, 'svm': 1360, 'svm classification': 1361, 'svr': 1362, 'swing detection': 1363, 'swing sports': 1364, 'sybil account': 1365, 'syllable segmentation': 1366, 'synchronization': 1367, 'syntactics': 1368, 'synthetic oversampling': 1369, 'system-level testing': 1370, 'systems biology': 1371, 'tangent bundle manifold learning': 1372, 'target detection': 1373, 'target tracking': 1374, 'tariff': 1375, 'taxonomy': 1376, 'tcp/ip model': 1377, 'teeth': 1378, 'temperature measurement': 1379, 'template matching': 1380, 'template-security': 1381, 'temporal pattern': 1382, 'temporal segmentation': 1383, 'tennis': 1384, 'test case prioritization': 1385, 'test code size': 1386, 'testing': 1387, 'text analysis': 1388, 'text categorization': 1389, 'text mining': 1390, 'text similarity': 1391, 'text summarization': 1392, 'the lasso estimate': 1393, 'thin film flow equation': 1394, 'thresholding': 1395, 'time series': 1396, 'time series analysis': 1397, 'time series classification': 1398, 'time series clustering': 1399, 'time series forecasting': 1400, 'time series prediction': 1401, 'time series representation': 1402, 'time-frequency analysis': 1403, 'time-series analysis': 1404, 'time-series data': 1405, 'time-varying impact': 1406, 'timetabling': 1407, 'tools': 1408, 'topic detection': 1409, 'topic model': 1410, 'topic model labeling': 1411, 'topic modeling': 1412, 'topic models': 1413, 'topic novelty detection': 1414, 'topic-semantic indexing (tsi)': 1415, 'topical ontology': 1416, 'topology': 1417, 'topology mamagement': 1418, 'traclus clustering': 1419, 'traditional machine learning': 1420, 'traffic flow prediciton': 1421, 'traffic flow prediction': 1422, 'traffic prediction': 1423, 'training': 1424, 'training data': 1425, 'training simulations': 1426, 'training speed': 1427, 'training with noisy data': 1428, 'trajectory analysis': 1429, 'trajectory planning in road traffic': 1430, 'transductive learning': 1431, 'transfer learning': 1432, 'transformer': 1433, 'transforms': 1434, 'transparency': 1435, 'trend prediction': 1436, 'tsvm': 1437, 'tuning': 1438, 'tuning curve': 1439, 'turbulence modeling': 1440, 'turkish ner': 1441, 'turkish universities': 1442, 'tweet mining': 1443, 'twitter': 1444, 'two-sided markets': 1445, 'ubiquitous monitoring': 1446, 'ultra-wide band radar': 1447, 'unbalanced data': 1448, 'uncertain labels': 1449, 'uncertainty': 1450, 'uncertainty quantification': 1451, 'underwater': 1452, 'union of intersections': 1453, 'unordered': 1454, 'unsolicited electronic mail': 1455, 'unsupervised clustering': 1456, 'unsupervised feature learning': 1457, 'unsupervised learning': 1458, 'unsupervised machine learning': 1459, 'unsupervised-learning': 1460, 'upper bound': 1461, 'urap rankings': 1462, 'useless words': 1463, 'user modeling': 1464, 'user profiles': 1465, 'validation': 1466, 'validity': 1467, 'valves': 1468, 'variable selection': 1469, 'variance inflation factor': 1470, 'variance of query response': 1471, 'variational bayes': 1472, 'variational em': 1473, 'variational inference': 1474, 'varying coefficient model': 1475, 'vascularization': 1476, 'vectors': 1477, 'vegetation': 1478, 'vehicles': 1479, 'vehicular cyber-physical systems': 1480, 'vertical handoff (vho)': 1481, 'vertical scaling': 1482, 'video event': 1483, 'video indexing': 1484, 'video steganography': 1485, 'video understanding': 1486, 'virtual world': 1487, 'viscous reconstruction': 1488, 'visual classification': 1489, 'visual inspection': 1490, 'visualising': 1491, 'visualization': 1492, 'voice': 1493, 'voiceprint': 1494, 'von mises distribution': 1495, 'vulnerability': 1496, 'waikato environment for knowledge analysis (weka)': 1497, 'wavelet': 1498, 'wavelet analysis': 1499, 'wavelet coefficients': 1500, 'wban security': 1501, 'weakly supervised learning': 1502, 'wearable sensors': 1503, 'weather': 1504, 'weather forecasting': 1505, 'web application': 1506, 'web based games': 1507, 'web based information sources': 1508, 'web caching': 1509, 'web robots': 1510, 'web scraping': 1511, 'web servers': 1512, 'web spam': 1513, 'weight convergence and robust stability': 1514, 'weka': 1515, 'wheel alignment': 1516, 'wheeze': 1517, 'wifi': 1518, 'wifi csi data mining': 1519, 'wifi slam': 1520, 'wind power forecasting': 1521, 'wind power plant': 1522, 'wind speed': 1523, 'wind turbine': 1524, 'wireless communication': 1525, 'wireless sensor network (wsn)': 1526, 'wireless sensor networks (wsns)': 1527, 'word embedding': 1528, 'word embeddings': 1529, 'word vectors': 1530, 'workload characterization': 1531, 'xgboost': 1532, 'youtube': 1533, 'zero-shot learning': 1534}\n",
      "1535\n"
     ]
    }
   ],
   "source": [
    "# * FASE 1.1 Creamos el diccionario\n",
    "diccionarioKeywords = dict()\n",
    "diccionarioKeywords[\"EsteValorEstaMuyDesconocido\"] = 0 # Establecemos el primero como valor desconocido\n",
    "for i in range(0, len(misKeywordsRetornadas)):\n",
    "    diccionarioKeywords[misKeywordsRetornadas[i]] = i+1\n",
    "\n",
    "print(diccionarioKeywords)\n",
    "print(len(diccionarioKeywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6b708b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# * FASE 1.2 Lo pasamos a Array, e incluimos el valor vacío\n",
    "matrizDiccionarioEntrada = array(\"i\", diccionarioLengua.values())\n",
    "    \n",
    "vocabulary_train = tf.keras.utils.to_categorical(matrizDiccionarioEntrada, num_classes=len(matrizDiccionarioEntrada), dtype='int')\n",
    "print(vocabulary_train)\n",
    "\n",
    "matrizDiccionarioVacio = np.array([0] * len(vocabulary_train[diccionarioLengua[\"EsteValorEstaMuyDesconocido\"]])) # Valor vacío \n",
    "print(matrizDiccionarioVacio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f06d91a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "[0 0 0 ... 0 0 0]\n",
      "1535\n"
     ]
    }
   ],
   "source": [
    "# * FASE 1.2.2 Pasamos las keywords a Array, e incluimos el valor vacío\n",
    "matrizKeywordsEnLaSalida = array(\"i\", diccionarioKeywords.values())\n",
    "    \n",
    "keywords_train = tf.keras.utils.to_categorical(matrizKeywordsEnLaSalida, num_classes=len(matrizKeywordsEnLaSalida), dtype='int')\n",
    "print(keywords_train)\n",
    "\n",
    "matrizSalidaSinKeywords = np.array([0] * len(keywords_train[diccionarioKeywords[\"EsteValorEstaMuyDesconocido\"]])) # Valor vacío \n",
    "print(matrizSalidaSinKeywords)\n",
    "print(len(matrizSalidaSinKeywords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb428b21",
   "metadata": {},
   "source": [
    "FASE 1.3 Ahora tomamos el texto y pasamos su abstract, title y keywords al número del diccionario adecuado. Esto nos permitirá tener la entrada y salida esperadas. Muy recomendable que se ajusten las entradas  para tener la misma longitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4eb4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO REEMPLAZA POR ALGO MEJOR\n",
    "'''\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    x_train,\n",
    "    value=word_index['<PAD>'],\n",
    "    padding='post',\n",
    "    maxlen=256\n",
    ")\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    x_test,\n",
    "    value=word_index['<PAD>'],\n",
    "    padding='post',\n",
    "    maxlen=256\n",
    ")\n",
    "'''\n",
    "    \n",
    "def textoaDiccionario(listadeTitulos, listaDeAbstractos, listaDeClaves, numPalabrasEntrada):\n",
    "    entradaEntendiblePorLaRed = []\n",
    "    salidaEntendiblePorLaRed = []\n",
    "    salidaEntendiblePorLaRedOptimizada = []\n",
    "    entradaIndicesTotal = np.zeros((len(listaDeAbstractos), numPalabrasEntrada))\n",
    "    #entradaIndicesTotal = []\n",
    "    contados = 0\n",
    "\n",
    "    for i, title, abstract, keywords in zip(range(len(listadeTitulos)), listadeTitulos, listaDeAbstractos, listaDeClaves):\n",
    "        print(\"CONTENIDO ARTÍCULO\")\n",
    "        # ENTRADA\n",
    "        unTitleAbstract = []\n",
    "        keywordsArticulo = []\n",
    "        entradaIndices = []\n",
    "        contj = 0 \n",
    "        print(i)\n",
    "        print(contados)\n",
    "        print(f'Longitud a leer: {len(title)+len(abstract)}')\n",
    "        for palabra in title:\n",
    "            #print(palabra)\n",
    "            elIndice = diccionarioLengua[palabra]\n",
    "            if elIndice is None:\n",
    "                elIndice = diccionarioLengua[\"EsteValorEstaMuyDesconocido\"]\n",
    "            unTitleAbstract.append(vocabulary_train[elIndice])\n",
    "       #     entradaIndices.append(elIndice)\n",
    "            entradaIndicesTotal[i][contj] = elIndice\n",
    "            contj = contj + 1\n",
    "        for palabra in abstract:\n",
    "            elIndice = diccionarioLengua[palabra]\n",
    "            if elIndice is None:\n",
    "                elIndice = diccionarioLengua[\"EsteValorEstaMuyDesconocido\"]\n",
    "            unTitleAbstract.append(vocabulary_train[elIndice])\n",
    "     #       entradaIndices.append(elIndice)\n",
    "            entradaIndicesTotal[i][contj] = elIndice\n",
    "            contj = contj + 1\n",
    "        # Relleno con el padding adecuado \n",
    "\n",
    "        #print(len(unTitleAbstract))\n",
    "        #cont = 0;\n",
    "        for long in range(len(unTitleAbstract)-1, numPalabrasEntrada-1):\n",
    "            unTitleAbstract.append(matrizDiccionarioVacio)\n",
    "#            entradaIndices.append(diccionarioLengua[\"<UNU>\"])\n",
    "        #    cont = cont +1\n",
    "        #print(f\"el cont es {cont}\") \n",
    "        #print(f\"Long total {len(unTitleAbstract)}\")\n",
    "        \n",
    "        # SALIDA ESPERADA\n",
    "        auxiliar = matrizDiccionarioVacio.copy()\n",
    "        auxiliarCompressed = matrizSalidaSinKeywords.copy()\n",
    "        for palabra in keywords:\n",
    "            auxiliar[diccionarioLengua[palabra]] = 1\n",
    "            auxiliarCompressed[diccionarioKeywords[palabra]] = 1\n",
    "        \n",
    "        entradaEntendiblePorLaRed.append(unTitleAbstract)\n",
    "#        entradaIndicesTotal.append(np.array(entradaIndices))\n",
    "        salidaEntendiblePorLaRed.append(auxiliar)\n",
    "        salidaEntendiblePorLaRedOptimizada.append(auxiliarCompressed)\n",
    "        \n",
    "        contados = contados + 1\n",
    "        \n",
    "        #print(len(unTitleAbstract)) # Con esto sabemos las longitudes, podemos asumir que 400 palabras a la entrada es más que suficiente\n",
    "        \n",
    "    return entradaEntendiblePorLaRed, np.array(entradaIndicesTotal), salidaEntendiblePorLaRed, salidaEntendiblePorLaRedOptimizada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42ccaa0",
   "metadata": {},
   "source": [
    "Ahora obtenemos la entrada de cada artículo con su respectiva salida esperada.\n",
    "\n",
    "Lo de salida compressed es meramente una variante en la que nos quitamos muchas neuronas de salida de en medio, ya que queremos solo clasificar la salida esperada entre una de dichas keywords, no de todo el espacio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c216659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTENIDO ARTÍCULO\n",
      "0\n",
      "0\n",
      "Longitud a leer: 121\n",
      "CONTENIDO ARTÍCULO\n",
      "1\n",
      "1\n",
      "Longitud a leer: 111\n",
      "CONTENIDO ARTÍCULO\n",
      "2\n",
      "2\n",
      "Longitud a leer: 123\n",
      "CONTENIDO ARTÍCULO\n",
      "3\n",
      "3\n",
      "Longitud a leer: 200\n",
      "CONTENIDO ARTÍCULO\n",
      "4\n",
      "4\n",
      "Longitud a leer: 185\n",
      "CONTENIDO ARTÍCULO\n",
      "5\n",
      "5\n",
      "Longitud a leer: 121\n",
      "CONTENIDO ARTÍCULO\n",
      "6\n",
      "6\n",
      "Longitud a leer: 179\n",
      "CONTENIDO ARTÍCULO\n",
      "7\n",
      "7\n",
      "Longitud a leer: 138\n",
      "CONTENIDO ARTÍCULO\n",
      "8\n",
      "8\n",
      "Longitud a leer: 189\n",
      "CONTENIDO ARTÍCULO\n",
      "9\n",
      "9\n",
      "Longitud a leer: 148\n",
      "CONTENIDO ARTÍCULO\n",
      "10\n",
      "10\n",
      "Longitud a leer: 134\n",
      "CONTENIDO ARTÍCULO\n",
      "11\n",
      "11\n",
      "Longitud a leer: 149\n",
      "CONTENIDO ARTÍCULO\n",
      "12\n",
      "12\n",
      "Longitud a leer: 152\n",
      "CONTENIDO ARTÍCULO\n",
      "13\n",
      "13\n",
      "Longitud a leer: 130\n",
      "CONTENIDO ARTÍCULO\n",
      "14\n",
      "14\n",
      "Longitud a leer: 124\n",
      "CONTENIDO ARTÍCULO\n",
      "15\n",
      "15\n",
      "Longitud a leer: 115\n",
      "CONTENIDO ARTÍCULO\n",
      "16\n",
      "16\n",
      "Longitud a leer: 133\n",
      "CONTENIDO ARTÍCULO\n",
      "17\n",
      "17\n",
      "Longitud a leer: 167\n",
      "CONTENIDO ARTÍCULO\n",
      "18\n",
      "18\n",
      "Longitud a leer: 166\n",
      "CONTENIDO ARTÍCULO\n",
      "19\n",
      "19\n",
      "Longitud a leer: 99\n",
      "CONTENIDO ARTÍCULO\n",
      "20\n",
      "20\n",
      "Longitud a leer: 133\n",
      "CONTENIDO ARTÍCULO\n",
      "21\n",
      "21\n",
      "Longitud a leer: 256\n",
      "CONTENIDO ARTÍCULO\n",
      "22\n",
      "22\n",
      "Longitud a leer: 120\n",
      "CONTENIDO ARTÍCULO\n",
      "23\n",
      "23\n",
      "Longitud a leer: 219\n",
      "CONTENIDO ARTÍCULO\n",
      "24\n",
      "24\n",
      "Longitud a leer: 110\n",
      "CONTENIDO ARTÍCULO\n",
      "25\n",
      "25\n",
      "Longitud a leer: 139\n",
      "CONTENIDO ARTÍCULO\n",
      "26\n",
      "26\n",
      "Longitud a leer: 146\n",
      "CONTENIDO ARTÍCULO\n",
      "27\n",
      "27\n",
      "Longitud a leer: 90\n",
      "CONTENIDO ARTÍCULO\n",
      "28\n",
      "28\n",
      "Longitud a leer: 87\n",
      "CONTENIDO ARTÍCULO\n",
      "29\n",
      "29\n",
      "Longitud a leer: 119\n",
      "CONTENIDO ARTÍCULO\n",
      "30\n",
      "30\n",
      "Longitud a leer: 135\n",
      "CONTENIDO ARTÍCULO\n",
      "31\n",
      "31\n",
      "Longitud a leer: 232\n",
      "CONTENIDO ARTÍCULO\n",
      "32\n",
      "32\n",
      "Longitud a leer: 117\n",
      "CONTENIDO ARTÍCULO\n",
      "33\n",
      "33\n",
      "Longitud a leer: 232\n",
      "CONTENIDO ARTÍCULO\n",
      "34\n",
      "34\n",
      "Longitud a leer: 153\n",
      "CONTENIDO ARTÍCULO\n",
      "35\n",
      "35\n",
      "Longitud a leer: 207\n",
      "CONTENIDO ARTÍCULO\n",
      "36\n",
      "36\n",
      "Longitud a leer: 330\n",
      "CONTENIDO ARTÍCULO\n",
      "37\n",
      "37\n",
      "Longitud a leer: 126\n",
      "CONTENIDO ARTÍCULO\n",
      "38\n",
      "38\n",
      "Longitud a leer: 101\n",
      "CONTENIDO ARTÍCULO\n",
      "39\n",
      "39\n",
      "Longitud a leer: 183\n",
      "CONTENIDO ARTÍCULO\n",
      "40\n",
      "40\n",
      "Longitud a leer: 167\n",
      "CONTENIDO ARTÍCULO\n",
      "41\n",
      "41\n",
      "Longitud a leer: 183\n",
      "CONTENIDO ARTÍCULO\n",
      "42\n",
      "42\n",
      "Longitud a leer: 224\n",
      "CONTENIDO ARTÍCULO\n",
      "43\n",
      "43\n",
      "Longitud a leer: 193\n",
      "CONTENIDO ARTÍCULO\n",
      "44\n",
      "44\n",
      "Longitud a leer: 142\n",
      "CONTENIDO ARTÍCULO\n",
      "45\n",
      "45\n",
      "Longitud a leer: 191\n",
      "CONTENIDO ARTÍCULO\n",
      "46\n",
      "46\n",
      "Longitud a leer: 126\n",
      "CONTENIDO ARTÍCULO\n",
      "47\n",
      "47\n",
      "Longitud a leer: 183\n",
      "CONTENIDO ARTÍCULO\n",
      "48\n",
      "48\n",
      "Longitud a leer: 155\n",
      "CONTENIDO ARTÍCULO\n",
      "49\n",
      "49\n",
      "Longitud a leer: 206\n",
      "CONTENIDO ARTÍCULO\n",
      "50\n",
      "50\n",
      "Longitud a leer: 189\n",
      "CONTENIDO ARTÍCULO\n",
      "51\n",
      "51\n",
      "Longitud a leer: 303\n",
      "CONTENIDO ARTÍCULO\n",
      "52\n",
      "52\n",
      "Longitud a leer: 149\n",
      "CONTENIDO ARTÍCULO\n",
      "53\n",
      "53\n",
      "Longitud a leer: 149\n",
      "CONTENIDO ARTÍCULO\n",
      "54\n",
      "54\n",
      "Longitud a leer: 174\n",
      "CONTENIDO ARTÍCULO\n",
      "55\n",
      "55\n",
      "Longitud a leer: 141\n",
      "CONTENIDO ARTÍCULO\n",
      "56\n",
      "56\n",
      "Longitud a leer: 167\n",
      "CONTENIDO ARTÍCULO\n",
      "57\n",
      "57\n",
      "Longitud a leer: 176\n",
      "CONTENIDO ARTÍCULO\n",
      "58\n",
      "58\n",
      "Longitud a leer: 136\n",
      "CONTENIDO ARTÍCULO\n",
      "59\n",
      "59\n",
      "Longitud a leer: 68\n",
      "CONTENIDO ARTÍCULO\n",
      "60\n",
      "60\n",
      "Longitud a leer: 184\n",
      "CONTENIDO ARTÍCULO\n",
      "61\n",
      "61\n",
      "Longitud a leer: 137\n",
      "CONTENIDO ARTÍCULO\n",
      "62\n",
      "62\n",
      "Longitud a leer: 212\n",
      "CONTENIDO ARTÍCULO\n",
      "63\n",
      "63\n",
      "Longitud a leer: 90\n",
      "CONTENIDO ARTÍCULO\n",
      "64\n",
      "64\n",
      "Longitud a leer: 224\n",
      "CONTENIDO ARTÍCULO\n",
      "65\n",
      "65\n",
      "Longitud a leer: 229\n",
      "CONTENIDO ARTÍCULO\n",
      "66\n",
      "66\n",
      "Longitud a leer: 196\n",
      "CONTENIDO ARTÍCULO\n",
      "67\n",
      "67\n",
      "Longitud a leer: 129\n",
      "CONTENIDO ARTÍCULO\n",
      "68\n",
      "68\n",
      "Longitud a leer: 154\n",
      "CONTENIDO ARTÍCULO\n",
      "69\n",
      "69\n",
      "Longitud a leer: 129\n",
      "CONTENIDO ARTÍCULO\n",
      "70\n",
      "70\n",
      "Longitud a leer: 129\n",
      "CONTENIDO ARTÍCULO\n",
      "71\n",
      "71\n",
      "Longitud a leer: 125\n",
      "CONTENIDO ARTÍCULO\n",
      "72\n",
      "72\n",
      "Longitud a leer: 151\n",
      "CONTENIDO ARTÍCULO\n",
      "73\n",
      "73\n",
      "Longitud a leer: 123\n",
      "CONTENIDO ARTÍCULO\n",
      "74\n",
      "74\n",
      "Longitud a leer: 13\n",
      "CONTENIDO ARTÍCULO\n",
      "75\n",
      "75\n",
      "Longitud a leer: 12\n",
      "CONTENIDO ARTÍCULO\n",
      "76\n",
      "76\n",
      "Longitud a leer: 15\n",
      "CONTENIDO ARTÍCULO\n",
      "77\n",
      "77\n",
      "Longitud a leer: 15\n",
      "CONTENIDO ARTÍCULO\n",
      "78\n",
      "78\n",
      "Longitud a leer: 146\n",
      "CONTENIDO ARTÍCULO\n",
      "79\n",
      "79\n",
      "Longitud a leer: 184\n",
      "CONTENIDO ARTÍCULO\n",
      "80\n",
      "80\n",
      "Longitud a leer: 142\n",
      "CONTENIDO ARTÍCULO\n",
      "81\n",
      "81\n",
      "Longitud a leer: 189\n",
      "CONTENIDO ARTÍCULO\n",
      "82\n",
      "82\n",
      "Longitud a leer: 246\n",
      "CONTENIDO ARTÍCULO\n",
      "83\n",
      "83\n",
      "Longitud a leer: 172\n",
      "CONTENIDO ARTÍCULO\n",
      "84\n",
      "84\n",
      "Longitud a leer: 155\n",
      "CONTENIDO ARTÍCULO\n",
      "85\n",
      "85\n",
      "Longitud a leer: 16\n",
      "CONTENIDO ARTÍCULO\n",
      "86\n",
      "86\n",
      "Longitud a leer: 122\n",
      "CONTENIDO ARTÍCULO\n",
      "87\n",
      "87\n",
      "Longitud a leer: 253\n",
      "CONTENIDO ARTÍCULO\n",
      "88\n",
      "88\n",
      "Longitud a leer: 133\n",
      "CONTENIDO ARTÍCULO\n",
      "89\n",
      "89\n",
      "Longitud a leer: 170\n",
      "CONTENIDO ARTÍCULO\n",
      "90\n",
      "90\n",
      "Longitud a leer: 195\n",
      "CONTENIDO ARTÍCULO\n",
      "91\n",
      "91\n",
      "Longitud a leer: 160\n",
      "CONTENIDO ARTÍCULO\n",
      "92\n",
      "92\n",
      "Longitud a leer: 333\n",
      "CONTENIDO ARTÍCULO\n",
      "93\n",
      "93\n",
      "Longitud a leer: 229\n",
      "CONTENIDO ARTÍCULO\n",
      "94\n",
      "94\n",
      "Longitud a leer: 235\n",
      "CONTENIDO ARTÍCULO\n",
      "95\n",
      "95\n",
      "Longitud a leer: 168\n",
      "CONTENIDO ARTÍCULO\n",
      "96\n",
      "96\n",
      "Longitud a leer: 198\n",
      "CONTENIDO ARTÍCULO\n",
      "97\n",
      "97\n",
      "Longitud a leer: 130\n",
      "CONTENIDO ARTÍCULO\n",
      "98\n",
      "98\n",
      "Longitud a leer: 200\n",
      "CONTENIDO ARTÍCULO\n",
      "99\n",
      "99\n",
      "Longitud a leer: 188\n",
      "CONTENIDO ARTÍCULO\n",
      "100\n",
      "100\n",
      "Longitud a leer: 123\n",
      "CONTENIDO ARTÍCULO\n",
      "101\n",
      "101\n",
      "Longitud a leer: 133\n",
      "CONTENIDO ARTÍCULO\n",
      "102\n",
      "102\n",
      "Longitud a leer: 113\n",
      "CONTENIDO ARTÍCULO\n",
      "103\n",
      "103\n",
      "Longitud a leer: 230\n",
      "CONTENIDO ARTÍCULO\n",
      "104\n",
      "104\n",
      "Longitud a leer: 124\n",
      "CONTENIDO ARTÍCULO\n",
      "105\n",
      "105\n",
      "Longitud a leer: 203\n",
      "CONTENIDO ARTÍCULO\n",
      "106\n",
      "106\n",
      "Longitud a leer: 116\n",
      "CONTENIDO ARTÍCULO\n",
      "107\n",
      "107\n",
      "Longitud a leer: 142\n",
      "CONTENIDO ARTÍCULO\n",
      "108\n",
      "108\n",
      "Longitud a leer: 119\n",
      "CONTENIDO ARTÍCULO\n",
      "109\n",
      "109\n",
      "Longitud a leer: 168\n",
      "CONTENIDO ARTÍCULO\n",
      "110\n",
      "110\n",
      "Longitud a leer: 83\n",
      "CONTENIDO ARTÍCULO\n",
      "111\n",
      "111\n",
      "Longitud a leer: 222\n",
      "CONTENIDO ARTÍCULO\n",
      "112\n",
      "112\n",
      "Longitud a leer: 206\n",
      "CONTENIDO ARTÍCULO\n",
      "113\n",
      "113\n",
      "Longitud a leer: 182\n",
      "CONTENIDO ARTÍCULO\n",
      "114\n",
      "114\n",
      "Longitud a leer: 109\n",
      "CONTENIDO ARTÍCULO\n",
      "115\n",
      "115\n",
      "Longitud a leer: 148\n",
      "CONTENIDO ARTÍCULO\n",
      "116\n",
      "116\n",
      "Longitud a leer: 83\n",
      "CONTENIDO ARTÍCULO\n",
      "117\n",
      "117\n",
      "Longitud a leer: 303\n",
      "CONTENIDO ARTÍCULO\n",
      "118\n",
      "118\n",
      "Longitud a leer: 90\n",
      "CONTENIDO ARTÍCULO\n",
      "119\n",
      "119\n",
      "Longitud a leer: 216\n",
      "CONTENIDO ARTÍCULO\n",
      "120\n",
      "120\n",
      "Longitud a leer: 261\n",
      "CONTENIDO ARTÍCULO\n",
      "121\n",
      "121\n",
      "Longitud a leer: 156\n",
      "CONTENIDO ARTÍCULO\n",
      "122\n",
      "122\n",
      "Longitud a leer: 164\n",
      "CONTENIDO ARTÍCULO\n",
      "123\n",
      "123\n",
      "Longitud a leer: 154\n",
      "CONTENIDO ARTÍCULO\n",
      "124\n",
      "124\n",
      "Longitud a leer: 247\n",
      "CONTENIDO ARTÍCULO\n",
      "125\n",
      "125\n",
      "Longitud a leer: 198\n",
      "CONTENIDO ARTÍCULO\n",
      "126\n",
      "126\n",
      "Longitud a leer: 129\n",
      "CONTENIDO ARTÍCULO\n",
      "127\n",
      "127\n",
      "Longitud a leer: 165\n",
      "CONTENIDO ARTÍCULO\n",
      "128\n",
      "128\n",
      "Longitud a leer: 209\n",
      "CONTENIDO ARTÍCULO\n",
      "129\n",
      "129\n",
      "Longitud a leer: 164\n",
      "CONTENIDO ARTÍCULO\n",
      "130\n",
      "130\n",
      "Longitud a leer: 162\n",
      "CONTENIDO ARTÍCULO\n",
      "131\n",
      "131\n",
      "Longitud a leer: 166\n",
      "CONTENIDO ARTÍCULO\n",
      "132\n",
      "132\n",
      "Longitud a leer: 158\n",
      "CONTENIDO ARTÍCULO\n",
      "133\n",
      "133\n",
      "Longitud a leer: 272\n",
      "CONTENIDO ARTÍCULO\n",
      "134\n",
      "134\n",
      "Longitud a leer: 174\n",
      "CONTENIDO ARTÍCULO\n",
      "135\n",
      "135\n",
      "Longitud a leer: 268\n",
      "CONTENIDO ARTÍCULO\n",
      "136\n",
      "136\n",
      "Longitud a leer: 129\n",
      "CONTENIDO ARTÍCULO\n",
      "137\n",
      "137\n",
      "Longitud a leer: 151\n",
      "CONTENIDO ARTÍCULO\n",
      "138\n",
      "138\n",
      "Longitud a leer: 154\n",
      "CONTENIDO ARTÍCULO\n",
      "139\n",
      "139\n",
      "Longitud a leer: 225\n",
      "CONTENIDO ARTÍCULO\n",
      "140\n",
      "140\n",
      "Longitud a leer: 148\n",
      "CONTENIDO ARTÍCULO\n",
      "141\n",
      "141\n",
      "Longitud a leer: 157\n",
      "CONTENIDO ARTÍCULO\n",
      "142\n",
      "142\n",
      "Longitud a leer: 190\n",
      "CONTENIDO ARTÍCULO\n",
      "143\n",
      "143\n",
      "Longitud a leer: 200\n",
      "CONTENIDO ARTÍCULO\n",
      "144\n",
      "144\n",
      "Longitud a leer: 203\n",
      "CONTENIDO ARTÍCULO\n",
      "145\n",
      "145\n",
      "Longitud a leer: 158\n",
      "CONTENIDO ARTÍCULO\n",
      "146\n",
      "146\n",
      "Longitud a leer: 204\n",
      "CONTENIDO ARTÍCULO\n",
      "147\n",
      "147\n",
      "Longitud a leer: 149\n",
      "CONTENIDO ARTÍCULO\n",
      "148\n",
      "148\n",
      "Longitud a leer: 122\n",
      "CONTENIDO ARTÍCULO\n",
      "149\n",
      "149\n",
      "Longitud a leer: 234\n",
      "CONTENIDO ARTÍCULO\n",
      "150\n",
      "150\n",
      "Longitud a leer: 257\n",
      "CONTENIDO ARTÍCULO\n",
      "151\n",
      "151\n",
      "Longitud a leer: 129\n",
      "CONTENIDO ARTÍCULO\n",
      "152\n",
      "152\n",
      "Longitud a leer: 205\n",
      "CONTENIDO ARTÍCULO\n",
      "153\n",
      "153\n",
      "Longitud a leer: 196\n",
      "CONTENIDO ARTÍCULO\n",
      "154\n",
      "154\n",
      "Longitud a leer: 197\n",
      "CONTENIDO ARTÍCULO\n",
      "155\n",
      "155\n",
      "Longitud a leer: 271\n",
      "CONTENIDO ARTÍCULO\n",
      "156\n",
      "156\n",
      "Longitud a leer: 155\n",
      "CONTENIDO ARTÍCULO\n",
      "157\n",
      "157\n",
      "Longitud a leer: 216\n",
      "CONTENIDO ARTÍCULO\n",
      "158\n",
      "158\n",
      "Longitud a leer: 202\n",
      "CONTENIDO ARTÍCULO\n",
      "159\n",
      "159\n",
      "Longitud a leer: 201\n",
      "CONTENIDO ARTÍCULO\n",
      "160\n",
      "160\n",
      "Longitud a leer: 139\n",
      "CONTENIDO ARTÍCULO\n",
      "161\n",
      "161\n",
      "Longitud a leer: 208\n",
      "CONTENIDO ARTÍCULO\n",
      "162\n",
      "162\n",
      "Longitud a leer: 145\n",
      "CONTENIDO ARTÍCULO\n",
      "163\n",
      "163\n",
      "Longitud a leer: 158\n",
      "CONTENIDO ARTÍCULO\n",
      "164\n",
      "164\n",
      "Longitud a leer: 165\n",
      "CONTENIDO ARTÍCULO\n",
      "165\n",
      "165\n",
      "Longitud a leer: 178\n",
      "CONTENIDO ARTÍCULO\n",
      "166\n",
      "166\n",
      "Longitud a leer: 248\n",
      "CONTENIDO ARTÍCULO\n",
      "167\n",
      "167\n",
      "Longitud a leer: 163\n",
      "CONTENIDO ARTÍCULO\n",
      "168\n",
      "168\n",
      "Longitud a leer: 105\n",
      "CONTENIDO ARTÍCULO\n",
      "169\n",
      "169\n",
      "Longitud a leer: 249\n",
      "CONTENIDO ARTÍCULO\n",
      "170\n",
      "170\n",
      "Longitud a leer: 255\n",
      "CONTENIDO ARTÍCULO\n",
      "171\n",
      "171\n",
      "Longitud a leer: 154\n",
      "CONTENIDO ARTÍCULO\n",
      "172\n",
      "172\n",
      "Longitud a leer: 75\n",
      "CONTENIDO ARTÍCULO\n",
      "173\n",
      "173\n",
      "Longitud a leer: 235\n",
      "CONTENIDO ARTÍCULO\n",
      "174\n",
      "174\n",
      "Longitud a leer: 109\n",
      "CONTENIDO ARTÍCULO\n",
      "175\n",
      "175\n",
      "Longitud a leer: 221\n",
      "CONTENIDO ARTÍCULO\n",
      "176\n",
      "176\n",
      "Longitud a leer: 239\n",
      "CONTENIDO ARTÍCULO\n",
      "177\n",
      "177\n",
      "Longitud a leer: 235\n",
      "CONTENIDO ARTÍCULO\n",
      "178\n",
      "178\n",
      "Longitud a leer: 126\n",
      "CONTENIDO ARTÍCULO\n",
      "179\n",
      "179\n",
      "Longitud a leer: 148\n",
      "CONTENIDO ARTÍCULO\n",
      "180\n",
      "180\n",
      "Longitud a leer: 130\n",
      "CONTENIDO ARTÍCULO\n",
      "181\n",
      "181\n",
      "Longitud a leer: 207\n",
      "CONTENIDO ARTÍCULO\n",
      "182\n",
      "182\n",
      "Longitud a leer: 117\n",
      "CONTENIDO ARTÍCULO\n",
      "183\n",
      "183\n",
      "Longitud a leer: 134\n",
      "CONTENIDO ARTÍCULO\n",
      "184\n",
      "184\n",
      "Longitud a leer: 152\n",
      "CONTENIDO ARTÍCULO\n",
      "185\n",
      "185\n",
      "Longitud a leer: 211\n",
      "CONTENIDO ARTÍCULO\n",
      "186\n",
      "186\n",
      "Longitud a leer: 129\n",
      "CONTENIDO ARTÍCULO\n",
      "187\n",
      "187\n",
      "Longitud a leer: 267\n",
      "CONTENIDO ARTÍCULO\n",
      "188\n",
      "188\n",
      "Longitud a leer: 229\n",
      "CONTENIDO ARTÍCULO\n",
      "189\n",
      "189\n",
      "Longitud a leer: 237\n",
      "CONTENIDO ARTÍCULO\n",
      "190\n",
      "190\n",
      "Longitud a leer: 214\n",
      "CONTENIDO ARTÍCULO\n",
      "191\n",
      "191\n",
      "Longitud a leer: 99\n",
      "CONTENIDO ARTÍCULO\n",
      "192\n",
      "192\n",
      "Longitud a leer: 275\n",
      "CONTENIDO ARTÍCULO\n",
      "193\n",
      "193\n",
      "Longitud a leer: 162\n",
      "CONTENIDO ARTÍCULO\n",
      "194\n",
      "194\n",
      "Longitud a leer: 143\n",
      "CONTENIDO ARTÍCULO\n",
      "195\n",
      "195\n",
      "Longitud a leer: 196\n",
      "CONTENIDO ARTÍCULO\n",
      "196\n",
      "196\n",
      "Longitud a leer: 241\n",
      "CONTENIDO ARTÍCULO\n",
      "197\n",
      "197\n",
      "Longitud a leer: 100\n",
      "CONTENIDO ARTÍCULO\n",
      "198\n",
      "198\n",
      "Longitud a leer: 153\n",
      "CONTENIDO ARTÍCULO\n",
      "199\n",
      "199\n",
      "Longitud a leer: 203\n",
      "CONTENIDO ARTÍCULO\n",
      "200\n",
      "200\n",
      "Longitud a leer: 197\n",
      "CONTENIDO ARTÍCULO\n",
      "201\n",
      "201\n",
      "Longitud a leer: 156\n",
      "CONTENIDO ARTÍCULO\n",
      "202\n",
      "202\n",
      "Longitud a leer: 183\n",
      "CONTENIDO ARTÍCULO\n",
      "203\n",
      "203\n",
      "Longitud a leer: 140\n",
      "CONTENIDO ARTÍCULO\n",
      "204\n",
      "204\n",
      "Longitud a leer: 195\n",
      "CONTENIDO ARTÍCULO\n",
      "205\n",
      "205\n",
      "Longitud a leer: 205\n",
      "CONTENIDO ARTÍCULO\n",
      "206\n",
      "206\n",
      "Longitud a leer: 277\n",
      "CONTENIDO ARTÍCULO\n",
      "207\n",
      "207\n",
      "Longitud a leer: 233\n",
      "CONTENIDO ARTÍCULO\n",
      "208\n",
      "208\n",
      "Longitud a leer: 138\n",
      "CONTENIDO ARTÍCULO\n",
      "209\n",
      "209\n",
      "Longitud a leer: 278\n",
      "CONTENIDO ARTÍCULO\n",
      "210\n",
      "210\n",
      "Longitud a leer: 179\n",
      "CONTENIDO ARTÍCULO\n",
      "211\n",
      "211\n",
      "Longitud a leer: 194\n",
      "CONTENIDO ARTÍCULO\n",
      "212\n",
      "212\n",
      "Longitud a leer: 217\n",
      "CONTENIDO ARTÍCULO\n",
      "213\n",
      "213\n",
      "Longitud a leer: 201\n",
      "CONTENIDO ARTÍCULO\n",
      "214\n",
      "214\n",
      "Longitud a leer: 162\n",
      "CONTENIDO ARTÍCULO\n",
      "215\n",
      "215\n",
      "Longitud a leer: 131\n",
      "CONTENIDO ARTÍCULO\n",
      "216\n",
      "216\n",
      "Longitud a leer: 223\n",
      "CONTENIDO ARTÍCULO\n",
      "217\n",
      "217\n",
      "Longitud a leer: 128\n",
      "CONTENIDO ARTÍCULO\n",
      "218\n",
      "218\n",
      "Longitud a leer: 145\n",
      "CONTENIDO ARTÍCULO\n",
      "219\n",
      "219\n",
      "Longitud a leer: 167\n",
      "CONTENIDO ARTÍCULO\n",
      "220\n",
      "220\n",
      "Longitud a leer: 129\n",
      "CONTENIDO ARTÍCULO\n",
      "221\n",
      "221\n",
      "Longitud a leer: 84\n",
      "CONTENIDO ARTÍCULO\n",
      "222\n",
      "222\n",
      "Longitud a leer: 189\n",
      "CONTENIDO ARTÍCULO\n",
      "223\n",
      "223\n",
      "Longitud a leer: 155\n",
      "CONTENIDO ARTÍCULO\n",
      "224\n",
      "224\n",
      "Longitud a leer: 175\n",
      "CONTENIDO ARTÍCULO\n",
      "225\n",
      "225\n",
      "Longitud a leer: 273\n",
      "CONTENIDO ARTÍCULO\n",
      "226\n",
      "226\n",
      "Longitud a leer: 153\n",
      "CONTENIDO ARTÍCULO\n",
      "227\n",
      "227\n",
      "Longitud a leer: 164\n",
      "CONTENIDO ARTÍCULO\n",
      "228\n",
      "228\n",
      "Longitud a leer: 181\n",
      "CONTENIDO ARTÍCULO\n",
      "229\n",
      "229\n",
      "Longitud a leer: 272\n",
      "CONTENIDO ARTÍCULO\n",
      "230\n",
      "230\n",
      "Longitud a leer: 123\n",
      "CONTENIDO ARTÍCULO\n",
      "231\n",
      "231\n",
      "Longitud a leer: 196\n",
      "CONTENIDO ARTÍCULO\n",
      "232\n",
      "232\n",
      "Longitud a leer: 127\n",
      "CONTENIDO ARTÍCULO\n",
      "233\n",
      "233\n",
      "Longitud a leer: 117\n",
      "CONTENIDO ARTÍCULO\n",
      "234\n",
      "234\n",
      "Longitud a leer: 154\n",
      "CONTENIDO ARTÍCULO\n",
      "235\n",
      "235\n",
      "Longitud a leer: 151\n",
      "CONTENIDO ARTÍCULO\n",
      "236\n",
      "236\n",
      "Longitud a leer: 136\n",
      "CONTENIDO ARTÍCULO\n",
      "237\n",
      "237\n",
      "Longitud a leer: 176\n",
      "CONTENIDO ARTÍCULO\n",
      "238\n",
      "238\n",
      "Longitud a leer: 277\n",
      "CONTENIDO ARTÍCULO\n",
      "239\n",
      "239\n",
      "Longitud a leer: 111\n",
      "CONTENIDO ARTÍCULO\n",
      "240\n",
      "240\n",
      "Longitud a leer: 172\n",
      "CONTENIDO ARTÍCULO\n",
      "241\n",
      "241\n",
      "Longitud a leer: 148\n",
      "CONTENIDO ARTÍCULO\n",
      "242\n",
      "242\n",
      "Longitud a leer: 108\n",
      "CONTENIDO ARTÍCULO\n",
      "243\n",
      "243\n",
      "Longitud a leer: 106\n",
      "CONTENIDO ARTÍCULO\n",
      "244\n",
      "244\n",
      "Longitud a leer: 231\n",
      "CONTENIDO ARTÍCULO\n",
      "245\n",
      "245\n",
      "Longitud a leer: 129\n",
      "CONTENIDO ARTÍCULO\n",
      "246\n",
      "246\n",
      "Longitud a leer: 212\n",
      "CONTENIDO ARTÍCULO\n",
      "247\n",
      "247\n",
      "Longitud a leer: 112\n",
      "CONTENIDO ARTÍCULO\n",
      "248\n",
      "248\n",
      "Longitud a leer: 200\n",
      "CONTENIDO ARTÍCULO\n",
      "249\n",
      "249\n",
      "Longitud a leer: 155\n",
      "CONTENIDO ARTÍCULO\n",
      "250\n",
      "250\n",
      "Longitud a leer: 263\n",
      "CONTENIDO ARTÍCULO\n",
      "251\n",
      "251\n",
      "Longitud a leer: 184\n",
      "CONTENIDO ARTÍCULO\n",
      "252\n",
      "252\n",
      "Longitud a leer: 140\n",
      "CONTENIDO ARTÍCULO\n",
      "253\n",
      "253\n",
      "Longitud a leer: 111\n",
      "CONTENIDO ARTÍCULO\n",
      "254\n",
      "254\n",
      "Longitud a leer: 109\n",
      "CONTENIDO ARTÍCULO\n",
      "255\n",
      "255\n",
      "Longitud a leer: 207\n",
      "CONTENIDO ARTÍCULO\n",
      "256\n",
      "256\n",
      "Longitud a leer: 219\n",
      "CONTENIDO ARTÍCULO\n",
      "257\n",
      "257\n",
      "Longitud a leer: 145\n",
      "CONTENIDO ARTÍCULO\n",
      "258\n",
      "258\n",
      "Longitud a leer: 238\n",
      "CONTENIDO ARTÍCULO\n",
      "259\n",
      "259\n",
      "Longitud a leer: 149\n",
      "CONTENIDO ARTÍCULO\n",
      "260\n",
      "260\n",
      "Longitud a leer: 216\n",
      "CONTENIDO ARTÍCULO\n",
      "261\n",
      "261\n",
      "Longitud a leer: 219\n",
      "CONTENIDO ARTÍCULO\n",
      "262\n",
      "262\n",
      "Longitud a leer: 199\n",
      "CONTENIDO ARTÍCULO\n",
      "263\n",
      "263\n",
      "Longitud a leer: 63\n",
      "CONTENIDO ARTÍCULO\n",
      "264\n",
      "264\n",
      "Longitud a leer: 157\n",
      "CONTENIDO ARTÍCULO\n",
      "265\n",
      "265\n",
      "Longitud a leer: 120\n",
      "CONTENIDO ARTÍCULO\n",
      "266\n",
      "266\n",
      "Longitud a leer: 240\n",
      "CONTENIDO ARTÍCULO\n",
      "267\n",
      "267\n",
      "Longitud a leer: 305\n",
      "CONTENIDO ARTÍCULO\n",
      "268\n",
      "268\n",
      "Longitud a leer: 188\n",
      "CONTENIDO ARTÍCULO\n",
      "269\n",
      "269\n",
      "Longitud a leer: 121\n",
      "CONTENIDO ARTÍCULO\n",
      "270\n",
      "270\n",
      "Longitud a leer: 288\n",
      "CONTENIDO ARTÍCULO\n",
      "271\n",
      "271\n",
      "Longitud a leer: 127\n",
      "CONTENIDO ARTÍCULO\n",
      "272\n",
      "272\n",
      "Longitud a leer: 167\n",
      "CONTENIDO ARTÍCULO\n",
      "273\n",
      "273\n",
      "Longitud a leer: 215\n",
      "CONTENIDO ARTÍCULO\n",
      "274\n",
      "274\n",
      "Longitud a leer: 175\n",
      "CONTENIDO ARTÍCULO\n",
      "275\n",
      "275\n",
      "Longitud a leer: 141\n",
      "CONTENIDO ARTÍCULO\n",
      "276\n",
      "276\n",
      "Longitud a leer: 132\n",
      "CONTENIDO ARTÍCULO\n",
      "277\n",
      "277\n",
      "Longitud a leer: 162\n",
      "CONTENIDO ARTÍCULO\n",
      "278\n",
      "278\n",
      "Longitud a leer: 140\n",
      "CONTENIDO ARTÍCULO\n",
      "279\n",
      "279\n",
      "Longitud a leer: 127\n",
      "CONTENIDO ARTÍCULO\n",
      "280\n",
      "280\n",
      "Longitud a leer: 198\n",
      "CONTENIDO ARTÍCULO\n",
      "281\n",
      "281\n",
      "Longitud a leer: 172\n",
      "CONTENIDO ARTÍCULO\n",
      "282\n",
      "282\n",
      "Longitud a leer: 216\n",
      "CONTENIDO ARTÍCULO\n",
      "283\n",
      "283\n",
      "Longitud a leer: 185\n",
      "CONTENIDO ARTÍCULO\n",
      "284\n",
      "284\n",
      "Longitud a leer: 125\n",
      "CONTENIDO ARTÍCULO\n",
      "285\n",
      "285\n",
      "Longitud a leer: 142\n",
      "CONTENIDO ARTÍCULO\n",
      "286\n",
      "286\n",
      "Longitud a leer: 173\n",
      "CONTENIDO ARTÍCULO\n",
      "287\n",
      "287\n",
      "Longitud a leer: 171\n",
      "CONTENIDO ARTÍCULO\n",
      "288\n",
      "288\n",
      "Longitud a leer: 248\n",
      "CONTENIDO ARTÍCULO\n",
      "289\n",
      "289\n",
      "Longitud a leer: 217\n",
      "CONTENIDO ARTÍCULO\n",
      "290\n",
      "290\n",
      "Longitud a leer: 178\n",
      "CONTENIDO ARTÍCULO\n",
      "291\n",
      "291\n",
      "Longitud a leer: 238\n",
      "CONTENIDO ARTÍCULO\n",
      "292\n",
      "292\n",
      "Longitud a leer: 111\n",
      "CONTENIDO ARTÍCULO\n",
      "293\n",
      "293\n",
      "Longitud a leer: 269\n",
      "CONTENIDO ARTÍCULO\n",
      "294\n",
      "294\n",
      "Longitud a leer: 243\n",
      "CONTENIDO ARTÍCULO\n",
      "295\n",
      "295\n",
      "Longitud a leer: 150\n",
      "CONTENIDO ARTÍCULO\n",
      "296\n",
      "296\n",
      "Longitud a leer: 124\n",
      "CONTENIDO ARTÍCULO\n",
      "297\n",
      "297\n",
      "Longitud a leer: 289\n",
      "CONTENIDO ARTÍCULO\n",
      "298\n",
      "298\n",
      "Longitud a leer: 173\n",
      "CONTENIDO ARTÍCULO\n",
      "299\n",
      "299\n",
      "Longitud a leer: 144\n",
      "CONTENIDO ARTÍCULO\n",
      "300\n",
      "300\n",
      "Longitud a leer: 120\n",
      "CONTENIDO ARTÍCULO\n",
      "301\n",
      "301\n",
      "Longitud a leer: 127\n",
      "CONTENIDO ARTÍCULO\n",
      "302\n",
      "302\n",
      "Longitud a leer: 116\n",
      "CONTENIDO ARTÍCULO\n",
      "303\n",
      "303\n",
      "Longitud a leer: 143\n",
      "CONTENIDO ARTÍCULO\n",
      "304\n",
      "304\n",
      "Longitud a leer: 184\n",
      "CONTENIDO ARTÍCULO\n",
      "305\n",
      "305\n",
      "Longitud a leer: 112\n",
      "CONTENIDO ARTÍCULO\n",
      "306\n",
      "306\n",
      "Longitud a leer: 89\n",
      "CONTENIDO ARTÍCULO\n",
      "307\n",
      "307\n",
      "Longitud a leer: 177\n",
      "CONTENIDO ARTÍCULO\n",
      "308\n",
      "308\n",
      "Longitud a leer: 101\n",
      "CONTENIDO ARTÍCULO\n",
      "309\n",
      "309\n",
      "Longitud a leer: 232\n",
      "CONTENIDO ARTÍCULO\n",
      "310\n",
      "310\n",
      "Longitud a leer: 181\n",
      "CONTENIDO ARTÍCULO\n",
      "311\n",
      "311\n",
      "Longitud a leer: 104\n",
      "CONTENIDO ARTÍCULO\n",
      "312\n",
      "312\n",
      "Longitud a leer: 132\n",
      "CONTENIDO ARTÍCULO\n",
      "313\n",
      "313\n",
      "Longitud a leer: 200\n",
      "CONTENIDO ARTÍCULO\n",
      "314\n",
      "314\n",
      "Longitud a leer: 137\n",
      "CONTENIDO ARTÍCULO\n",
      "315\n",
      "315\n",
      "Longitud a leer: 155\n",
      "CONTENIDO ARTÍCULO\n",
      "316\n",
      "316\n",
      "Longitud a leer: 178\n",
      "CONTENIDO ARTÍCULO\n",
      "317\n",
      "317\n",
      "Longitud a leer: 183\n",
      "CONTENIDO ARTÍCULO\n",
      "318\n",
      "318\n",
      "Longitud a leer: 169\n",
      "CONTENIDO ARTÍCULO\n",
      "319\n",
      "319\n",
      "Longitud a leer: 166\n",
      "CONTENIDO ARTÍCULO\n",
      "320\n",
      "320\n",
      "Longitud a leer: 186\n",
      "CONTENIDO ARTÍCULO\n",
      "321\n",
      "321\n",
      "Longitud a leer: 276\n",
      "CONTENIDO ARTÍCULO\n",
      "322\n",
      "322\n",
      "Longitud a leer: 208\n",
      "CONTENIDO ARTÍCULO\n",
      "323\n",
      "323\n",
      "Longitud a leer: 213\n",
      "CONTENIDO ARTÍCULO\n",
      "324\n",
      "324\n",
      "Longitud a leer: 192\n",
      "CONTENIDO ARTÍCULO\n",
      "325\n",
      "325\n",
      "Longitud a leer: 151\n",
      "CONTENIDO ARTÍCULO\n",
      "326\n",
      "326\n",
      "Longitud a leer: 159\n",
      "CONTENIDO ARTÍCULO\n",
      "327\n",
      "327\n",
      "Longitud a leer: 180\n",
      "CONTENIDO ARTÍCULO\n",
      "328\n",
      "328\n",
      "Longitud a leer: 98\n",
      "CONTENIDO ARTÍCULO\n",
      "329\n",
      "329\n",
      "Longitud a leer: 144\n",
      "CONTENIDO ARTÍCULO\n",
      "330\n",
      "330\n",
      "Longitud a leer: 126\n",
      "CONTENIDO ARTÍCULO\n",
      "331\n",
      "331\n",
      "Longitud a leer: 145\n",
      "CONTENIDO ARTÍCULO\n",
      "332\n",
      "332\n",
      "Longitud a leer: 172\n",
      "CONTENIDO ARTÍCULO\n",
      "333\n",
      "333\n",
      "Longitud a leer: 132\n",
      "CONTENIDO ARTÍCULO\n",
      "334\n",
      "334\n",
      "Longitud a leer: 192\n",
      "CONTENIDO ARTÍCULO\n",
      "335\n",
      "335\n",
      "Longitud a leer: 164\n",
      "CONTENIDO ARTÍCULO\n",
      "336\n",
      "336\n",
      "Longitud a leer: 107\n",
      "CONTENIDO ARTÍCULO\n",
      "337\n",
      "337\n",
      "Longitud a leer: 155\n",
      "CONTENIDO ARTÍCULO\n",
      "338\n",
      "338\n",
      "Longitud a leer: 163\n",
      "CONTENIDO ARTÍCULO\n",
      "339\n",
      "339\n",
      "Longitud a leer: 293\n",
      "CONTENIDO ARTÍCULO\n",
      "340\n",
      "340\n",
      "Longitud a leer: 112\n",
      "CONTENIDO ARTÍCULO\n",
      "341\n",
      "341\n",
      "Longitud a leer: 166\n",
      "CONTENIDO ARTÍCULO\n",
      "342\n",
      "342\n",
      "Longitud a leer: 133\n",
      "CONTENIDO ARTÍCULO\n",
      "343\n",
      "343\n",
      "Longitud a leer: 119\n",
      "CONTENIDO ARTÍCULO\n",
      "344\n",
      "344\n",
      "Longitud a leer: 170\n",
      "CONTENIDO ARTÍCULO\n",
      "345\n",
      "345\n",
      "Longitud a leer: 145\n",
      "CONTENIDO ARTÍCULO\n",
      "346\n",
      "346\n",
      "Longitud a leer: 241\n",
      "CONTENIDO ARTÍCULO\n",
      "347\n",
      "347\n",
      "Longitud a leer: 147\n",
      "CONTENIDO ARTÍCULO\n",
      "348\n",
      "348\n",
      "Longitud a leer: 174\n",
      "CONTENIDO ARTÍCULO\n",
      "349\n",
      "349\n",
      "Longitud a leer: 158\n",
      "CONTENIDO ARTÍCULO\n",
      "350\n",
      "350\n",
      "Longitud a leer: 189\n",
      "CONTENIDO ARTÍCULO\n",
      "351\n",
      "351\n",
      "Longitud a leer: 119\n",
      "CONTENIDO ARTÍCULO\n",
      "352\n",
      "352\n",
      "Longitud a leer: 184\n",
      "CONTENIDO ARTÍCULO\n",
      "353\n",
      "353\n",
      "Longitud a leer: 152\n",
      "CONTENIDO ARTÍCULO\n",
      "354\n",
      "354\n",
      "Longitud a leer: 212\n",
      "CONTENIDO ARTÍCULO\n",
      "355\n",
      "355\n",
      "Longitud a leer: 232\n",
      "CONTENIDO ARTÍCULO\n",
      "356\n",
      "356\n",
      "Longitud a leer: 162\n",
      "CONTENIDO ARTÍCULO\n",
      "357\n",
      "357\n",
      "Longitud a leer: 134\n",
      "CONTENIDO ARTÍCULO\n",
      "358\n",
      "358\n",
      "Longitud a leer: 240\n",
      "CONTENIDO ARTÍCULO\n",
      "359\n",
      "359\n",
      "Longitud a leer: 123\n",
      "CONTENIDO ARTÍCULO\n",
      "360\n",
      "360\n",
      "Longitud a leer: 111\n",
      "CONTENIDO ARTÍCULO\n",
      "361\n",
      "361\n",
      "Longitud a leer: 156\n",
      "CONTENIDO ARTÍCULO\n",
      "362\n",
      "362\n",
      "Longitud a leer: 108\n",
      "CONTENIDO ARTÍCULO\n",
      "363\n",
      "363\n",
      "Longitud a leer: 132\n",
      "CONTENIDO ARTÍCULO\n",
      "364\n",
      "364\n",
      "Longitud a leer: 134\n",
      "CONTENIDO ARTÍCULO\n",
      "365\n",
      "365\n",
      "Longitud a leer: 159\n",
      "CONTENIDO ARTÍCULO\n",
      "366\n",
      "366\n",
      "Longitud a leer: 148\n",
      "CONTENIDO ARTÍCULO\n",
      "367\n",
      "367\n",
      "Longitud a leer: 171\n",
      "CONTENIDO ARTÍCULO\n",
      "368\n",
      "368\n",
      "Longitud a leer: 164\n",
      "CONTENIDO ARTÍCULO\n",
      "369\n",
      "369\n",
      "Longitud a leer: 196\n",
      "CONTENIDO ARTÍCULO\n",
      "370\n",
      "370\n",
      "Longitud a leer: 250\n",
      "CONTENIDO ARTÍCULO\n",
      "371\n",
      "371\n",
      "Longitud a leer: 146\n",
      "CONTENIDO ARTÍCULO\n",
      "372\n",
      "372\n",
      "Longitud a leer: 178\n",
      "CONTENIDO ARTÍCULO\n",
      "373\n",
      "373\n",
      "Longitud a leer: 173\n",
      "CONTENIDO ARTÍCULO\n",
      "374\n",
      "374\n",
      "Longitud a leer: 127\n",
      "CONTENIDO ARTÍCULO\n",
      "375\n",
      "375\n",
      "Longitud a leer: 147\n",
      "CONTENIDO ARTÍCULO\n",
      "376\n",
      "376\n",
      "Longitud a leer: 87\n",
      "CONTENIDO ARTÍCULO\n",
      "377\n",
      "377\n",
      "Longitud a leer: 101\n",
      "CONTENIDO ARTÍCULO\n",
      "378\n",
      "378\n",
      "Longitud a leer: 239\n",
      "CONTENIDO ARTÍCULO\n",
      "379\n",
      "379\n",
      "Longitud a leer: 252\n",
      "CONTENIDO ARTÍCULO\n",
      "380\n",
      "380\n",
      "Longitud a leer: 212\n",
      "CONTENIDO ARTÍCULO\n",
      "381\n",
      "381\n",
      "Longitud a leer: 174\n",
      "CONTENIDO ARTÍCULO\n",
      "382\n",
      "382\n",
      "Longitud a leer: 209\n",
      "CONTENIDO ARTÍCULO\n",
      "383\n",
      "383\n",
      "Longitud a leer: 156\n",
      "CONTENIDO ARTÍCULO\n",
      "384\n",
      "384\n",
      "Longitud a leer: 157\n",
      "CONTENIDO ARTÍCULO\n",
      "385\n",
      "385\n",
      "Longitud a leer: 131\n",
      "CONTENIDO ARTÍCULO\n",
      "386\n",
      "386\n",
      "Longitud a leer: 162\n",
      "CONTENIDO ARTÍCULO\n",
      "387\n",
      "387\n",
      "Longitud a leer: 160\n",
      "CONTENIDO ARTÍCULO\n",
      "388\n",
      "388\n",
      "Longitud a leer: 148\n",
      "CONTENIDO ARTÍCULO\n",
      "389\n",
      "389\n",
      "Longitud a leer: 113\n",
      "CONTENIDO ARTÍCULO\n",
      "390\n",
      "390\n",
      "Longitud a leer: 157\n",
      "CONTENIDO ARTÍCULO\n",
      "391\n",
      "391\n",
      "Longitud a leer: 176\n",
      "CONTENIDO ARTÍCULO\n",
      "392\n",
      "392\n",
      "Longitud a leer: 168\n",
      "CONTENIDO ARTÍCULO\n",
      "393\n",
      "393\n",
      "Longitud a leer: 134\n",
      "CONTENIDO ARTÍCULO\n",
      "394\n",
      "394\n",
      "Longitud a leer: 171\n",
      "CONTENIDO ARTÍCULO\n",
      "395\n",
      "395\n",
      "Longitud a leer: 149\n",
      "CONTENIDO ARTÍCULO\n",
      "396\n",
      "396\n",
      "Longitud a leer: 131\n",
      "CONTENIDO ARTÍCULO\n",
      "397\n",
      "397\n",
      "Longitud a leer: 163\n",
      "CONTENIDO ARTÍCULO\n",
      "398\n",
      "398\n",
      "Longitud a leer: 86\n",
      "CONTENIDO ARTÍCULO\n",
      "399\n",
      "399\n",
      "Longitud a leer: 274\n",
      "CONTENIDO ARTÍCULO\n",
      "400\n",
      "400\n",
      "Longitud a leer: 96\n",
      "CONTENIDO ARTÍCULO\n",
      "401\n",
      "401\n",
      "Longitud a leer: 135\n",
      "CONTENIDO ARTÍCULO\n",
      "402\n",
      "402\n",
      "Longitud a leer: 131\n",
      "CONTENIDO ARTÍCULO\n",
      "403\n",
      "403\n",
      "Longitud a leer: 77\n",
      "CONTENIDO ARTÍCULO\n",
      "404\n",
      "404\n",
      "Longitud a leer: 145\n",
      "CONTENIDO ARTÍCULO\n",
      "405\n",
      "405\n",
      "Longitud a leer: 117\n",
      "CONTENIDO ARTÍCULO\n",
      "406\n",
      "406\n",
      "Longitud a leer: 101\n",
      "CONTENIDO ARTÍCULO\n",
      "407\n",
      "407\n",
      "Longitud a leer: 171\n",
      "CONTENIDO ARTÍCULO\n",
      "408\n",
      "408\n",
      "Longitud a leer: 195\n",
      "CONTENIDO ARTÍCULO\n",
      "409\n",
      "409\n",
      "Longitud a leer: 131\n",
      "CONTENIDO ARTÍCULO\n",
      "410\n",
      "410\n",
      "Longitud a leer: 115\n",
      "CONTENIDO ARTÍCULO\n",
      "411\n",
      "411\n",
      "Longitud a leer: 278\n",
      "CONTENIDO ARTÍCULO\n",
      "412\n",
      "412\n",
      "Longitud a leer: 201\n",
      "CONTENIDO ARTÍCULO\n",
      "413\n",
      "413\n",
      "Longitud a leer: 162\n",
      "CONTENIDO ARTÍCULO\n",
      "414\n",
      "414\n",
      "Longitud a leer: 140\n",
      "CONTENIDO ARTÍCULO\n",
      "415\n",
      "415\n",
      "Longitud a leer: 161\n",
      "CONTENIDO ARTÍCULO\n",
      "416\n",
      "416\n",
      "Longitud a leer: 215\n",
      "CONTENIDO ARTÍCULO\n",
      "417\n",
      "417\n",
      "Longitud a leer: 239\n",
      "CONTENIDO ARTÍCULO\n",
      "418\n",
      "418\n",
      "Longitud a leer: 190\n",
      "CONTENIDO ARTÍCULO\n",
      "419\n",
      "419\n",
      "Longitud a leer: 159\n",
      "CONTENIDO ARTÍCULO\n",
      "420\n",
      "420\n",
      "Longitud a leer: 166\n",
      "CONTENIDO ARTÍCULO\n",
      "421\n",
      "421\n",
      "Longitud a leer: 163\n",
      "CONTENIDO ARTÍCULO\n",
      "422\n",
      "422\n",
      "Longitud a leer: 150\n",
      "CONTENIDO ARTÍCULO\n",
      "423\n",
      "423\n",
      "Longitud a leer: 135\n",
      "CONTENIDO ARTÍCULO\n",
      "424\n",
      "424\n",
      "Longitud a leer: 140\n",
      "CONTENIDO ARTÍCULO\n",
      "425\n",
      "425\n",
      "Longitud a leer: 188\n",
      "CONTENIDO ARTÍCULO\n",
      "426\n",
      "426\n",
      "Longitud a leer: 251\n",
      "CONTENIDO ARTÍCULO\n",
      "427\n",
      "427\n",
      "Longitud a leer: 204\n",
      "CONTENIDO ARTÍCULO\n",
      "428\n",
      "428\n",
      "Longitud a leer: 115\n",
      "CONTENIDO ARTÍCULO\n",
      "429\n",
      "429\n",
      "Longitud a leer: 162\n",
      "CONTENIDO ARTÍCULO\n",
      "430\n",
      "430\n",
      "Longitud a leer: 188\n",
      "CONTENIDO ARTÍCULO\n",
      "431\n",
      "431\n",
      "Longitud a leer: 160\n",
      "CONTENIDO ARTÍCULO\n",
      "432\n",
      "432\n",
      "Longitud a leer: 253\n",
      "CONTENIDO ARTÍCULO\n",
      "433\n",
      "433\n",
      "Longitud a leer: 225\n",
      "CONTENIDO ARTÍCULO\n",
      "434\n",
      "434\n",
      "Longitud a leer: 177\n",
      "CONTENIDO ARTÍCULO\n",
      "435\n",
      "435\n",
      "Longitud a leer: 146\n",
      "CONTENIDO ARTÍCULO\n",
      "436\n",
      "436\n",
      "Longitud a leer: 132\n",
      "CONTENIDO ARTÍCULO\n",
      "437\n",
      "437\n",
      "Longitud a leer: 202\n",
      "CONTENIDO ARTÍCULO\n",
      "438\n",
      "438\n",
      "Longitud a leer: 179\n",
      "CONTENIDO ARTÍCULO\n",
      "439\n",
      "439\n",
      "Longitud a leer: 152\n",
      "CONTENIDO ARTÍCULO\n",
      "440\n",
      "440\n",
      "Longitud a leer: 177\n",
      "CONTENIDO ARTÍCULO\n",
      "441\n",
      "441\n",
      "Longitud a leer: 189\n",
      "CONTENIDO ARTÍCULO\n",
      "442\n",
      "442\n",
      "Longitud a leer: 251\n",
      "CONTENIDO ARTÍCULO\n",
      "443\n",
      "443\n",
      "Longitud a leer: 217\n",
      "CONTENIDO ARTÍCULO\n",
      "444\n",
      "444\n",
      "Longitud a leer: 260\n",
      "CONTENIDO ARTÍCULO\n",
      "445\n",
      "445\n",
      "Longitud a leer: 131\n",
      "CONTENIDO ARTÍCULO\n",
      "446\n",
      "446\n",
      "Longitud a leer: 242\n",
      "CONTENIDO ARTÍCULO\n",
      "447\n",
      "447\n",
      "Longitud a leer: 209\n",
      "Y ahora el cjto de validacion\n",
      "CONTENIDO ARTÍCULO\n",
      "0\n",
      "0\n",
      "Longitud a leer: 157\n",
      "CONTENIDO ARTÍCULO\n",
      "1\n",
      "1\n",
      "Longitud a leer: 209\n",
      "CONTENIDO ARTÍCULO\n",
      "2\n",
      "2\n",
      "Longitud a leer: 183\n",
      "CONTENIDO ARTÍCULO\n",
      "3\n",
      "3\n",
      "Longitud a leer: 151\n",
      "CONTENIDO ARTÍCULO\n",
      "4\n",
      "4\n",
      "Longitud a leer: 87\n",
      "CONTENIDO ARTÍCULO\n",
      "5\n",
      "5\n",
      "Longitud a leer: 166\n",
      "CONTENIDO ARTÍCULO\n",
      "6\n",
      "6\n",
      "Longitud a leer: 209\n",
      "CONTENIDO ARTÍCULO\n",
      "7\n",
      "7\n",
      "Longitud a leer: 248\n",
      "CONTENIDO ARTÍCULO\n",
      "8\n",
      "8\n",
      "Longitud a leer: 161\n",
      "CONTENIDO ARTÍCULO\n",
      "9\n",
      "9\n",
      "Longitud a leer: 221\n",
      "CONTENIDO ARTÍCULO\n",
      "10\n",
      "10\n",
      "Longitud a leer: 198\n",
      "CONTENIDO ARTÍCULO\n",
      "11\n",
      "11\n",
      "Longitud a leer: 188\n",
      "CONTENIDO ARTÍCULO\n",
      "12\n",
      "12\n",
      "Longitud a leer: 148\n",
      "CONTENIDO ARTÍCULO\n",
      "13\n",
      "13\n",
      "Longitud a leer: 155\n",
      "CONTENIDO ARTÍCULO\n",
      "14\n",
      "14\n",
      "Longitud a leer: 166\n",
      "CONTENIDO ARTÍCULO\n",
      "15\n",
      "15\n",
      "Longitud a leer: 168\n",
      "CONTENIDO ARTÍCULO\n",
      "16\n",
      "16\n",
      "Longitud a leer: 109\n",
      "CONTENIDO ARTÍCULO\n",
      "17\n",
      "17\n",
      "Longitud a leer: 171\n",
      "CONTENIDO ARTÍCULO\n",
      "18\n",
      "18\n",
      "Longitud a leer: 260\n",
      "CONTENIDO ARTÍCULO\n",
      "19\n",
      "19\n",
      "Longitud a leer: 159\n",
      "CONTENIDO ARTÍCULO\n",
      "20\n",
      "20\n",
      "Longitud a leer: 129\n",
      "CONTENIDO ARTÍCULO\n",
      "21\n",
      "21\n",
      "Longitud a leer: 160\n",
      "CONTENIDO ARTÍCULO\n",
      "22\n",
      "22\n",
      "Longitud a leer: 232\n",
      "CONTENIDO ARTÍCULO\n",
      "23\n",
      "23\n",
      "Longitud a leer: 121\n",
      "CONTENIDO ARTÍCULO\n",
      "24\n",
      "24\n",
      "Longitud a leer: 173\n",
      "CONTENIDO ARTÍCULO\n",
      "25\n",
      "25\n",
      "Longitud a leer: 269\n",
      "CONTENIDO ARTÍCULO\n",
      "26\n",
      "26\n",
      "Longitud a leer: 303\n",
      "CONTENIDO ARTÍCULO\n",
      "27\n",
      "27\n",
      "Longitud a leer: 193\n",
      "CONTENIDO ARTÍCULO\n",
      "28\n",
      "28\n",
      "Longitud a leer: 256\n",
      "CONTENIDO ARTÍCULO\n",
      "29\n",
      "29\n",
      "Longitud a leer: 176\n",
      "CONTENIDO ARTÍCULO\n",
      "30\n",
      "30\n",
      "Longitud a leer: 224\n",
      "CONTENIDO ARTÍCULO\n",
      "31\n",
      "31\n",
      "Longitud a leer: 164\n",
      "CONTENIDO ARTÍCULO\n",
      "32\n",
      "32\n",
      "Longitud a leer: 101\n",
      "CONTENIDO ARTÍCULO\n",
      "33\n",
      "33\n",
      "Longitud a leer: 132\n",
      "CONTENIDO ARTÍCULO\n",
      "34\n",
      "34\n",
      "Longitud a leer: 216\n",
      "CONTENIDO ARTÍCULO\n",
      "35\n",
      "35\n",
      "Longitud a leer: 202\n",
      "CONTENIDO ARTÍCULO\n",
      "36\n",
      "36\n",
      "Longitud a leer: 214\n",
      "CONTENIDO ARTÍCULO\n",
      "37\n",
      "37\n",
      "Longitud a leer: 197\n",
      "CONTENIDO ARTÍCULO\n",
      "38\n",
      "38\n",
      "Longitud a leer: 15\n",
      "CONTENIDO ARTÍCULO\n",
      "39\n",
      "39\n",
      "Longitud a leer: 191\n",
      "CONTENIDO ARTÍCULO\n",
      "40\n",
      "40\n",
      "Longitud a leer: 99\n",
      "CONTENIDO ARTÍCULO\n",
      "41\n",
      "41\n",
      "Longitud a leer: 155\n",
      "CONTENIDO ARTÍCULO\n",
      "42\n",
      "42\n",
      "Longitud a leer: 113\n",
      "CONTENIDO ARTÍCULO\n",
      "43\n",
      "43\n",
      "Longitud a leer: 123\n",
      "Indices Entrada Entrenamiento\n",
      "[[3028. 8390.  530. ...    0.    0.    0.]\n",
      " [4375. 8280. 4998. ...    0.    0.    0.]\n",
      " [ 609. 8656. 3028. ...    0.    0.    0.]\n",
      " ...\n",
      " [ 152. 1535.  512. ...    0.    0.    0.]\n",
      " [6772. 7039. 9329. ...    0.    0.    0.]\n",
      " [ 935. 6010. 1544. ...    0.    0.    0.]]\n",
      "<class 'numpy.ndarray'>\n",
      "448\n",
      "448\n",
      "448\n"
     ]
    }
   ],
   "source": [
    "# Cuántas dimensiones tienen nuestros word vectors (50, 100, 200 o 300)\n",
    "# Tamaño de salida del embedding\n",
    "EMBEDDING_DIM = 200\n",
    "# El tamaño máximo de nuestro vocabulario (se escogerán las más frecuentes)\n",
    "WORDS_IN_VOCAB = len(diccionarioLengua)\n",
    "# El tamaño de la frase más larga con la que alimentar el modelo\n",
    "MAX_SEQUENCE_LENGTH = 333\n",
    "\n",
    "entradaEntrenamiento, entradaEntrenamientoIndices, salidaEsperada, salidaEsperadaCompressed = textoaDiccionario(listaTitlesTotalPorArticulo, listaTotalAbstractsPorArticulo, listaTotalKeywordsPorArticulo, MAX_SEQUENCE_LENGTH)\n",
    "print(\"Y ahora el cjto de validacion\")\n",
    "entradaTest, entradaTestIndices, salidaEsperadaTest, salidaEsperadaCompressedTest  = textoaDiccionario(listaTestTitlesPorArticulo, listaTestAbstractsPorArticulo, listaTestKeywordsPorArticulo, MAX_SEQUENCE_LENGTH)\n",
    "#print(entradaEntrenamiento)\n",
    "#print(\"Valor de entrada 0:\")\n",
    "#print(entradaEntrenamiento[0])\n",
    "#print(\"Salida esperada (diccionario general)\")\n",
    "#print(salidaEsperada[0])\n",
    "print(\"Indices Entrada Entrenamiento\")\n",
    "print(entradaEntrenamientoIndices)\n",
    "print(type(entradaEntrenamientoIndices))\n",
    "print(len(entradaEntrenamientoIndices))\n",
    "print(len(entradaEntrenamiento))\n",
    "print(len(listaTitlesTotalPorArticulo))\n",
    "#print(len(entradaEntrenamientoIndices))\n",
    "#print(entradaEntrenamientoIndices.shape())\n",
    "#print(\"Salida esperada (optimizada)\")\n",
    "#print(salidaEsperadaCompressed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d98eda",
   "metadata": {},
   "source": [
    "Ahora la entrada es importante que la normalizemos para evitar una explosión del gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e74f89dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hecho\n"
     ]
    }
   ],
   "source": [
    "entradaEntrenamientoIndicesNormalizados = entradaEntrenamientoIndices / len(diccionarioLengua)\n",
    "entradaTestIndicesNormalizados = entradaTestIndices / len(diccionarioLengua)\n",
    "print(\"Hecho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "680885c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "salidaEsperadaCompressedAjustada = np.array(salidaEsperadaCompressed)\n",
    "print(salidaEsperadaCompressedAjustada[0])\n",
    "salidaEsperadaCompressedAjustadaTest = np.array(salidaEsperadaCompressedTest)\n",
    "print(salidaEsperadaCompressedAjustadaTest[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c24cd94",
   "metadata": {},
   "source": [
    "FASE 2: RRNN DE CONVOLUCIÓN\n",
    "\n",
    "ENTRADA: matriz de 400 palabras, cada una con un vector identificativo.\n",
    "\n",
    "SALIDA: capa de longitud igual al número de palabras clave que estamos buscando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "150c78e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 11\u001b[0m\n\u001b[0;32m      6\u001b[0m word_index \u001b[38;5;241m=\u001b[39m  tokenizer\u001b[38;5;241m.\u001b[39mword_index\n\u001b[0;32m      7\u001b[0m index_word \u001b[38;5;241m=\u001b[39m {index: word \u001b[38;5;28;01mfor\u001b[39;00m word, index \u001b[38;5;129;01min\u001b[39;00m word_index\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m      9\u001b[0m sentencias \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     10\u001b[0m     [word_index[w] \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mtext_to_word_sequence(text)]\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcorpus\u001b[49m\n\u001b[0;32m     12\u001b[0m ]\n\u001b[0;32m     13\u001b[0m vocabularioz_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(word_index) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBiggest index: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mmax\u001b[39m(seq)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mseq\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39msequences\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(seq)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m>\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "# TO-DO Esto es otra forma alternativa de pasar el texto a palabras, pero ya lo hicimos\n",
    "\n",
    "corpus = \n",
    "tokenizer =   tf.keras.preprocessing.text.Tokenizer(num_words=WORDS_IN_VOCAB)\n",
    "tokenizer.fit_on_texts(x_dataframe.abstract)\n",
    "sequences =   tokenizer.texts_to_sequences(x_dataframe.abstract) #[a, b] for a,b in zip(x_dataframe.title, x_dataframe.abstract)\n",
    "word_index =  tokenizer.word_index\n",
    "index_word = {index: word for word, index in word_index.items()}\n",
    "\n",
    "sentencias = [\n",
    "    [word_index[w] for w in tf.keras.preprocessing.text.text_to_word_sequence(text)]\n",
    "    for text in corpus\n",
    "]\n",
    "vocabularioz_size = len(word_index) + 1\n",
    "\n",
    "print(f'Biggest index: {max(max(seq) for seq in sequences if len(seq) > 0)}')\n",
    "print(f'Unique tokens: {len(word_index)}')\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794fc919",
   "metadata": {},
   "source": [
    "Creamos checkpoints para guardar la versión que tenga el menor error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e80fc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'cnn-Algigantix/model-{loss:.4f}.h5',\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b01d614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TO-DO 1º AUTO-ENCODER?? Primero meto las palabras y debe sacarme las mismas palabras\n",
    "# TO-DO añade embedding\n",
    "print(\"Iniciando red de Convolución\")\n",
    "print(f\"La shape de entrada es: {len(entradaEntrenamiento)} artículos, {len(entradaEntrenamiento[0])} palabras por artículo, {len(entradaEntrenamiento[0][0])} caracteres por palabra\")\n",
    "print(f\"La salida esperada tiene dimensiones {len(salidaEsperadaCompressedAjustada)} artículos, {len(salidaEsperadaCompressedAjustada[0])} claves\")\n",
    "#tf.keras.layers.Embedding(input_dim=1000, output_dim=64)\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    input_dim=len(diccionarioLengua),\n",
    "    output_dim=EMBEDDING_DIM,\n",
    "    input_length=MAX_SEQUENCE_LENGTH,\n",
    ")\n",
    "#print('Loading embedding with GloVe vectors... ', end='')\n",
    "# Cargamos sólo las palabras elegidas de nuestro conjunto de datos\n",
    "#num_words = min(MAX_VOCAB_SIZE, len(word_index) + 1)\n",
    "#embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "#for word, i in word_index.items():\n",
    "#    if i < MAX_VOCAB_SIZE:\n",
    "#        embedding_vector = word2vec.get(word)\n",
    "#        if embedding_vector is not None:\n",
    "#            embedding_matrix[i] = embedding_vector\n",
    "#\n",
    "# Creamos la capa de embedding\n",
    "#embedding_layer = tf.keras.layers.Embedding(\n",
    "#  input_dim=num_words,\n",
    "#  output_dim=EMBEDDING_DIM,\n",
    "#  weights=[embedding_matrix],\n",
    "#  input_length=MAX_SEQUENCE_LENGTH,\n",
    "#  trainable=False,\n",
    "#)\n",
    "print('done')\n",
    "\n",
    "LOAD_PREVIOUS = False\n",
    "\n",
    "checkpoints = sorted(glob.glob('cnn-Algigantix/*.h5'))\n",
    "if LOAD_PREVIOUS and checkpoints:\n",
    "    print(f'Loading previous model: {checkpoints[0]}')\n",
    "    model = tf.keras.models.load_model(checkpoints[0])\n",
    "else:\n",
    "    \n",
    "    input_ = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH, )) # len(entradaEntrenamiento[0][0])\n",
    "    x = embedding_layer(input_)\n",
    "    #x = tf.keras.layers.Conv1D(16, kernel_size=3, activation='relu')(x) #tf.keras.layers.LeakyReLU(alpha=0.1)\n",
    "    #x = tf.keras.layers.MaxPooling1D(pool_size=3, strides=3)(x)\n",
    "    #x = tf.keras.layers.Conv1D(16, kernel_size=4, activation='relu')(x)\n",
    "    x = tf.keras.layers.Conv1D(16, kernel_size=5, activation='relu')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(1648, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    #x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "    #x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(1648, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    output = tf.keras.layers.Dense(len(matrizSalidaSinKeywords), activation = 'sigmoid')(x) # sigmoid\n",
    "\n",
    "    model = tf.keras.Model(input_, output)\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', #tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#model = tf.keras.Sequential([\n",
    "#    # VECTOR 400 palabras cada una con un vector de todo ceros menos 1\n",
    "#    tf.keras.layers.Conv2D(\n",
    "#        input_shape=(len(entradaEntrenamiento[0]), len(entradaEntrenamiento[0][0]), 1),\n",
    "#        kernel_size=(3, 3),\n",
    "#        filters=1,\n",
    "#        activation='relu',\n",
    "#    ),\n",
    "#    #tf.keras.layers.Conv2D(\n",
    "#    #    kernel_size=(1, 1),\n",
    "#    #    filters=8,\n",
    "#    #    activation='relu',\n",
    "#    #),\n",
    "#    #tf.keras.layers.Conv2D(\n",
    "#    #    kernel_size=(1, 1),\n",
    "#    #    filters=8,\n",
    "#    #    activation='relu',\n",
    "#    #),\n",
    "#    tf.keras.layers.MaxPooling2D(\n",
    "#        pool_size=(3, 3),\n",
    "#        strides=(3, 3)\n",
    "#    ),\n",
    "#    #tf.keras.layers.Conv2D(\n",
    "#    #    kernel_size=(2, 1),\n",
    "#    #    filters=8,\n",
    "#    #    activation='relu',\n",
    "#    #),\n",
    "#    #tf.keras.layers.Conv2D(\n",
    "#    #    kernel_size=(2, 2),\n",
    "#    #    filters=8,\n",
    "#    #    activation='relu',\n",
    "#    #),\n",
    "#    #tf.keras.layers.MaxPooling2D(\n",
    "#    #    pool_size=(2, 2),\n",
    "#    #    strides=(2, 2)\n",
    "#    #),\n",
    "#    tf.keras.layers.Conv2D(\n",
    "#        kernel_size=(3, 1),\n",
    "#        filters=1,\n",
    "#        activation='relu',\n",
    "#    ),\n",
    "#    tf.keras.layers.Conv2D(\n",
    "#        kernel_size=(3, 2),\n",
    "#        filters=1,\n",
    "#        activation='relu',\n",
    "#    ),\n",
    "#    tf.keras.layers.Conv2D(\n",
    "#        kernel_size=(3, 3),\n",
    "#        filters=1,\n",
    "#        activation='relu',\n",
    "#    ),\n",
    "#    tf.keras.layers.Conv2D(\n",
    "#        kernel_size=(3, 4),\n",
    "#        filters=1,\n",
    "#        activation='relu',\n",
    "#    ),\n",
    "#    tf.keras.layers.MaxPooling2D(\n",
    "#        pool_size=(2, 2),\n",
    "#        strides=(2, 2)\n",
    "#    ),\n",
    "#    tf.keras.layers.Conv2D(\n",
    "#        kernel_size=(4, 1),\n",
    "#        filters=1,\n",
    "#        activation='relu',\n",
    "#    ),\n",
    "#    tf.keras.layers.Conv2D(\n",
    "#        kernel_size=(4, 2),\n",
    "#        filters=1,\n",
    "#        activation='relu',\n",
    "#    ),\n",
    "#    tf.keras.layers.Conv2D(\n",
    "#        kernel_size=(4, 3),\n",
    "#        filters=1,\n",
    "#        activation='relu',\n",
    "#    ),\n",
    "#    tf.keras.layers.Conv2D(\n",
    "#        kernel_size=(4, 4),\n",
    "#        filters=1,\n",
    "#        activation='relu',\n",
    "#    ),\n",
    "#    tf.keras.layers.MaxPooling2D(\n",
    "#        pool_size=(2, 2),\n",
    "#        strides=(2, 2)\n",
    "#    ),\n",
    "#    tf.keras.layers.Conv2D(\n",
    "#        kernel_size=(5, 1),\n",
    "#        filters=1,\n",
    "#        activation='relu',\n",
    "#    ),\n",
    "#    tf.keras.layers.Conv2D(\n",
    "#        kernel_size=(5, 2),\n",
    "#        filters=1,\n",
    "#        activation='relu',\n",
    "#    ),\n",
    "#    tf.keras.layers.Conv2D(\n",
    "#        kernel_size=(5, 3),\n",
    "#        filters=1,\n",
    "#        activation='relu',\n",
    "#    ),\n",
    "#    tf.keras.layers.Conv2D(\n",
    "#        kernel_size=(5, 4),\n",
    "#        filters=1,\n",
    "#        activation='relu',\n",
    "#    ),\n",
    "#    tf.keras.layers.MaxPooling2D(\n",
    "#        pool_size=(2, 2),\n",
    "#        strides=(2, 2)\n",
    "#    ),\n",
    "#    \n",
    "#    # La RRNN perceptrón multicapa, necesito aplanar\n",
    "#    tf.keras.layers.Flatten(),\n",
    "#    tf.keras.layers.Dense(2048, activation = 'relu'),\n",
    "#    tf.keras.layers.Dropout(0.5),\n",
    "#    tf.keras.layers.Dense(2048, activation = 'relu'),\n",
    "#    tf.keras.layers.Dropout(0.5),\n",
    "#    tf.keras.layers.Dense(len(matrizSalidaSinKeywords), activation = 'softmax'), #capa de n neuronas de método softmax\n",
    "#    #TO-DO estr uctura,  basate en AlexNet\n",
    "#    # len(misKeywordsRetornadas)\n",
    "#])\n",
    "#\n",
    "#model.compile(\n",
    "#    loss='categorical_crossentropy', #tf.keras.losses.CategoricalCrossentropy(),\n",
    "#    optimizer=tf.keras.optimizers.Adam(),\n",
    "#    metrics=[tf.keras.metrics.CategoricalAccuracy()]\n",
    "#)\n",
    "#\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8de57ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "entradaEntrenadaAjustada = np.array(entradaEntrenamiento)\n",
    "print(entradaEntrenadaAjustada[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bed73d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "entradaTestAjustada = np.array(entradaTest)\n",
    "print(entradaTestAjustada[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101a18f3",
   "metadata": {},
   "source": [
    "Ahora entrenamos la red de convolución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a8b512c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 2s 156ms/step - loss: nan - categorical_accuracy: 0.0000e+00 - val_loss: nan - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 151ms/step - loss: nan - categorical_accuracy: 0.0000e+00 - val_loss: nan - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 2s 155ms/step - loss: nan - categorical_accuracy: 0.0000e+00 - val_loss: nan - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 149ms/step - loss: nan - categorical_accuracy: 0.0000e+00 - val_loss: nan - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 156ms/step - loss: nan - categorical_accuracy: 0.0000e+00 - val_loss: nan - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "11/13 [========================>.....] - ETA: 0s - loss: nan - categorical_accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cnn_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#entradaEntrenadaAjustada,\u001b[39;49;00m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentradaEntrenamientoIndices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msalidaEsperadaCompressedAjustada\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnn_history = model.fit(\n",
    "    #entradaEntrenadaAjustada,\n",
    "    entradaEntrenamientoIndices,\n",
    "    salidaEsperadaCompressedAjustada,\n",
    "    epochs=50,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b67d4be7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mcnn_history\u001b[49m\u001b[38;5;241m.\u001b[39mhistory)\u001b[38;5;241m.\u001b[39mplot()\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(cnn_history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(cnn_history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal. loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cnn_history' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(cnn_history.history).plot()\n",
    "plt.plot(cnn_history.history['loss'], label='Train loss')\n",
    "plt.plot(cnn_history.history['val_loss'], label='Val. loss')\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(cnn_history.history['loss'], label='Train')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(cnn_history.history['categorical_accuracy'], label='Train')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(cnn_history.history['loss'], label='Training')\n",
    "plt.plot(cnn_history.history['val_loss'], label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(f'Training: {cnn_history.history[\"loss\"][-1]:.2f}, validation: {cnn_history.history[\"val_loss\"][-1]:.2f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(cnn_history.history['categorical_accuracy'], label='Training')\n",
    "plt.plot(cnn_history.history['val_categorical_accuracy'], label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(f'Training: {cnn_history.history[\"categorical_accuracy\"][-1]:.2f}, validation: {cnn_history.history[\"val_categorical_accuracy\"][-1]:.2f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc5a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_loss, cnn_acc = model.evaluate(entradaTestIndicesNormalizados, salidaEsperadaCompressedTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001e001c",
   "metadata": {},
   "source": [
    "Ahora tras haberlo entrenado lo guardamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef5ddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perceptronMulticape = tf.keras.Sequential() # TO-DO hacer el perceptrón multicapa por separado tras entrenar la convolucion\n",
    "\n",
    "model.save(\"cnn-Algigantix.h5\") # guardar\n",
    "tf.keras.load_model(\"cnn-Algigantix.h5\") # cargar \n",
    "\n",
    "#\n",
    "\n",
    "#\n",
    "#model.summary()\n",
    "#\n",
    "#\n",
    "#history = model.fit(\n",
    "# TO-DO\n",
    "#\n",
    "#)\n",
    "#\n",
    "#test_loss, test_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "789ab7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointRecurrent = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'rnn-Algigantix/model-{loss:.4f}.h5',\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b38b568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, None, 64)          622656    \n",
      "                                                                 \n",
      " simple_rnn_12 (SimpleRNN)   (None, None, 256)         82176     \n",
      "                                                                 \n",
      " simple_rnn_13 (SimpleRNN)   (None, None, 128)         49280     \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 256)              263168    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1535)              394495    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,411,775\n",
      "Trainable params: 1,411,775\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# FASE 3 RRNN RECURRENTE\n",
    "print(\"hello\")\n",
    "\n",
    "modelRRRNN = tf.keras.Sequential()\n",
    "modelRRRNN.add(tf.keras.layers.Embedding(input_dim=len(diccionarioLengua), output_dim=64))\n",
    "# La salida de GRU será un tensor 3D de dimensión (batch_size, timesteps, 256)\n",
    "modelRRRNN.add(tf.keras.layers.SimpleRNN(256, return_sequences=True))\n",
    "# La salida de SimpleRNN será un tensor 2D de dimensión (batch_size, 128)\n",
    "modelRRRNN.add(tf.keras.layers.SimpleRNN(128, return_sequences=True))\n",
    "\n",
    "#modelRRRNN.add(tf.keras.layers.LSTM(128))\n",
    "modelRRRNN.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)))\n",
    "modelRRRNN.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "modelRRRNN.add(tf.keras.layers.Dense(len(matrizSalidaSinKeywords), activation = 'sigmoid'))\n",
    "\n",
    "modelRRRNN.compile(\n",
    "    loss='categorical_crossentropy', #tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "modelRRRNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "651ec3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 5s 292ms/step - loss: 34.7643 - categorical_accuracy: 0.0000e+00 - val_loss: 36.3582 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 3s 260ms/step - loss: 34.6528 - categorical_accuracy: 0.0000e+00 - val_loss: 39.5822 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 3s 265ms/step - loss: 33.8048 - categorical_accuracy: 0.0050 - val_loss: 43.2134 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 3s 258ms/step - loss: 33.4301 - categorical_accuracy: 0.0050 - val_loss: 45.9762 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 3s 256ms/step - loss: 33.5367 - categorical_accuracy: 0.0050 - val_loss: 48.4484 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 3s 255ms/step - loss: 33.9203 - categorical_accuracy: 0.0050 - val_loss: 50.6237 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 3s 257ms/step - loss: 34.3005 - categorical_accuracy: 0.0050 - val_loss: 52.5827 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 3s 248ms/step - loss: 34.4361 - categorical_accuracy: 0.0050 - val_loss: 54.1981 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 3s 253ms/step - loss: 34.5645 - categorical_accuracy: 0.0050 - val_loss: 55.8853 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 3s 254ms/step - loss: 34.7544 - categorical_accuracy: 0.0050 - val_loss: 57.5904 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 3s 253ms/step - loss: 34.9497 - categorical_accuracy: 0.0050 - val_loss: 59.2180 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 3s 251ms/step - loss: 35.0579 - categorical_accuracy: 0.0050 - val_loss: 60.7483 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 3s 252ms/step - loss: 35.1797 - categorical_accuracy: 0.0050 - val_loss: 62.2662 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 3s 254ms/step - loss: 35.2862 - categorical_accuracy: 0.0050 - val_loss: 63.8281 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 3s 256ms/step - loss: 35.4400 - categorical_accuracy: 0.0050 - val_loss: 65.4156 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 3s 259ms/step - loss: 35.5823 - categorical_accuracy: 0.0050 - val_loss: 67.0337 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 3s 260ms/step - loss: 35.6752 - categorical_accuracy: 0.0050 - val_loss: 68.4766 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 3s 255ms/step - loss: 35.7027 - categorical_accuracy: 0.0050 - val_loss: 69.9316 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 3s 256ms/step - loss: 35.7766 - categorical_accuracy: 0.0050 - val_loss: 71.4279 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 3s 255ms/step - loss: 35.8908 - categorical_accuracy: 0.0050 - val_loss: 72.9810 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 3s 256ms/step - loss: 35.9386 - categorical_accuracy: 0.0050 - val_loss: 74.4394 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 3s 255ms/step - loss: 36.0425 - categorical_accuracy: 0.0050 - val_loss: 76.0007 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 3s 249ms/step - loss: 36.1257 - categorical_accuracy: 0.0050 - val_loss: 77.4424 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 3s 254ms/step - loss: 36.1781 - categorical_accuracy: 0.0050 - val_loss: 78.9117 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 3s 250ms/step - loss: 36.2424 - categorical_accuracy: 0.0050 - val_loss: 80.4114 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 3s 248ms/step - loss: 36.3701 - categorical_accuracy: 0.0050 - val_loss: 81.8972 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 3s 246ms/step - loss: 36.4065 - categorical_accuracy: 0.0050 - val_loss: 83.3736 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 3s 252ms/step - loss: 36.3286 - categorical_accuracy: 0.0050 - val_loss: 84.6375 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 3s 249ms/step - loss: 36.3162 - categorical_accuracy: 0.0050 - val_loss: 86.0883 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 3s 251ms/step - loss: 36.4044 - categorical_accuracy: 0.0050 - val_loss: 87.6529 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 3s 252ms/step - loss: 36.5304 - categorical_accuracy: 0.0050 - val_loss: 89.1932 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 3s 242ms/step - loss: 36.5331 - categorical_accuracy: 0.0050 - val_loss: 90.5374 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 3s 244ms/step - loss: 36.5645 - categorical_accuracy: 0.0050 - val_loss: 92.0571 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 3s 238ms/step - loss: 36.6012 - categorical_accuracy: 0.0050 - val_loss: 93.4590 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 3s 238ms/step - loss: 36.7132 - categorical_accuracy: 0.0050 - val_loss: 95.0095 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 3s 239ms/step - loss: 36.7337 - categorical_accuracy: 0.0050 - val_loss: 96.3662 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 3s 236ms/step - loss: 36.8004 - categorical_accuracy: 0.0050 - val_loss: 97.9335 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 3s 234ms/step - loss: 36.8324 - categorical_accuracy: 0.0050 - val_loss: 99.2227 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 3s 233ms/step - loss: 36.8629 - categorical_accuracy: 0.0050 - val_loss: 100.7664 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 3s 236ms/step - loss: 36.8790 - categorical_accuracy: 0.0050 - val_loss: 102.0918 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 3s 236ms/step - loss: 36.8441 - categorical_accuracy: 0.0050 - val_loss: 103.4966 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 3s 239ms/step - loss: 36.8507 - categorical_accuracy: 0.0050 - val_loss: 104.9082 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 3s 238ms/step - loss: 36.9568 - categorical_accuracy: 0.0050 - val_loss: 106.4295 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 3s 233ms/step - loss: 37.0141 - categorical_accuracy: 0.0050 - val_loss: 107.8499 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 3s 238ms/step - loss: 36.9648 - categorical_accuracy: 0.0050 - val_loss: 109.2789 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 3s 240ms/step - loss: 36.9190 - categorical_accuracy: 0.0050 - val_loss: 110.5821 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 3s 234ms/step - loss: 37.0388 - categorical_accuracy: 0.0050 - val_loss: 112.1437 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 3s 237ms/step - loss: 37.0266 - categorical_accuracy: 0.0050 - val_loss: 113.4472 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 3s 242ms/step - loss: 37.0097 - categorical_accuracy: 0.0050 - val_loss: 114.8784 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 3s 244ms/step - loss: 37.0388 - categorical_accuracy: 0.0050 - val_loss: 116.3443 - val_categorical_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "rnn_history = modelRRRNN.fit(\n",
    "    #entradaEntrenadaAjustada,\n",
    "    entradaEntrenamientoIndicesNormalizados,\n",
    "    salidaEsperadaCompressedAjustada,\n",
    "    epochs=50,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[checkpointRecurrent]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e05cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
