{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "010176d1",
   "metadata": {},
   "source": [
    "<div><img style=\"float: right; width: 120px; vertical-align:middle\" src=\"https://www.upm.es/sfs/Rectorado/Gabinete%20del%20Rector/Logos/EU_Informatica/ETSI%20SIST_INFORM_COLOR.png\" alt=\"ETSISI logo\" />\n",
    "\n",
    "\n",
    "# Problemas de clasificación, regresión y sus métricas<a id=\"top\"></a>\n",
    "\n",
    "<i><small>Autor: Alberto Díaz Álvarez<br>Última actualización: 2023-03-05</small></i></div>\n",
    "                                                  \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554fb61b",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En un esquema de aprendizaje supervisado el objetivo es modelar de algún modo la relación entre las características medidas de los datos y alguna etiqueta o _label_ asociada a los datos de manera que, una vez determinado dicho modelo, este pueda ser usado para aplicar etiquetas a datos nuevos y desconocidos.\n",
    "\n",
    "Esto se corresponde con dos tareas diferentes, tanto en la definición de la arquitectura como en la medida de su desempeño:\n",
    "\n",
    "- **Tareas de clasificación**, donde las etiquetas con categorías discretas.\n",
    "- **Tareas de regresión**, también denominadas de ajuste, donde las etiquetas son cantidades continuas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f243ba3",
   "metadata": {},
   "source": [
    "## Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d6d24f",
   "metadata": {},
   "source": [
    "Vamos a plantear soluciones a dos tipos de problemas diferentes, uno de clasificación y otro de regresión. Para ellos, definiremos además una serie de métricas para medir el desempeño de estas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67582fcc",
   "metadata": {},
   "source": [
    "## Bibliotecas y configuración\n",
    "\n",
    "A continuación importaremos las bibliotecas que se utilizarán a lo largo del _notebook_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58374f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e97df",
   "metadata": {},
   "source": [
    "Si salen algunos _warning_ es porque `tensorflow` es así. Seguramente sea una compilación genérica y requiera de una compilación específica para que desaparezcan. Afortunadamente, no suele pasar nada porque salgan estos warning, sobreviviremos.\n",
    "\n",
    "Configuraremos también algunos parámetros para adecuar la presentación gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca72f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({\"axes.grid\" : False})\n",
    "plt.rcParams.update({'figure.figsize': (16, 9),'figure.dpi': 64})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06541e93",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37fa74e",
   "metadata": {},
   "source": [
    "## Tareas de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aec0b7",
   "metadata": {},
   "source": [
    "Como hemos indicado en la introducción, las tareas de clasificación son predecir etiquetas discretas. La verdad es que ya hemos desarrollado esta tarea antes, hemos clasificado ejemplos de entrada en una de las 10 clases de salida: los diez dígitos del 0 al 9.\n",
    "\n",
    "En este caso trataremos de resolver un problema de clasificación binaria (es decir, pertenecer o no a una clase) con un modelo sencillo para ilustrar el problema. Para ello nos aprovecharemos de la función `make_classification` de la biblioteca `scikit learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a3e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = sklearn.datasets.make_classification(\n",
    "    n_samples=7000,\n",
    "    n_features=2,\n",
    "    n_redundant=0,\n",
    "    n_classes=2\n",
    ")\n",
    "plt.scatter(X[:,0], X[:,1], marker=\"+\", c=Y, cmap='bwr');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66883758",
   "metadata": {},
   "source": [
    "El conjunto de datos está compuesto de 7000 ejemplos de dos características y dos clases (0 o 1). Visualmente, vemos que estas dos clases están relativamente bien diferenciadas.\n",
    "\n",
    "Vamos a extraer 1000 ejemplos para el conjunto de test y el resto como conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edcdc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = X[:-1000,:], Y[:-1000]\n",
    "x_test, y_test = X[-1000:,:], Y[-1000:]\n",
    "plt.scatter(x_train[:,0], x_train[:,1], marker=\"+\", c=y_train, cmap='bwr');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1efd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_test[:,0], x_test[:,1], marker=\"+\", c=y_test, cmap='bwr');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb832e4",
   "metadata": {},
   "source": [
    "### Modelo para clasificar datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f95be9",
   "metadata": {},
   "source": [
    "Ahora crearemos un modelo que sea capaz de clasificar valores que provengan de esta distribución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b053640",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # La primera capa del modelo toma entradas de 28x28 y las \"aplana\"\n",
    "    tf.keras.layers.Flatten(input_shape=(2,)),\n",
    "    tf.keras.layers.Dense(10, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(5, activation='sigmoid'),\n",
    "    # La salida la cambiamos a 10 neuronas y una función de activación softmax\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.SGD(),\n",
    "    metrics = [tf.keras.metrics.BinaryAccuracy()]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b11c18",
   "metadata": {},
   "source": [
    "Ahora entrenemos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13322dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=len(x_train), epochs=1000, validation_split=0.1, verbose=0)\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fcb1c2",
   "metadata": {},
   "source": [
    "Parece que más o menos aprende bien, así que nos quedaremos con este modelo. Vamos a hacer un recorrido sobre algunas de las diferentes métricas que existen para evaluar un modelo de clasificación. Para ello, extraeremos las predicciones de nuestro modelo sobre el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75683dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ_test = (model.predict(x_test) > 0.5).astype(int)[:,0]\n",
    "print(ŷ_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e8b498",
   "metadata": {},
   "source": [
    "### Matriz de confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d8992f",
   "metadata": {},
   "source": [
    "La matriz de confusión no es una métrica como tal, sino que es una tabla que se utiliza en problemas de clasificación para evaluar dónde se cometieron errores en el modelo. Se utiliza para problemas de clasificación en los que la salida puede ser de dos o más tipos de clases, aunque aquí la explicaremos para problemas de clasificación binaria (dos clases).\n",
    "\n",
    "La idea es que las filas representan las clases reales que deberían haber sido los resultados, mientras que las columnas representan las predicciones que hemos hecho. Utilizando esta tabla es fácil identificar qué predicciones son erróneas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ffc694",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.ConfusionMatrixDisplay.from_predictions(y_test, ŷ_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7362f3",
   "metadata": {},
   "source": [
    "Prácticamente todas las medidas de rendimiento se basan en los valores de esta matriz. Antes de explicar estas métricas, es útil conocer los nombres por los que se conocen a los valores de acierto y fallo:\n",
    "\n",
    "1. **Verdaderos positivos** (TP, de _true positives_): Aquellos casos donde la clase real y la clase que predice el modelo son verdaderas. Por ejemplo, el caso de que una persona tiene cáncer (`true`) y el modelo clasifica su caso como cáncer (`true`).\n",
    "1. **Verdaderos negativos** (TN, de _true negatives_): Aquellos casos donde la clase real y la clase que predice el modelo son falsas. Por ejemplo, el caso de que una persona **no** tiene cáncer (`false`) y el modelo clasifica su caso como que **no** tiene cáncer (`false`).\n",
    "1. **Falsos positivos** (FP, del inglés _false positives_): Aquellos casos donde la clase real es falsa, pero el modelo la predice como verdadera. Por ejemplo, una persona que **no** tiene cáncer, pero cuyo caso queda predicho por el modelo como que sí lo tiene.\n",
    "1. **Falsos Negativos** (FN, del inglés _false negative_): Aquellos casos donde la clase real es verdadera, pero la que predice el modelo es falsa. Por ejemplo, el caso de una persona que sí tiene cáncer, pero para la que el modelo predice que no lo tiene.\n",
    "\n",
    "Por supuesto, nosotros buscamos el escenario donde hay 0 falsos positivos y 0 falsos negativos, pero en la vida real no es así, ya que prácticamente ningún modelo será preciso al 100%. Por lo tanto, siempre habrá algún error asociado a cada modelo que utilicemos para predecir la clase real de la variable objetivo. Esto dará lugar a falsos positivos y falsos negativos, los cuales además estarán relacionados: cuando unos disminuyan otros aumentarán y viceversa.\n",
    "\n",
    "Entonces, ¿cuáles son preferibles? pues depende del problema:\n",
    "\n",
    "1. Minimizar los falsos negativos: Suele ser recomendable en los casos en los que pasar por alto un caso positivo supone un gran error. En el caso de la detección de cáncer anterior, es preferible cometer el error de falso positivo (el paciente es diagnosticado con cáncer cuando no lo tiene) en lugar de un false negativo (no es diagnosticado cuando sí lo tiene), porque en el segundo caso no se le realizaría ningún examen posterior.\n",
    "1. Minimizar los falsos positivos: Suele ser preferible en el caso contrario al anterior. Por ejemplo, en un caso de detección de _spam_, suele ser preferible que un correo de _spam_ no sea detectado como tal; si en este caso minimizásemos los falsos negativos, aumentarían los falsos positivos y por tanto nuestro sistema podría eliminar correos genuinos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a9f294",
   "metadata": {},
   "source": [
    "### Exactitud (_accuracy_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d546708e",
   "metadata": {},
   "source": [
    "Se define como el número de predicciones correctas (verdaderos positivos y verdaderos negativos) respecto al total de predicciones realizadas:\n",
    "\n",
    "$$\n",
    "Acc = \\frac{TP + TN}{TP + FP + TN + FN}\n",
    "$$\n",
    "\n",
    "Responde a la pregunta: **¿con qué frecuencia acierta el modelo?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc4f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.sum(ŷ_test == y_test) / len(y_test)\n",
    "print(f'Accuracy = {accuracy:.02}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696c3f97",
   "metadata": {},
   "source": [
    "Es una medida válida siempre y cuando el problema de clasificación esté bien balanceado. Sin embargo, en el momento que hay un claro sesgo hacia alguna de las clases, la medida se vuelve inútil. Por ejemplo, si estamos determinando si va a haber una fusión del núcleo en una central nuclear, nuestro modelo puede aprender a decir siempre que no y acertar el 99,9999% de los casos; desde el punto de vista de la exactitud, el modelo está muy bien, pero siendo objetivos no vale para nada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9c4e94",
   "metadata": {},
   "source": [
    "### Precisión (_precision_)\n",
    "\n",
    "Medida que indica qué proporción de predicciones positivas lo son realmente:\n",
    "\n",
    "$$\n",
    "Pre = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "Responde a la pregunta: **de los positivos que se han predecido, ¿qué porcentaje es realmente positivo?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a483ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = np.sum((ŷ_test == 1) & (y_test == 1))\n",
    "FP = np.sum((ŷ_test == 1) & (y_test == 0))\n",
    "precision = TP / (TP + FP)\n",
    "print(f'Precision = {precision:.02}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b83482f",
   "metadata": {},
   "source": [
    "Sobre cuándo es útil o cuando no lo vemos en la siguiente medida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1608783",
   "metadata": {},
   "source": [
    "### Recuperación (_recall_)\n",
    "\n",
    "También se suele traducir como \"sensibilidad\", y es una medida que indica la proporción de verdaderos positivos fueron predichos como positivos por el modelo.\n",
    "\n",
    "$$\n",
    "Rec = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "Responde a la pregunta: **de todos los casos positivos, ¿qué porcentaje han sido predichos por el modelo?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862c8965",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = np.sum((ŷ_test == 1) & (y_test == 1))\n",
    "FN = np.sum((ŷ_test == 0) & (y_test == 1))\n",
    "recall = TP / (TP + FN)\n",
    "print(f'Recall = {recall:.02}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd11b9c6",
   "metadata": {},
   "source": [
    "La precisión consiste precisamente en eso, ser preciso con los valores positivos, mientras que la recuperación consiste en recuperar todos los valores positivos. Por ejemplo, aunque sólo hayamos detectado un caso de cáncer, si lo hemos hecho correctamente, la **precisión** es del 100%; sin embargo, si marcamos todos los ejemplos como positivo en cáncer, la precisión no será nada buena, pero habremos conseguiro un 100% de **recuperación**.\n",
    "\n",
    "Así que, básicamente, si queremos centrarnos más en minimizar los falsos negativos, nuestro objetivo sería conseguir una sensibilidad lo más cercana al 100% sin que la precisión fuera demasiado mala. Por otro lado, si quisiésemos centrarnos en minimizar los falsos positivos, entonces nuestro objetivo debería ser que la precisión fuera lo más cercana posible al 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e2d4c8",
   "metadata": {},
   "source": [
    "### Especificidad (_specificity_)\n",
    "\n",
    "El lo opuesto a la sensibilidad. Mide qué proporción de valores realmente negativos son predichos como negativos:\n",
    "\n",
    "$$\n",
    "Spe = \\frac{TN}{TN + FP}\n",
    "$$\n",
    "\n",
    "Responde a la pregunta: **¿cómo de bien predice el modelo los resultados negativos?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558898f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = np.sum((ŷ_test == 0) & (y_test == 0))\n",
    "FP = np.sum((ŷ_test == 1) & (y_test == 0))\n",
    "specificity = TN / (TN + FP)\n",
    "print(f'Specificity = {specificity:.02}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc74583f",
   "metadata": {},
   "source": [
    "Por ejemplo, supongamos que de 100 personas 5 tienen cáncer y nuestro modelo predice que todas tienen cáncer. Ya vimos que la recuperación era del 100%: todos los casos de cáncer son diagnosticados correctamente. Sin embargo, la epecificidad será del 0%, ya que no ha habido ningún falso negativo identificado correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0a5b0f",
   "metadata": {},
   "source": [
    "### _F1 Score_\n",
    "\n",
    "Generalmente las medidas de precisión y recuperación se suelen juntas para entender la calidad de una clasificación. El _F1 score_ es una métrica que representa a ambas, concretamente su media armónica, y se expresa como sigue:\n",
    "\n",
    "$$\n",
    "F1 = 2 \\cdot \\frac{Pre \\cdot Rec}{Pre + Rec}\n",
    "$$\n",
    "\n",
    "Su valor estará en el intervalo $[0, 1]$, donde 0 indica que la precisión o la recuperación son 0 (malo) y 1 donde ambas son 1 (bueno)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb814b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "print(f'F1 Score = {f1_score:.02}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a36bf0",
   "metadata": {},
   "source": [
    "### Curvas ROC (_Receiver Operating Characteristic_) y AUC (_Area Under the Curve_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151168d0",
   "metadata": {},
   "source": [
    "La **curva ROC** es una medida de rendimiento para problemas de clasificación binaria que evalúa la capacidad de un modelo para distinguir entre dos clases. Muestra la tasa de verdaderos positivos ($Rec$) frente a la tasa de falsos positivos ($1 - Spe$) para diferentes umbrales de probabilidad.\n",
    "\n",
    "Veamos la curva ROC con nuestros datos reales y predichos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20342f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FP_rate, TP_rate, thresholds = sklearn.metrics.roc_curve(y_test, ŷ_test)\n",
    "plt.plot(FP_rate, TP_rate)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for our classification problem')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3c6691",
   "metadata": {},
   "source": [
    "Esta curva es muy útil porque nos proporciona una forma de evaluar _recall_ y especificidad de un modelo de clasificación en diferentes umbrales de probabilidad. Un modelo con una curva ROC cercana a la esquina superior izquierda tiene una alta tasa de verdaderos positivos u una baja tasa de falsos positivos, lo que indica que es un buen modelo de clasificación. Por otro lado, un modelo con una curva ROC cercana a la diagonal tiene un rendimiento aleatorio.\n",
    "\n",
    "La curva ROC también se utiliza para calcular el área bajo la curva ROC (AUC), que es una medida numérica del rendimiento del modelo de clasificación. El AUC oscila entre 0 y 1, donde un valor de 1 indica un modelo de clasificación perfecto y un valor de 0,5 indica un rendimiento aleatorio. Veamos cómo se calcula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2d2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.roc_auc_score(y_test, ŷ_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5a4def",
   "metadata": {},
   "source": [
    "El AUC es muy útil como resumen numérico del rendimiento del clasificador, incluso cuando hay un gran desequilibrio de clases (a diferencia de la exactitud de la clasificación). Permite evaluar la capacidad de un modelo para distinguir entre dos clases y **comparar diferentes modelos de clasificación de manera objetiva**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228b2ec6",
   "metadata": {},
   "source": [
    "## Tareas de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5c873a",
   "metadata": {},
   "source": [
    "Las tareas de rergesión son aquellas que tratan de predecir una salida continua a partir de un conjunto de características de entrada. Son una técnica dentro del aprendizaje supervisado que trata de establecer una relación funcional entre las características de entrada y sus respectivas salidas.\n",
    "\n",
    "Algunos ejemplos de este tipo de modelos puede ser la predicción de precios de viviendas, proyección de ventas o de ingresos futuros de clientes, etcétera.\n",
    "\n",
    "En este caso vamos a crear un modelo sencillo que trate de resolver el problema del conjunto de datos _Boston Housing Price dataset_ al que podemos acceder directamente a través de `keras`. Las 13 características que definen cada uno de los ejemplos se describen en el sitio web [StatLib](http://lib.stat.cmu.edu/datasets/boston). Estas son, por orden:\n",
    "\n",
    "- `CRIM`: Tasa de criminalidad per cápita por ciudad\n",
    "- `ZN`: Proporción de suelo residencial para parcelas de más de 25K pies cuadrados\n",
    "- `INDUS`: Proporción de acres comerciales no minoristas por ciudad\n",
    "- `CHAS`: Variable ficticia del río Charles (= 1 si el tramo linda con el río; 0 en caso contrario)\n",
    "- `NOX`: Concentración de óxidos nítricos (partes por 10 millones)\n",
    "- `RM`: Número medio de habitaciones por vivienda\n",
    "- `AGE`: Proporción de unidades ocupadas por sus propietarios construidas antes de 1940\n",
    "- `DIS`: Distancias ponderadas a cinco centros de empleo de Boston\n",
    "- `RAD`: Índice de accesibilidad a autopistas radiales\n",
    "- `TAX`: Tipo del impuesto sobre bienes inmuebles de valor íntegro por 10.000 dólares\n",
    "- `PTRATIO`: Ratio alumno-profesor por ciudad\n",
    "- `B`: 1000(Bk - 0,63)^2 donde Bk es la proporción de negros por ciudad\n",
    "- `LSTAT`: % más bajo de la población\n",
    "- `MEDV`: Valor medio de las viviendas ocupadas por sus propietarios en miles de $.\n",
    "\n",
    "El valor a predecir (las salidas) serán los valores medios de las viviendas en miles de dolares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b450d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data()\n",
    "\n",
    "print(f'Training shape: {x_train.shape} input, {y_train.shape} output')\n",
    "print(f'Test shape:     {x_test.shape} input, {y_test.shape} output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b5baea",
   "metadata": {},
   "source": [
    "Introducir los datos en crudo a una red sería bastante problemático, así que los adaptaremos. Como no es el objetvo de este notebook, no se detallará el porqué de las transformaciones, pero básicamente se normalizarán las características restando su media y dividiendo por su desviación típica. Es una técnica típica de normalización para que los valores estén centrados en 0 con desviación típica de 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6fee2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train - x_train.mean(axis=0)) / x_train.std(axis=0)\n",
    "x_test = (x_test - x_test.mean(axis=0)) / x_test.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c2a3d7",
   "metadata": {},
   "source": [
    "Veamos qué forma tiene la salida del conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d31a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e001845",
   "metadata": {},
   "source": [
    "Vamos a crear por tanto un modelo cuya salida sea una única neurona (dado que vamos a predecir un único valor) y, aunque en muchos casos las salidas se suelen normalizar, en este caso la activación de la última neurona será lineal para no añadir complicación al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f3cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_shape=(13,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.MeanSquaredError(),\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics = [tf.keras.metrics.RootMeanSquaredError()]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb3d79b",
   "metadata": {},
   "source": [
    "Hemos cambiado tanto el tipo de neurona de activación (ReLU) como el optimizador, simplemente para que se vea lo fácil que es cambiarlos. En realidad los cambios diferenciadores con un problema de clasificación están en la forma de calcular el loss, que ahora usaremos cálculos específicos para medir un error de ajuste, como puede ser el MAE o el MSE.\n",
    "\n",
    "Entrenemos ahora el modelo y veamos cómo se comporta el proceso de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f803a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=len(x_train), epochs=1000, validation_split=0.1, verbose=0)\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e897570",
   "metadata": {},
   "source": [
    "Buen entrenamiento. Ahora vamos a predecir las salidas del conjunto de test y vamos a ponerlas frente a frente a frente con las reales, así podemos compararlas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6be095",
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ_test = model.predict(x_test)[:,0]\n",
    "np.column_stack((y_test, ŷ_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b18a03f",
   "metadata": {},
   "source": [
    "A ojo parece que el modelo predice más o menos bien. Para ver cómo de bien, extraer conclusiones o, al menos, poder comparar entre modelos, existen diferentes métricas. Veamos algunas de las más conocidas:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de152d82",
   "metadata": {},
   "source": [
    "### Error absoluto medio (MAE, de _Mean Absolute Error_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aa77b6",
   "metadata": {},
   "source": [
    "Es la media de las diferencias absolutas entre las predicciones y los valores reales. Se define como:\n",
    "\n",
    "$$\n",
    "MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
    "$$\n",
    "\n",
    "Veamos la implementación en numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21396b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.abs(y_test - ŷ_test).mean()\n",
    "print(f'MAE = {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc44e2bc",
   "metadata": {},
   "source": [
    "El MAE es útil porque da una idea de cuánto se desvían las predicciones del valor real en promedio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47634b26",
   "metadata": {},
   "source": [
    "### Error cuadrático medio (MSE, de _Mean Squared Error_)\n",
    "\n",
    "Es la media de las diferencias al cuadrado entre las predicciones y los valores reales. Se define como:\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "Veamos la implementación en numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809e8b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = ((y_test - ŷ_test) ** 2).mean()\n",
    "print(f'MSE = {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a791bf61",
   "metadata": {},
   "source": [
    "Es útil dado que penaliza más fuertemente las grandes desviaciones de las predicciones del valor real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4384c8aa",
   "metadata": {},
   "source": [
    "### Raíz del error cuadrático medio (RMSE, de _Root Mean Squared Error_)\n",
    "\n",
    "El RMSE es simplemente la raíz cuadrada del MSE. Se define como:\n",
    "\n",
    "$$\n",
    "RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n",
    "$$\n",
    "\n",
    "Veamos la implementación en numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73354821",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = mse ** .5\n",
    "print(f'RMSE = {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e689b9b",
   "metadata": {},
   "source": [
    "El RMSE se utiliza a menudo porque a las ventajas del MSE se le añade la de tener las mismas unidades que la variable objetivo, lo que lo hace fácilmente interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307d9329",
   "metadata": {},
   "source": [
    "## Coeficiente de determinación ($R^2$ )\n",
    "\n",
    "Es una medida de la proporción de la varianza en los valores objetivo que se puede explicar por las predicciones del modelo. Determina cómo de bien se predecirán los valores futuros con nuestro modelo. Se define como:\n",
    "\n",
    "$$R^2(y, \\hat{y}) = 1 - \\frac{\\sum_1^{n} (y_i - \\hat{y}_i)^2}{\\sum_1^{n}(y_i - \\bar{y})^2}$$\n",
    "\n",
    "Siendo$\\bar{y}$ la media de los valores. Veamos su implementación en numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b099bb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = 1 - ((y_test - ŷ_test) ** 2).sum() / ((y_test - y_test.mean()) ** 2).sum()\n",
    "print(f'R² = {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc187770",
   "metadata": {},
   "source": [
    "El $R^2$ varía entre 0 y 1, donde 1 significa que todas las variaciones se pueden explicar por el modelo y 0 significa que el modelo no explica ninguna variación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05096b5",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd65fcd4",
   "metadata": {},
   "source": [
    "Este notebook ha sido intenso, pero en él hemos visto las principales diferencias de los dos tipos de problema que nos encontraremos en problemas de aprendizaje profundo: clasificación y regresión. Los modelos desarrollados para éstos son muy parecidos, varían básicamente en la salida y su cálculo del error.\n",
    "\n",
    "También, para la evaluación de estos modelos hemos presentado algunas medidas, unas específicas para clasificación y otras para regresión. Hay algunas que no hemos explicado (e.g. entropía cruzada) pero hemos preferido quedarnos en las más comunes. Una cosa buena es que prácticamente todos los frameworks incluyen estas implementaciones, seguramente mucho mejor de lo que las podamos implementar nosotros. Sin embargo, es muy importante es saber cómo estamos midiendo y qué significan esas mediciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23734ea4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9fcfec",
   "metadata": {},
   "source": [
    "\n",
    "[1] Guía para la creación de capas y modelos personalizados (<https://www.tensorflow.org/guide/keras/custom_layers_and_models>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582efec2",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div><img style=\"float: right; width: 120px; vertical-align:top\" src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" alt=\"Creative Commons by-nc-sa logo\" />\n",
    "\n",
    "[Volver al inicio](#top)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
