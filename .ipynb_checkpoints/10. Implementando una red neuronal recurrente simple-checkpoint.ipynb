{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div><img style=\"float: right; width: 120px; vertical-align:middle\" src=\"https://www.upm.es/sfs/Rectorado/Gabinete%20del%20Rector/Logos/EU_Informatica/ETSI%20SIST_INFORM_COLOR.png\" alt=\"ETSISI logo\" />\n",
    "\n",
    "\n",
    "# Implementando una red neuronal recurrente simple<a id=\"top\"></a>\n",
    "\n",
    "<i><small>Autor: Alberto Díaz Álvarez<br>Última actualización: 2023-03-14</small></i></div>\n",
    "                                                  \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introducción\n",
    "\n",
    "Las unidades recurrentes simples (SRU, del inglés _Single Recurrent Unit_) son a las Redes Neuronales Recurrentes (RNNs) lo que las neuronas a las Redes Neuronales tradicionales. La única diferencia es que la salida de la red se concatena a la entrada, de tal manera que la salida anterior forma parte de la entrada actual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "\n",
    "En este _notebook_ vamos a implementar una red neuronal recurrente para resolver el problema [MNIST](http://yann.lecun.com/exdb/mnist/). En realidad lo haremos más como ejercicio que como probelma de aplicación real, ya que técnicamente el MNIST es un problema de reconocimiento de imagen. Sin embargo, como veremos, las RNNs, leyendo las columnas de izquierda a derecha de la imagen de los números son capaces de alcanzar resultados equiparables a los de las Redes de Convolución (CNNs).\n",
    "\n",
    "Al finalizar habremos aprendido a:\n",
    "\n",
    "- Crear y entrenar un modelo recurrente para la resolución de problemas de clasificación usando, para ello, una SRU.\n",
    "- Apilar dos o más SRU para hacer Redes Recurrentes multicapa, aumentando así la potencia de estas redes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Imports y configuración\n",
    "\n",
    "A continuación importaremos las librerías que se usarán a lo largo del notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asímismo, configuramos algunos parámetros para adecuar la presentación gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'figure.figsize': (20, 6),'figure.dpi': 64})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga y preprocesamiento de datos\n",
    "\n",
    "Empezamos como en el resto de notebooks, descargando y preparando el conjunto `mnist` para nuestra tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train / 255, x_test / 255\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modelo basado en una capa de SRUs\n",
    "\n",
    "La primera capa será una SRU (en keras una `SimpleRNN`) de 10 \"unidades\" (una salida de dimensión 10) y cuya entrada sean las dimensiones de la imagen (esto es, $28 \\times 28$).\n",
    "\n",
    "La segunda capa será una densa con activación softmax para las 10 posibles salidas. Esto quiere decir que los 10 valores de salida de nuestra SRU se conectarán con 10 neuronas haciendo un total de 110 conexiones (10 * 10 + 10 de bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 10)                390       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 500\n",
      "Trainable params: 500\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(10, input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos indicando una entrada de $28 \\times 28$, pero que no nos lleve a engaño. No estamos ofreciendo una entrada de 28 filas por 28 columnas; estamos ofreciendo una entrada de 28 elementos de una secuencia, cada uno de tamaño 28. Es decir, se va a alimentar a nuestra red primero con la primera fila de la imagen, luego con la segunda, luego con la tercera, y así sucesivamente hasta la fila número 28.\n",
    "\n",
    "Por último, vamos a compilar el modelo creado con la función de pérdida que corresponde a este tipo de problema con un optimizador de descenso del gradiente estocástico y vamos a añadir la métrica de _exactitud_ para ver cómo evoluciona dicho entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Entrenamiento del modelo\n",
    "\n",
    "Por último, entrenaremos nuestra red durante $10$ epochs (sí, las redes recurentes son muuucho más lentas de entrenar que otras). Vamos además a usar un conjunto de validación de un 10% del conjunto de entrenamiento para ver la evolución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ahora, para ver cómo ha evolucionado el entrenamiento, vamos a mostrar dos gráficas, una al lado de la otra, con los datos de entrenamiento de pérdida y exactitud tanto en el conjunto de entrenamiento como en el de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['categorical_accuracy'], label='Train')\n",
    "plt.plot(history.history['val_categorical_accuracy'], label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que distan de las precisiones alcanzadas con otras técnicas de deep learning, sobre todo comparando con las redes de convolución. Pero como hemos dicho, es un ejemplo de implementación, no un caso de uso específico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación de dígitos\n",
    "\n",
    "Vamos a sacar una inferencia de un ejemplo en concreto. Concretamente, vamos a sacar por pantalla el dígito como figura y la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = x_train[36]\n",
    "\n",
    "predicted = model.predict(np.array([example]))\n",
    "                          \n",
    "plt.imshow(example, cmap='hot')\n",
    "plt.title(f'predicted: {np.argmax(predicted)}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apilando redes\n",
    "\n",
    "Las redes recurrentes ya se consideran _aprendizaje profundo_, aunque existe el concepto de las _redes recurrentes profundas_, lo cual es simplemente apilar unidades recurrentes para aumentar la complejidad del modelo. Otra forma de llamarlas es _stacked networks_.\n",
    "\n",
    "Vamos a crear un modelo con varias unidades recurrentes apiladas (digamos 3 capas). Los datos de compilación podemos dejarlos como en el anterior ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(16, return_sequences=True, input_shape=(28, 28)),\n",
    "    tf.keras.layers.SimpleRNN(8, return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(4),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nos fijamos, hemos devuelto los valores como secuencia en todas menos la última capa recurente. Esto es así porque nuestra SRU **espera las entradas como secuencia**. Si no lo pusiésemos, únicamente devolvería un valor y no se le podría pasar una secuencia de elementos los primeros.\n",
    "\n",
    "Ahora, pasaremos a realizar un entrenamiento sobre este modelo con los mismos parámetros que el anterior ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la evolución del _loss_ y la exactitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['categorical_accuracy'], label='Training')\n",
    "plt.plot(history.history['val_categorical_accuracy'], label='Validation')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('apoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y hasta aquí el notebook. Hemos visto que crear una red neuronal recurrente es tan sencillo como crear una red normal, y que en el caso de querer tener varias unidades apiladas hay que añadir un mínimo cambio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div><img style=\"float: right; width: 120px; vertical-align:top\" src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" alt=\"Creative Commons by-nc-sa logo\" />\n",
    "\n",
    "[Volver al inicio](#top)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
