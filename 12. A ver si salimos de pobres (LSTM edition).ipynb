{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div><img style=\"float: right; width: 120px; vertical-align:middle\" src=\"https://www.upm.es/sfs/Rectorado/Gabinete%20del%20Rector/Logos/EU_Informatica/ETSI%20SIST_INFORM_COLOR.png\" alt=\"ETSISI logo\" />\n",
    "\n",
    "\n",
    "# A ver si salimos de pobres - LSTM _edition_<a id=\"top\"></a>\n",
    "\n",
    "<i><small>Autor: Alberto Díaz Álvarez<br>Última actualización: 2023-03-14</small></i></div>\n",
    "                                                  \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introducción\n",
    "\n",
    "El anterior intento de predecir la bolsa no salió como esperábamos. Vamo a volver a intentarlo, esta vez con unas flamantes redes LSTM, y usando únicamente el valor de bolsa anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "\n",
    "Crearemos un modelo de regresión de un valor de la bosla en base al valor anterior. Al finalizar habremos aprendido a:\n",
    "\n",
    "- Predecir la tendencia de una serie temporal usando LSTM.\n",
    "- Pensárselo dos veces antes de invertir en bolsa en base a las recomendaciones que hagan los modelos que nosotros hayamos programado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Imports y configuración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación importaremos las librerías que se usarán a lo largo del notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asímismo, configuramos algunos parámetros para adecuar la presentación gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'figure.figsize': (20, 6),'figure.dpi': 64})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y preparación de datos\n",
    "\n",
    "Volveremos a cargar los datos del histórico de Google tal y como hicimos en el ejercicio número 03.esentar las notas que nos hará fácil más tarde convertir las notas generadas en una nueva pista de audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close/Last</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-03-27</th>\n",
       "      <td>558.460022</td>\n",
       "      <td>13052.0</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>552.919983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-28</th>\n",
       "      <td>559.989990</td>\n",
       "      <td>41003.0</td>\n",
       "      <td>561.200012</td>\n",
       "      <td>566.429993</td>\n",
       "      <td>558.669983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-31</th>\n",
       "      <td>556.969971</td>\n",
       "      <td>10772.0</td>\n",
       "      <td>566.890015</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>556.929993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-01</th>\n",
       "      <td>567.159973</td>\n",
       "      <td>7932.0</td>\n",
       "      <td>558.710022</td>\n",
       "      <td>568.450012</td>\n",
       "      <td>558.710022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-02</th>\n",
       "      <td>567.000000</td>\n",
       "      <td>146697.0</td>\n",
       "      <td>599.989990</td>\n",
       "      <td>604.830017</td>\n",
       "      <td>562.190002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Close/Last    Volume        Open        High         Low\n",
       "Date                                                                \n",
       "2014-03-27  558.460022   13052.0  568.000000  568.000000  552.919983\n",
       "2014-03-28  559.989990   41003.0  561.200012  566.429993  558.669983\n",
       "2014-03-31  556.969971   10772.0  566.890015  567.000000  556.929993\n",
       "2014-04-01  567.159973    7932.0  558.710022  568.450012  558.710022\n",
       "2014-04-02  567.000000  146697.0  599.989990  604.830017  562.190002"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Datasets/GOOG-20211004.csv', parse_dates=['Date'], index_col='Date')\n",
    "df = df.replace('[\\$]', '', regex=True).astype('float32')\n",
    "df.sort_index(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a obviar el reto de valores y a usar únicamente la evolución temporal del valor de cierre de la acción. Sin embargo, en lugar de usar el valor absoluto, lo que usaremos será la variación del valor con respecto al día anterior. No vamos a hacer ninguna transformación más allá de normalizar y poco más, así que podemos convertirlo a un array de numpy tranquilamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.5299683],\n",
       "       [ -3.0200195],\n",
       "       [ 10.190002 ],\n",
       "       ...,\n",
       "       [-33.26001  ],\n",
       "       [-25.109863 ],\n",
       "       [ 63.93994  ]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df[['Close/Last']].diff(axis=0).values[1:]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora crearemos un `MinMaxScaler` para hacer la normalización y desnormalización de nuestros datos. Aprovechamos y los dejamos ya normalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49262467],\n",
       "       [0.47625545],\n",
       "       [0.52378035],\n",
       "       ...,\n",
       "       [0.36746287],\n",
       "       [0.3967842 ],\n",
       "       [0.7171532 ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ya tenemos nuestro conjunto de datos casi listo para trabajar sobre él. Lo siguiente será especificar la longitud de la secuencia, que es lo mismo que el número de timesteps o el número de observaciones previas a considerar para hacer una predicción.\n",
    "\n",
    "Usaremos un tamaño de 20, lo que quiere decir que para predecir el valor de un día usará los 20 anteriores (aproximadamente un mes). Crearemos por tanto los conjuntos `X_train` e `Y_train`, dos arrays de NumPy que contendrán las secuencias y el siguiente valor de dicha secuencia respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... [0.54738086 0.52036256 0.40369114] -> 0.4548136591911316\n",
      "... [0.52036256 0.40369114 0.4498847 ] -> 0.4906102120876312\n",
      "... [0.40369114 0.4498847  0.494028  ] -> 0.5250754356384277\n",
      "... [0.4498847 0.494028  0.5012231] -> 0.48337870836257935\n",
      "... [0.494028   0.5012231  0.55943286] -> 0.5039933323860168\n",
      "... [0.5012231  0.55943286 0.41358465] -> 0.47481653094291687\n",
      "... [0.55943286 0.41358465 0.4602101 ] -> 0.4866887032985687\n",
      "... [0.41358465 0.4602101  0.50938976] -> 0.44153836369514465\n",
      "... [0.4602101  0.50938976 0.458807  ] -> 0.4684845507144928\n",
      "... [0.50938976 0.458807   0.4807165 ] -> 0.4908619523048401\n",
      "x_train shape: (1874, 10), Y_train shape: (1874,)\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_LEN = 10\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(len(dataset) - SEQUENCE_LEN - 9):\n",
    "    x_train.append(dataset[i:i + SEQUENCE_LEN, 0])\n",
    "    y_train.append(dataset[i + SEQUENCE_LEN + 9, 0])\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "for i in range(10):\n",
    "    print(f'... {x_train[i][-3:]} -> {y_train[i]}')\n",
    "print(f'x_train shape: {x_train.shape}, Y_train shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que los datos de entrada de una red recurrente tienen ue tener una dimensión específica, así que ahora los vamos a transformar para adaptarlos a ese requisito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1874, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.reshape(x_train, (*x_train.shape[:2], 1))\n",
    "\n",
    "print(f'X_train shape: {x_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, ya que tenemos los datos preparados, vamos a extraer los últimos valores (por ejemplo 100) para que hagan las veces de conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1624, 10, 1), Y_train shape: (1624,)\n",
      "X_test shape: (250, 10, 1), Y_test shape: (250,)\n"
     ]
    }
   ],
   "source": [
    "TEST_SIZE = 250\n",
    "\n",
    "x_train, x_test = x_train[:-TEST_SIZE], x_train[-TEST_SIZE:]\n",
    "y_train, y_test = y_train[:-TEST_SIZE], y_train[-TEST_SIZE:]\n",
    "\n",
    "print(f'X_train shape: {x_train.shape}, Y_train shape: {y_train.shape}')\n",
    "print(f'X_test shape: {x_test.shape}, Y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Implementando y entrenando nuestro modelo\n",
    "\n",
    "Pasamos a construir nuestra red neuronal recurrente. Crearemos una estructura apilada de 3 nodos LSTM de 40 nodos cada uno, con una capa de Dropout tras cada capa. Luego, usaremos como optimizador Adam y como medida de pérdida el error cuadrático medio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 10, 128)           66560     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10, 128)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 10, 128)           131584    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, 128)           0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 10, 128)           131584    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 10, 128)           0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 461,441\n",
      "Trainable params: 461,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True, input_shape=(x_train.shape[1], 1)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.LSTM(128),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ahora, entrenaremos el modelo durante... digamos 100 epochs, con los datos de entrenamiento que hemos preparado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la evolución de nuestro entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Train loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediciendo los valores\n",
    "\n",
    "Después de todo lo hecho, este es el paso sencillo. Tenemos que pasar nuestros dates de test para ver cómo se comporta nuestro modelo con valores que nunca ha visto. Los compararemos con los valores de verdad para ver qué tal lo hace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(x_test)\n",
    "predicted = scaler.inverse_transform(predicted)\n",
    "real = scaler.inverse_transform(y_test.reshape((-1, 1)))\n",
    "\n",
    "plt.plot(real, label = 'Real')\n",
    "plt.plot(predicted, label = 'Predicted')\n",
    "plt.title('GOOG Stock Price Prediction')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('GOOG Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al menos no es un comportamiento como el anterior. Pero sigue siendo inútil. Por lo visto no nos vamos a hacer ricos. Al menos no así."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este _notebook_ hemos aprendido que es muy fácil cambiar entre tipos de unidades recurrentes. La API de Keras nos permite reemplazar una y otra prácticamente sin esfuerzo.\n",
    "\n",
    "También hemos visto que no todos los problemas de series temporales son resolubles, al menos no con los datos de los que diponemos a la primera. Desde luego que el valor en bolsa de unas acciones es una serie temporal, pero existen muchas variables relacionadas con los valroes, muchas de ellas emocionales de los propios propietarios de las acciones, por lo que es muy difícil identificarlas, obtenerlas y cuantificarlas. Aún así, si lo intentáis y os sale muy bien, no os olvidéis de nosotros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div><img style=\"float: right; width: 120px; vertical-align:top\" src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" alt=\"Creative Commons by-nc-sa logo\" />\n",
    "\n",
    "[Volver al inicio](#top)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
