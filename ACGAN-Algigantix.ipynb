{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d7afe1f",
   "metadata": {},
   "source": [
    "# Implementación de una red AC-GAN con Keras<a id=\"top\"></a>\n",
    "\n",
    "<i><small>Autor: Algigantix<br>Última actualización: 2023-04-28</small></i></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eaad41",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Las redes generativas adversariales (GAN, de _Generative Adversarial Networks_) fueron presentadas por primera vez por Goodfellow et al. en el artículo [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661) publicado en 2014. Este tipo de redes pueden ser utilizadas para la generación sintética de datos prácticamente idénticos a los originales.\n",
    "\n",
    "Para la generación de estos datos se usan dos redes neuronales durante el entrenamiento: la **generadora**, que acepta un vector de entrada de ruido generado aleatoriamente y produce los datos de salida de aspecto similar a los datos auténticos, y la **discriminadora**, que intenta determinar si los datos que se le presentan son auténticos o generados.\n",
    "\n",
    "Entrenando estas redes al mismo tiempo, una retroalimentando a la otra, dispondremos de un medio para generar datos prácticamente indistinguibles de los originales, o visto de otro modo, dispondremos de un medio para determinar si unos determinados datos son verdaderos o _fake_.\n",
    "\n",
    "Una AC-GAN (_Auxiliary Classifier GAN_) es una variante en la que se incluye la clasificación por clases en la entrada de las dos redes, y la red discriminadora puede clasificar según probabilidad de que una imagen sea de una clase u  otra. Además emplean redes de convolución.\n",
    "\n",
    "En nuestro caso, diseñaremos una red ACGAN que trate de falsificar billetes de euro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c4ec0c",
   "metadata": {},
   "source": [
    "## Imports y configuración\n",
    "\n",
    "Primero importamos las bibliotecas que necesitamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7affa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import enum\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763b0d77",
   "metadata": {},
   "source": [
    "También incluimos un pip por si faltan algunos paquetes en la instalación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8392374d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pydot in c:\\users\\andro\\appdata\\roaming\\python\\python39\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\andro\\appdata\\roaming\\python\\python39\\site-packages (from pydot) (2.4.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330779a2",
   "metadata": {},
   "source": [
    "Asimismo algunas configuraciones gráficas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27071ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'figure.figsize': (15, 8),'figure.dpi': 64})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d50279",
   "metadata": {},
   "source": [
    "## El dataset que usaremos\n",
    "\n",
    "Utilizaremos un dataset propio de billetes de 5€, 10€, 20€ y 50€, con una dimensión de imágenes predeterminada por nosotros y de 3 canales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "229e261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH, HEIGHT, CHANNELS = 640, 480, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d19613c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real images: (70000, 28, 28)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'load_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReal images: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# plot raw pixel data\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# load the images into memory\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m (trainX, trainy), (testX, testy) \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# plot images from the training dataset\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m     13\u001b[0m  \u001b[38;5;66;03m# define subplot\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Cargar imágenes TO-DO clasificar chicos, id buscando como cargar imágenes\n",
    "# TO-DO BUSCAD COMO CARGAR IMAGENES NUESTRAS\n",
    "\n",
    "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data() #load_data()\n",
    "dataset = np.concatenate((x_train, x_test))\n",
    "\n",
    "print(f'Real images: {dataset.shape}')\n",
    "\n",
    "\n",
    "# plot raw pixel data\n",
    "\n",
    "# plot images from the training dataset\n",
    "for i in range(100):\n",
    " # define subplot\n",
    " plt.subplot(10, 10, 1 + i)\n",
    " # turn off axis\n",
    " plt.axis('off')\n",
    " # plot raw pixel data\n",
    " plt.imshow(dataset[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c94e6c",
   "metadata": {},
   "source": [
    "También definiremos las clases de billetes, pero indicando que solo usaremos 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abaf0130",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Billetes(enum.Enum):\n",
    "    \"\"\"Cada una de los posibles billetes a falsificar.\"\"\"\n",
    "    los5euros = 0\n",
    "    los10euros = 1\n",
    "    los20euros = 2\n",
    "    los50euros = 3\n",
    "    los100euros = 4\n",
    "    los200euros = 5\n",
    "    los500euros = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53adedcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_billetes = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e44e53",
   "metadata": {},
   "source": [
    "## Red generadora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d059a4",
   "metadata": {},
   "source": [
    "La parte generadora de un modelo GAN se encarga de generar datos nuevos a partir de ruido aleatorio. Es de esperar que, a la larga, sea capaz de generar nuevos datos con una distribución similar a la de los elementos reales.\n",
    "\n",
    "Y ya que hemos dicho _ruido aleatorio_, vamos con la definición de la longitud del vector de valores de entrada de ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20068f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.]\n",
      "2\n",
      "[0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "test = np.zeros(num_billetes)\n",
    "print(test)\n",
    "print(Billetes.los20euros.value)\n",
    "test[Billetes.los20euros.value] = 1\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b7408bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_FEATURES = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e155a997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(hidden_features, output_shape, clase):\n",
    "    \n",
    "    in_label = tf.keras.layers.Input(shape=(1,))\n",
    "    np.zeroes(n in Billetes())\n",
    "    clasecilla =  np.zeros(num_billetes)\n",
    "    clasecilla[clase.value] = 1\n",
    "    \n",
    "    # embedding for categorical input\n",
    "    li = tf.keras.layers.Embedding(num_billetes, 50)(in_label)\n",
    "    # linear multiplication\n",
    "    n_nodes = 7 * 7\n",
    "    li = tf.keras.layers.Dense(n_nodes, input_shape=(1,))\n",
    "    # reshape to additional channel\n",
    "    li = tf.keras.layers.Reshape((7, 7, 1))(li)\n",
    "    \n",
    "    n_nodes = 7 * 7\n",
    "    li = Dense(n_nodes, kernel_initializer=init)(li)\n",
    "    # reshape to additional channel\n",
    "    li = Reshape((7, 7, 1))(li)\n",
    "    \n",
    "    in_label = tf.keras.layers.Input(shape=(hidden_features,))\n",
    "    \n",
    "     # foundation for 7x7 image\n",
    " n_nodes = 384 * 7 * 7\n",
    " gen = Dense(n_nodes, kernel_initializer=init)(in_lat)\n",
    " gen = Activation('relu')(gen)\n",
    " gen = Reshape((7, 7, 384))(gen)\n",
    " # merge image gen and label input\n",
    " merge = Concatenate()([gen, li])\n",
    "    \n",
    "    return tf.keras.models.Sequential([\n",
    "        \n",
    "        tf.keras.layers.Input(shape=(hidden_features,)),\n",
    "         #in_image = Input(shape=(WIDTH, HEIGHT, CHANNELS))\n",
    "        tf.keras.layers.Conv2D(32, (3, 3, 3), activation=tf.keras.layers.LeakyReLU(alpha=0.2), padding='same', input_shape=(WIDTH, HEIGHT, CHANNELS))(x)\n",
    "        tf.keras.layers.Dropout(0.5)\n",
    "        \n",
    "        tf.keras.layers.Conv2DTranspose(192, (5,5, 3), strides=(2,2), padding='same', kernel_initializer=init)\n",
    "        \n",
    "        \n",
    "        tf.keras.layers.Dense(128, activation=tf.keras.layers.LeakyReLU(alpha=0.2)),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.8),\n",
    "        tf.keras.layers.Dense(128, activation=tf.keras.layers.LeakyReLU(alpha=0.2)),\n",
    "        tf.keras.layers.BatchNormalization(momentum=0.8),\n",
    "        tf.keras.layers.Dense(WIDTH*HEIGHT*CHANNELS, activation='sigmoid'),\n",
    "        tf.keras.layers.Reshape(output_shape)\n",
    "    ], name='Generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41b27a2",
   "metadata": {},
   "outputs": [],
   "source": [
    " # weight initialization\n",
    " init = RandomNormal(stddev=0.02)\n",
    " # label input\n",
    " in_label = Input(shape=(1,))\n",
    " # embedding for categorical input\n",
    " li = tf.keras.layers.Embedding(n_classes, 50)(in_label)\n",
    " # linear multiplication\n",
    " n_nodes = 7 * 7\n",
    " li = tf.keras.layers.Dense(n_nodes, kernel_initializer=init)(li)\n",
    " # reshape to additional channel\n",
    " li = tf.keras.layers.Reshape((7, 7, 1))(li)\n",
    " # image generator input\n",
    " in_lat = Input(shape=(latent_dim,))\n",
    " # foundation for 7x7 image\n",
    " n_nodes = 384 * 7 * 7\n",
    " gen = Dense(n_nodes, kernel_initializer=init)(in_lat)\n",
    " gen = Activation('relu')(gen)\n",
    " gen = Reshape((7, 7, 384))(gen)\n",
    " # merge image gen and label input\n",
    " merge = Concatenate()([gen, li])\n",
    " # upsample to 14x14\n",
    " gen = Conv2DTranspose(192, (5,5), strides=(2,2), padding='same', kernel_initializer=init)(merge)\n",
    " gen = BatchNormalization()(gen)\n",
    " gen = Activation('relu')(gen)\n",
    " # upsample to 28x28\n",
    " gen = Conv2DTranspose(1, (5,5), strides=(2,2), padding='same', kernel_initializer=init)(gen)\n",
    " out_layer = Activation('tanh')(gen)\n",
    " # define model\n",
    " model = Model([in_lat, in_label], out_layer, name='Generator')\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c96c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = create_generator(HIDDEN_FEATURES, (WIDTH, HEIGHT, CHANNELS))\n",
    "tf.keras.utils.plot_model(generator, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106d8c63",
   "metadata": {},
   "source": [
    "## Red discriminadora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0977e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator(input_shape,):\n",
    "    return tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(32, activation=tf.keras.layers.LeakyReLU(alpha=0.2)),\n",
    "        tf.keras.layers.Dropout(0.9),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "    ], name='Discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194cdef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1b927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = create_discriminator(input_shape=(WIDTH, HEIGHT, CHANNELS))\n",
    "tf.keras.utils.plot_model(discriminator, show_shapes=True, show_layer_names=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
